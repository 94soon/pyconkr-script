https://www.youtube.com/watch?v=6oOQJtLa14U

네, 안녕하세요? 

저는 오늘 추천 시스템 소개해주신 어플리케이션 서버 개발 후기를 발표하게 된 김광섭이라고 합니다.

저는 일단 파이썬하고 C++ 개발을 하고 있고요. 

현업에서도 그 두 가지 언어를 개발하고 있고 패턴인식 전공해서 

지금은 추천 시스템이랑 머신러닝에 관심이 많습니다.

여기 계신 분들이 추천 시스템을 한번도 못 들어보시지는 않았을 것 같은데 

추천 시스템이라는 게 한마디로 정의하기가 어려운 것 같아요. 

저도 정의하기 어려운 것 같은데 굳이 한마디로 정의를 하자면 뭔가 우리가 소비하는 데이터를 

좀 새로운 방법으로 새로운 경험으로 할 수 있게 해주자는 게 추천 시스템의 역할인 것 같아요.

그러니까 우리가 뭐 일상생활에서 음악을 소비하고 뉴스를 보고 

블로그 글을 보고 사람을 만나고 친구를 만나고 이런 것들이 일종의 다 데이터라고 볼 수 있거든요.

그런데 지금까지 우리가 데이터를 소비하는 방식이 되게 획일화 되어 있었어요. 

검색이나 지인추천 등.

그런데 이런 것들이 너무 구시대적인 발상이라는 거죠. 

그래서 추천 시스템에서는 좀 다른 방향으로 새로운 경험을 도와주자는 거예요.

그래서 음악, 블로그, 뉴스 영화 등 우리가 사용하는 대부분 서비스들은 알게 모르게 

이미 추천 시스템들이 많이 적용이 되어 있어요.

그런데 이게 사실 복잡한 문제예요. 

이게 서비스랑 굉장히 많이 맞닿아있어요.

UX, UI까지도 고민을 해야 하기 때문에 굉장히 복잡한 문제인데 

오늘 제가 여기서 추천 시스템에 대한 이야기를 하려는 건 아니니까 

이걸 굉장히 단순화해서 보면 두 가지 맥락으로 해석할 수 있어요. 

굉장히 심플하죠. 

이렇게 볼 수 있어요.

우리가 어떤 아이템을 소비하거나 보고 있을 때 

맥락에서 적절하게 더 보여져야 할 게 뭔가, 

이 문제랑 아이템은 모르겠고 어떤 사람이라는 객체가 주어졌을 때 

이 사람에게 우리가 뭘 보여줘야 될까?

서비스적으로 보면 이 두 가지 문제로 압축할 수 있어요.

그런데 사실 이것도 내부적으로 보면 두 개가 시스템적으로는 크게 다르지 않아요.

어쨌든 요약을 하면 이 두 가지를 볼 수 있다는 어죠.

그래서 지금 위 같은 경우는 바나나라는 상품 페이지가 있다고 가정을 할게요.

그러면 바나나 하나만 덜렁 보여주는 경우도 있지만 

대부분은 그것과 관련된 뭔가를 옆에 뿌려주거나 아니면 다음에 추천을 해줘요.

그럴 때 이제 아, 바나나와 관련된 게 뭘까? 하고 

대상이 되는 아이템을 선별하는 과정이라고 볼 수 있는 거죠.

그래서 이걸 설계적인 측면으로 보면 이렇게 볼 수 있을 것 같아요.

어떤 사람이 PC가 됐든 모바일이 됐든 어떤 아이템을 하나 보고 있다고 하면 

서비스적인 측면에서는 이 사람이 추가적으로 원하는 게 뭘까? 

그걸 표현할 수 있는 게 뭘까?

그러니까 이 사람이 바나나와 유사한 걸 찾고 싶은지 

바나나와 같이 먹고 싶은 우유 같은 걸 찾고 싶은 건지 

그런 맥락을 적절하게 결정한 다음에 

그걸 표현할 수 있는 유사도나 거리 같은 개념을 만들어내는 거예요.

그러면 이제 그 순서대로 우리가 보여주고 싶은 아이템들을 정렬을 할 수 있겠죠.

여기서는 뭐 바나나 다음에 제일 볼 만한 게 토마토라고 한 거고요.

그러면 이렇게 정렬이 됐으면 그거를 거기서 끝인 게 아니라 

서비스에 노출을 하려면 상품에 대한 품절 재고 상황이나 

아니면 이 상품을 보고 있는 사람의 혐오도, 이 사람이 사과를 굉장히 혐오해요. 

그런데 사과를 보여주면 안 되잖아요. 

이런 개인적인 선호도까지 고려해서 필터링한 다음에 상품을 보여주게 돼요.

그러면 여기서 우리가 필요로 하는 것들을 묶어보면 크게 세 가지로 나눌 수 있어요.

첫 번째는 우리가 이 서비스를 사용하고 있는 사람의 개인적인 선호도. 

뭘 좋아하고 뭘 싫어하고 우리 홈페이지에 와서 뭘 행동을 했는지, 

뭘 샀고 뭘 봤고 이런 정보들이 하나 있을 거고 

또 하나는 이제 상품 정보인데 말 그대로 우리가 추천을 하려고 하는 대상이 있어야 되잖아요. 

이런 걸 다 뭉뚱그려서 상품이라고 할 게요.

적절하지는 않은데 사람이 될 수도 있어요. 

아이템의 관점에서. 그러면 그 상품에 대한 상품명, 재고량, 가격 이런 것들이 필요하게 될 것 같고.

그다음에 이제 관계나 유사도, 거리와 같은 

두 상품과 추천을 받고자 하는 객체 간에 관계를 정의할 수 있는 정보가 필요하게 돼요.

중간에 있는 관계에 대한 영역은 사실 굉장히 복잡해요. 

그런데 결과적으로 보면 이런 매트릭으로 표현할 수 있어요. 

바나나가 오렌지와 유사도가 0.83이다.

그런데 여기서 굉장히 많은 기술들이 들어가는데 그건 중요하지 않고요.

그래서 이걸 시스템 모양으로 조금 더 구성화를 하면 이렇게 될 수 있을 것 같아요. 

데이터베이스에 우리가 원하는 추천에 필요한 리소스들이 다 들어가 있다고 보고 

이걸 수집하는 영역이 크게 두 군데인 거예요. 

데이터 사이언티스트나 머신러닝 하시는 분들이 

우리가 추천하려고 하는 대상이나 아이템에 대한 분석을 통해서 

관계 유사도 거리 이런 걸 계산하는 영역이 있겠고요.

아래쪽이 그런 영역이고 

또 한 가지는 이 사람이 사고 좋아하고 싫어했던 정보를 수집해서 넣어주는 데이터수집 역할이 있을 거예요.

이 두 군데에서 데이터베이스를 구성해주고 있고 

우리가 이제 파이썬으로 제가 만들려고 했던 거는 

이 어플리케이션 서버 쪽인데 이쪽에서는 하려고 하는 게 이거예요.

어떤 사람이 과일추천에 대한 니즈가 있어요. 

그러면 그 요청을 받았을 때 스키마, 룰로 정의된 명사에 따라서 

추천결과를 제공해줄 수 있는 프레임워크를 만들고 싶었던 거예요.

그게 어플리케이션 서버이고 지금 예를 들자면 여기 지금 룰 스키마에 장보기, 과일추천이라고 되어 있는데 

장보기라는 서비스에 과일추천이라는 기능을 명시를 한 거예요.

그래서 이 추천을 할 때 이 사람이 디스라이크한 최근 5개를 빼주고 

그 다음에 스테이터스가 OK인 거, 아직 품절이 아닌 상품 20개를 해라, 하는 

어플리케이션 서버를 만들고 싶은 거죠.

그래서 이제 대충 그림이 나왔으니까 만들면 되잖아요.

그런데 이제 회사에 오면 항상 이런 질문에 봉착해요. 

이거 꼭 새로 만들어야 되냐.

그런데 항상 새로 만들자는 사람이 있고 항상 있는 거 쓰자는 사람이 있어요. 

항상 딜레마인데. 

그런데 사실 다 일리가 있어요. 

무턱대고 새로 만드는 게 좋은 건 아니죠.

그래서 조금 더 포멀하게 각 잡고 요구사항을 분석해보니까 

새로 만들지 기존에 있는 걸 쓸지를 알려면 우리가 좀 더 명확하게 요구사항 분석을 해야 하잖아요.

그래서 좀 더 분석을 해보니 이렇게 세 가지 영역에 대한 기능이 필요하다는 걸 알게 됐어요.

첫 번째로는 데이터베이스에 대한 기능이 필수적으로 필요하겠죠. 

지금 말씀드렸던 여러 가지 데이터들 우리가 메모리상에 적재할 수는 없어요. 

저희가 뒤쪽에 소개하겠지만 하루에 받는 쿼리가 수억 건이고 이벤트들이 수백 억씩 들어오거든요. 

말이 안 되죠.

그래서 이런 수평확장이 가능한 데이터베이스가 반드시 필요하게 되고요.

그리고 보통 OLTP라고 이 기능이 필요해요. 

그런데 이게 별 건 애

아니고 우리가 흔히 많이 쓰는 건데 뭐 두 개 이상의 테이블의 관계를 이용해서 

연산을 할 수 있는 그런 기능이라고 보시면 돼요.

좀 전에 재고처리 하는 거 보셨겠지만 그런 온라인, 그러니까 실시간으로 이런 프로세싱을 하게 되는 기능이 필요해요.

그리고 또 한 가지로는 실시간 분석 기능이 필요한데 

이게 OLTP랑 구별되는 점이 이건 데이터를 분석하고 단순한 거로는 해결이 안 되는 게 있을 수 있어요.

예를 들면 머신러닝을 실시간으로 처리할 수도 있잖아요. 

그리고 개인화 추천이 실시간 분석에 들어가는데 이건 뒤에서 좀 더 설명드릴게요.

혹은 굉장히 복잡한 비즈니스로직도 있어요. 

서비스 운영하시는 분들이 굉장히 섬세하거든요.

그러니까 저희가 질의로 표현할 수 없는 그런 사람만 알아 들을 수 있는 언어로 이런 걸 적용해달라고 이야기를 하는데 

그런 것들은 실시간으로 저희가 구현할 수밖에 없는 니즈들이 있어요.

이런 것들을 모두 무시할 수는 없기 때문에 반드시 필요한 영역이에요.

이 중에서는 실시간 분석쪽이 가장 중요한데 필터링이나 비즈니스 로직은 서비스 자체만으로도 중요한 거지만 

개인화추천이나 온라인 기계학습 같은 기능들은 추천 퀄리티를 위해서 필요한 거예요.

이것들이 잘 안 되면 우리가 속칭 이야기하는 스테이트오브디 아트라는 알고리즘들을 쓸 수가 없거든요.

그 대표적인 이유가 일단 스케일러빌리티인데 

아까 과일 추천 예제를 보여드렸을 때 

과일이 백만 개 정도면 어떤 과일이든지 그것과 우리가 추천하고 싶은 상품을 

백만 로우로 정의해서 DB에 저장해두면 되거든요.

그런데 사실 그것도 적은 거는 아니에요. 

100개씩만 해도 억 단위로 넘어가죠. 

그리고 그런 아이템 상품들이 시시각각 변하니까 

이런 관계도를 미리 계산해놓는 게 가능하지가 않아요.

그런데 개인화로 넘어오면 그게 더 심각해지는 게 서비스에 사용하는 사람들이 수천만 명이거든요. 

그리고 저희가 보여주고 싶은 아이템이 수백만 가지예요.

이 모든 조합에 대해서 추천결과를 미리 만들어놓고 

성향이 바뀌는 것을 계속 업데이트하는 것이 불가능해요.

이게 가장 큰 니즈예요, 사실. 실시간 분석의.

그래서 이런 요구사항 분석이 끝난 다음에 

그러면 외부에 나온 솔루션 중에서 우리가 쓸 수 있는 게 뭐가 있을까 찾아봤어요.

가장 만만한 게 mySQL인데 여기서는 스케일아웃이 쉽지 않은데 

데이터베이스로서의 의미가 없다는 게 아니라 

저희가 이야기하는 데이터베이스에서는 스케일아웃 같은 특징이 굉장히 중요했어요.

데이터가 너무 많이 뻥튀기가 되기 때문에 

그래서 이게 수평확장이 굉장히 안정적으로 스무스하게 일어나줘야 하는데 

마이스케일이 그런 점에서 아쉬웠고요.

OLTP 기능은 잘 되지만 실시간 분석 기능이 적용되지 않고요.

에이체에이스는 안정적인데 OLTP에서 일단 걸리고요.

어랑고DB는 얼추 잘 되는데 실시간 분석, 저희가 원하는 기능에 일부를 제공해줘요. 

그런데 너무 느려요.

당시에는 그랬고요.

디그래프라고 그래프 데이터베이스인데 좀 핫한 게 있어요. 

최근에 버전1이 넘어갔는데 저희가 벤치마킹 했을 때는 1 이하였어요.

그러다 보니까 쿼리 잘못 날리니까 DB가 죽더라고요. 

이거는 아니다 싶어서 접었고, 그런데 속도는 무난했어요.

네오포제이는 실시간 분석을 제공해주는데 일단 유료예요.

유료라서 여기서는 더 고려를 하지 못했고요.

결론적으로는 저희가 그냥 있는 거 쓰기에는 어려운 것 같다. 

이제 새로 만들기를 해야겠다.

그래서 대표적인 예제로는 실시간 분석이 필요한데 여기 지금 예제가 있어요.

예를 들어서 제가 저희가 이제 다양한 서비스에 추천을 적용했거든요. 

음악도 있고 웹툰도 있고 그래요.

제가 이말년 서유기를 좋아하는데 다른 사람들이 그걸 봤으면 좋겠는 거예요. 

그래서 두 번 정도를 첫 화면에 보여줬는데 이 사람이 안 봐요.

그러면 이말년의 서유기를 영영 지워버릴 수도 있거든요. 

그런데 이건 너무 가혹하다는 거죠. 

그래서 아래로 살짝만 낮춰주시면 안 돼요? 

이런 것들이에요.

그래서 이런 것들을 구현하려는 니즈가 있었고 

아까 말씀드렸던 대용량 개인화 추천, 온라인 기계학습 같은 기능을 실시간에 구현을 하자는 니즈.

그리고 속도랑 안정성 이야기는, 

그러니까 데이터베이스에서 OLTP 기능은 제공을 해주지만 그 기능을 다 사용하지는 않았어요.

일부는 저희가 따로 구현했거든요.

그러니까 DB별로 특장점이 있어요. 

어떤 DB는 빠른데 어떤 건 굉장히 느려요. 

말도 안 되게. 

그래서 이런 것들의 속도를 보장해주기 위해서는 

저희가 따로 만드는 게 좋겠다고 판단을 했었어요.

나머지는 확장성이나 안정성 완결성 이런 것들이 있는데 조금 더 중요한 게 완결성이에요.

저희가 추천 시스템을 만들어서 서비스에 팔러 다녀요.

우리 시스템 써달라고.

그런데 저희 시스템 API 이렇게 있고요. 

이거 호출하신 다음에 결과 써서 노출하시면 돼요. 

하면 안 써요. 왜냐하면 귀찮거든요.

그래서 이 API 한번 호출하고 그냥 바로 서비스에 노출하시면 돼요. 

이렇게 해야지 쓸까 말까 거든요.

그러니까 완결성 있는 결과를 제공해주기 위해서도 

어플리케이션 서버를 만드는 게 되게 중요했었어요.

그래서 이제 만들어보자고 결정을 했고 

저희가 집중하려고 했던 영역은 이 실시간분석 영역하고 

OLTP쪽의 성능을 최적화하는 게 핵심이었어요.

그리고 저희가 데이터베이스적인 요소를 개발하는 거는 능력외적인 영역이라고 봤고 

이것들은 그냥 잘 알려진 솔루션을 썼어요.

그래서 대충 이렇게 됐어요.

앞쪽에 로드밸런싱 관련된 L7스위치라든지 저희가 마라톤으로 서비스 스케일링을 하고 있어요. 

그래서 마라톤LB가 붙고요.

마라톤 앱 하나에는 저희가 보통 CPU 8개나 메모리 4기가 정도로 하나 가상머신 띄우고 

그 안에 이런 구성으로 앱을 올리고 있어요.

NGINX에 GUNICORN에 그 밑에 파이썬으로 작성된 프로세스가 몇 개 뜨고요.

여기서 이걸 동작하는 걸 보자면 이렇게 동작해요. 

누가 어떤 브런치라는 사이트에서 유사아티클을 보고 싶다는 요청이 오면 

이 앱이 룰이나 스키마 같은 걸 저장해놨어요. 

거기서 브런치에 시밀러에 해당되는 스키마를 건네주는 거예요.

그런데 만약에 정의되지 않은 그런 요청이 오면 404 에러가 나가는 거죠.

그래서 새로운 서비스를 만들고 싶으면 이 스키마만 계속 추가하면 돼요.

시스템적인 구성이나 이런 거는 나중에 궁금하시면 뒤쪽에서 질문 주시고요. 

여기서부터 할 얘기는 이제 이걸 만들면서 겪었던 포인트포인트 몇 가지에 대해서 공유드리려고 해요. 

이렇게 있어요.

7개인데 맞죠, 7개?

이 7개가 개발하면서 어? 했던 것들. 그런 것들. 아니면 좀 누구나 실수할 수 있을 법한, 

아니면 들으면 유익할 것 같은 내용들로 뽑아봤고요.

첫 번째 진부한 이야기이기는 한데 2냐, 3냐에 대한 이야기예요.

그래서 좀 더 정확하게 이야기하자면 토네이도를 쓰느냐, 

Sanic을 쓰느냐의 질문이었는데 사실 처음부터 고민할 건 아니었어요.

그런데 네거시가 있어서 이게 항상 발목을 잡아압수

그래서 얘를 좀 계산을 시킬까, 아니면 새로 만들까 고민했는데 결국은 3로 바꿨어요.

크게 두 가지 쟁점이 있었어요.

일단 코드가독성이 정말 좋아졌어요. 

그리고 전체 코드 량이 굉장히 줄었어요.

이거는 도큐먼트만 보셔도 감이 오실 텐데 사실 공평한 비교는 아니에요. 

왜냐하면 토네이도 쪽이 좀 더 로우레벨로 들어갈 수 있고 새닉은 좀 더 심플해요.

결과적으로 보면 이 코드를 보시면 되는데 일단 오른쪽이 토네이도고 왼쪽이 새닉이거든요.

그런데 지금 저는 2에서 비동기콜을 할 때 항상 굉장히 마음이 찝찝했어요. 

아니, 리턴을 하는데 왜 레이지를 하지?

이게 예외인가?

그러니까 뭔가 안 되는 걸 어거지로 하게 하려고 만든 듯한 느낌이 너무 드는 거예요. 

그런데 어떻게 해요? 하기는 해야 하잖아요. 

월급이 들어왔으니까.

(웃음)

그런데 안 돼요. 좀 이상해. 

그래서 지금 일단 코루틴 레코레이터가 붙는 것도 마음에 안 들었어요.

일드를 한다는 것도 사실 좀 직관적이지는 않았요. 

제너레이터인가, 이게? 개념적으로는 틀린 건 아니지만.

그런데 새닉으로 넘어오면 굉장히 우아해지죠. 

어싱크라는 것도 굉장히 직관적인 것 같아요. 

이게 비동기콜을 하는 매쏘드다.. 등등.

코드량도 그런데 더 직관적이에요.

그리고 토네이도 같은 경우는 한번 처리해주려면 헤더처리나 피니시 같은 것도 해줘야 하거든요. 

그런데 이런 것들은 사실 굳이 불필요하죠. 

저희 입장에서는.

이런 이유로 일단 바꿨고요.

또 한 가지 이유는 성능인데 새닉이 주장하는 게 

새닉 홈페이지 처음 들어가서 깃허브 홈페이지 처음 들어가보면 뭐 아티클이 있어요.

그런데 uvloop이 뭐냐 하면 

토네이도 같은 파이썬에 있는 비동기 웹 서버들이 흔히 쓰는 이벤트루프인데 얘가 굉장히 빨라요.

이걸 보고 나서 이걸 사용하면 새닉을 좀 빨리 만들 수 있지 않을까 해서 나온 게 새닉인데 

여기 링크 들어가 보시면 굉장히 압도적일 정도로 빨라요.

그런데 이 정도로 빨라진 건 아니고 

저희가 파이썬 2 버전으로 있던 토네이도로 짠 2버전을 3를 사용해서 똑같이 만들었어요. 

그런데 2배 이상 빠르더라고요.

물론 지금은 옵티마이즈가 돼서 비교는 어렵지만 지금 최소한 세 배 이상은 빠르지 싶어요. 

계속 갔었다면.

그래서 이런 이유로 저희가 3로 넘어왔고요.

그리고 3에 와서 비동기를 쓰다가 중요했던 지점 중의 하나가 

이 어싱크 Io를 어떻게 쓰는지에 따라서 성능차이가 많이 났다. 

되게 당연한 이야기일 수도 있는데 두 개의 역할이 똑같거든요.

지금 보면 어웨이트가 위에는 네 개, 아래는 세 개가 들어가 있는 것 같네요.

이게 두 개가 똑같아요. 하는 일은.

그런데 여기서 두 개를 다르게 썼거든요.

위쪽에서는 런하고 어웨이트가 동시에 일어나요. 

그래서 비동기콜을 순차적으로 쓰는 거거든요. 

이렇게 쓰면 리퀘스트간에 컨테스트 스위칭은 일어나서 그쪽에서는 효율화를 볼 수 있어요. 

어웨이트 걸리는 순간 다른 리퀘스트가 처리가 될 테니까. 

그런데 한 리퀘스트 안에서 전체 처리 시간은 거의 차이가 안 나요.

그런데 아래처럼 피쳐를 써서, 그러니까 서로 의존성이 없는 비동기콜을 동시에 날려버리고 

필요한 시점에 어웨이트를 걸어주면 병렬로 실행이 돼요.

그러니까 이런 식으로 하면 반 이상씩 리퀘스트 타임 속도를 줄일 수 있어요.

그런데 전체 자체가 확 드라마틱하게 개선은 안 되는데 

그래도 단일 리퀘스트에 대한 속도가 빨라지는 것도 의미가 있죠.

그리고 CPU 자원을 충분히 사용하지 못하는 상황이라면 이렇게만 해도 쓰루프도 많이 올라갈 수 있어요.

두 번째로 데이터베이스 프로파일링인데 이게 아까 OLTP랑 관련이 있어요. 

저희가 다 만들고 나서 파이썬 코드로 열심히 최적화를 했어요.

했는데 돌려서 프로파일링을 해보니까 대부분이 네트워크 IO인 거예요. 

사실. 이게 사실 바람직한 거예요. 

네트워크 프로그래밍 해보셨던 분은 알겠지만 옵티마이즈 잘 하면 결국 네트워크IO에 걸리거든요.

룰마다 추천기능의 복잡도가 달라요. 

엄청 복잡한 것들은 실시간 연산이 많이 필요하기는 해요.

그렇게 하더라도 왼쪽 같은 경우가 그런 경우인데 전체 시간의 32% 정도밖에 CPU를 안 써요. 

나머지는 기다리는 시간인 거예요.

그리고 대부분의 경우는 이렇게 99%가 네트워크IO예요. 

그래서 저희가 아, 이게 네트워크IO를 줄이는 게 

결국 가장 중요하구나 라는 걸 깨닫고 데이터베이스를 프로파일링을 했어요.

얘가 우리가 기대한 속도만큼 응답이 오는지를 프로파일링을 했는데 

두 가지 정도 사례를 공유를 드릴게요.

저희가 이제 몽고DB를 쓰고 있거든요.

이게 보면 aggregate라는 기능이 있어요. 

이게 순차적으로 실행할 수 있게 해주는 기능인데 

이 안에 연산 중에 $filter라는 게 있어요.

$filter는 직관적으로 보시면 아시겠지만 

아까 씨없는 포도 같은 경우에는 

품절이면 굳이 노출할 필요가 없으니까 메타 데이터를 가져온 다음에 거리는 방법이 있고 

애초에 조건절을 걸어서 거르는 방법이 있잖아요.

그런데 당연하지만 후자가 더 성능이 좋았어요.

그러니까 앱 서버에서 필터링을 하는 것 자체가 

CPU상에 리소스도 필요하고 데이터 넘어오는 양이 많아지잖아요.

그래서 DB에서 거른 다음에 가져오는 게 네트워크 양도 줄고.

그런데 이런 것들이 있어요. 

$group인데 이게 예를 들자면 이런 거예요. 

이 사람이 마지막에 봤던 상품 100개를 가져오고 싶어요. 

그런데 그 100개 중에서 여러 번 봤던 것도 있을 수 있잖아요.

그러니까 그룹파일을 하고 싶은데 DB에서 그룹파이해서 갖고 오니까 어마어마하게 느린 거예요. 

이건 어떻게 하면 DB의 특성일 수도 버그일 수도 있거든요.

이런 것들은 그냥 다 갖고 온 다음에 앱 서버에서 그룹파이 하게 하니까 훨씬 더 빠르더라고요.

이런 식으로 하나하나 해서 옵티마이즈 하는 게 필요하고.

하고 싶은 이야기가 이거예요. 

DB를 너무 믿지 말자. 

적절한 레벨에서 테스트를 한 다음에 그걸 직접 구현하는 것도 필요한 것 같아요.

그 다음에 캐싱인데 캐싱은 굉장히 중요하죠.

반복되는 이야기지만 저희가 데이터 엑세스 비용이 너무 크기 때문에 

이걸 최대한 줄이는 게 중요해요.

그래서 아까 아키텍쳐 보신 것 중에 레디스 서버를 쓰고 있는데 이게 로컬에 있어요.

로컬 서버에 하나가 더 있고 

GUNICORN 밑에 매달려있는 여러 개의 파이썬 프로세스들이 레디스를 쉐어하고 있어요. 

이렇게 쓰고 있고요.

이렇게 하는 것 중에 좀 필요한 니즈가 뭐냐 하면 저희가 다양한 추천 쿼리를 받아요. 

그런데 그 쿼리만 보면 거의 랜덤이에요. 

물론 핫한 컨텐츠는 있지만.

그런데 가만 보면 이 각각의 컨텐츠에 필요한 리소스들이 중복이 있어요. 

예를 들자면 이런 거예요.

바나나와 관련된 추천을 하고 싶은데 

여기에서 우리가 필요한 추천하고자 하는 컨텐츠 세 개는 토마토에 추천하는 세 개랑 비슷한 거예요.

그런데 사실 이거를 쿼리 레벨 옵티마이즈로 캐시로는 안 되거든요. 

쪼개야 돼요, 굉장히 세세하게.

그래서 이렇게 내부에서 필요한 메타데이터 하나하나까지 쿼리량을 줄이기 위해서 캐시적용을 했어요.

그런데 이게 프로세스 내에 임베디드 캐시로 적용하면 중복요청에 대해서만 캐시가 적용이 되는데 

인스턴스 내에 있는 프로세스들이 공유할 수 있는 레디스 하나를 쓰기 때문에 프로세스간의 중복요청도 처리가 되겠죠.

물론 이걸 인스턴스를 넘어서 클라우드로 구성할 수도 있어요. 

그런데 이건 캐시를 어느 레벨까지 두느냐인데 

저희는 일단 인스턴스 하나 내에서 쉐어하는 형태로 하고 있어요.

그리고 또 하나는 슈퍼노드 이슈가 있어요.

이거는 저희도 해보기 전에는 몰랐던 건데 DB를 좀 아시는 분은 익숙하신 얘기겠지만 

데이터베이스가 모든 데이터를 한 군데 저장하지는 않거든요. 

그래서 샤딩을 해서 샤드라는 개념으로 어느 정도 쪼개놓고 모든 리쿼스트들이 이게 퍼질 거라는 걸 기능해요.

그런데 이상하게 항상 1번 샤드가 항상 죽는 거예요. 

그래서 쿼리를 봤더니 쿼리에 이상한 특정 요청이 너무 많이 들어오나 봤더니 그것도 아니에요.

특별히 문제는 없어보이는데 항상 샤드1번으로만 리퀘스트가 2배 이상 가는 거예요.

꼼꼼히 봤더니 아까 이 이야기랑 비슷한데 되게 핫한 포도가 있는 거예요.

그래서 엄청나게 모든 과일에서 항상 나가는 포도가 있어요.

너무 유명한 거예요. 얘가.

그러니까 어떤 리퀘스트가 들어와도 이 포도 정보를 항상 가져가려고 하니까 

이 포도가 있는 샤드1번은 항상 죽으려고 하는 거죠.

또 다른 이슈는 추천이 항상 있지는 않아요.

사용자가 거의 뭐 억이 넘거든요.

그런데 그 모든 사용자들이 액티브 유저가 아니거든요. 

그러다 보면 가끔씩 방문한 유저들은 결과가 없어요. 

그러면 저희가 이 사람과 유사한 사람, 비슷한 추정연령대, 지역 이런 걸 활용해서 결과를 보여주거든요.

그런데 서울 인구의 30%가 콜드스타트라고 하면 

전체 쿼리의 30%가 콜드스타트 결과를 가져가려고 하는 거예요. 

이거는 쿼리 레벨에서 캐싱을 해서는 해결이 안 돼요.

그래서 내부에서 그런 슈퍼노드가 될 만한 포인트포인트에 다 캐시적용을 했어요. 

중복요청이 안 가도록.

사실 이런 것들은 외부 솔루션을 사용했으면 해결할 수 없는 문제들이거든요. 

안쪽에서 캐시를 되게 꼼꼼하게 적용해야 하는 것들이라.

그다음에 필터링인데 복잡한 필터링. 

이거는 사실 복잡한 건 아니에요. 

그런데 개념적으로 설명하기 쉬워서 넣은 예제인데 

아까 제가 바나나가 싫다는 저의 선호도가 있으면 DB에서 바나나 제거하면 되잖아요.

그런데 그 정도까지는 아니고 아까 이말년 서유기랑 비슷해요. 

계륵인데 아예 제거는 가혹하고 조금 미뤄주고 싶은 거예요.

이런 것들은 다 파이썬 앱에서 짰어요.

그래서 룰 스키마에 보면 필터스에 롤링이라고 있어요. 

롤링 기능을 툴을 해주면 이런 상품이 제거될 예정이었던 애들이 아예 없어지는 게 아니라 

그냥 뒤쪽으로 좀 넘어가져요.

그러면 항상 개수도 일정하게 보존할 수 있고 

패널티를 적용하는 역할도 할 수 있고 이런 걸 했는데.

그런데 대부분 다 돼요. 

식으로 만들어놨는데.

가끔 저희가 예상하지 못한 로직에 대한 요청이 들어올 때가 있어요. 

그러면 그걸 또 언제 배포해요? 

시간도 오래 걸릴 수도 있고 긴급할 수도 있고.

엄청 드물게 요청이 올 수 있는 케이스일 수도 있잖아요.

그런 경우에는 그냥 룰에다가 파이썬 코드를 심었어요.

그래서 룰에 파이썬 코드를 심고 온더플라이로 컴파일을 해서 로직에 적용했어요. 

아래쪽에 보면 람다 보이시죠?

그래서 필터를 골뱅이를 붙이면 그냥 저 부분을 파이썬 컴파일을 해버렸어요. 

이런 식으로 대응을 하도록 했고요.

그 다음에 설정배포인데 이제 당연한 이야기겠지만 

저희가 한번 서비스를 배포하고 나면 거의 설정만 바꿔요. 

스키마만 바꿔요, 룰만.

룰만 추가로 한다든지 룰 삭제를 한다든지 이런 것들인데 예를 들어서 이런 거예요.

브런치라는 서비스를 저희가 버켓테스트를 해요. 

일부는 A버켓, 일부는 B버켓에 결과를 보여주겠다는 거거든요.

이게 바뀌면 바뀐 내용을 전체 업데이트를 해줘야 하잖아요. 

그런데 이 마라톤 앱을 하나를 내렸다 올리는 거는 비용이 너무 커요. 

유실될 수도 있어요.

그리고 이 앱 안에 앱 하나하나 안에 들어가 있는 게 많기 때문에 시간도 좀 오래 걸려요.

이건 좀 그래서 말이 안 되는 것 같아서 이렇게 할 수가 있어요.

인스턴스 앱 안에서 앱을 그냥 하나하나 매뉴얼이 리스타트를 할 수 있어요.

프로세스 아이디 얻어오는 건 어렵지 않으니까.

그런데 이렇게 해도 결국은 유실이 돼요, 리퀘스트가.

그리고 시간은 매한가지로 오래 걸려요. 

인스턴스 내에 앱을 하나하나씩 리스타트를 해주고 시간 딜레이도 줘야 하니까 

저희가 인스턴스를 한두 개 쓰는 것도 아니고 이것도 별로고.

이래서 사실 GUNICORN를 쓰는 거죠. 

그래서 GUNICORN에 킬텀 시그넘을 주면 얘가 API 서버들을 하나씩 롤링 리스타트를 해줘요. 

굉장히 간편하죠.

그러면 인스턴스마다 GUNICORN에 킬시그널 한번씩만 날려주면 끝나요.

앱이 리스타트 되면서 룰 DB를 다시 물고 오니까.

그래서 이거는 GUNICORN에 들어가보면 확인하실 수 있고요.

다음으로는 퍼포먼스인데 저희가 이거를 만들어서 서비스에 넣은 지 좀 됐어요.

공격적으로 넣기 시작한 지는 1년 정도인데 

대충 하루에 3.5억 정도의 추천결과 요청이 들어와요.

대부분이 한 17ms 내로 나가고 0.3%가 100ms가 넘어가는 건데.

이게 하루에 대충 인서트가 10억 건 이상이 발생하고 있어요. 

이미 있는 결과에 대한 업데이트도 10억 건이고...

그리고 부하테스트를 해봤을 때 

단일 싱글쓰레드로 앱 서버 띄우고 20명 가상유저 붙어서 리퀘스트를 보냈을 때 

평균적으로 초당 300건 정도 처리하는 것 같더라고요.

데이터마다 필요한 것은 43k 정도 되고.

마지막으로 회사에서...

(웃음)

저희가, 우리 회사에서 가장 파이썬 많이 쓰는 부서거든요. 

저희 코드 레파지토리에 보면 99%가 파이썬이에요. 나머지 1% C++이고.

그런데 파이썬은 뭘 하려고만 하면 파이썬으로 그런 거 하는 거 아니래요. 

그럼 뭐 해야 되는지...

(웃음)

그런데 네트워크 코드가 문제지 파이썬 코드가 문제인 적이 없거든요?

물론 언어적인 취약성 때문에 이야기하시는 분들도 있지만, 어쨌든 일장일단이 있는 거고.

그런데 그런 분들이 하는 이야기들의 근거를 곰곰이 보면 외부 사이트에 의존을 해요. 

경험이 아니라. 

그래서 제가 이런 경험사례를 공유하면서 

여러분이 어디 가서 이런 똑같은 걸 파이썬으로 개발하고 싶을 때 레퍼런스 하셨으면 좋겠고요.

두 번째로는 같은 이야기인데 어플리케이션 서버에 병목이 대부분 네트워크 IO인 것 같아요.

지금 저희도 굉장히 헤비한 매트릭스 연산 이런 걸 하는데 심지어 딥러닝도 돌려요, 실시간으로.

그런데 CPU 연산 최적화만 잘하면 사실 별로 문제는 안 되는 것 같아요. 

언어의 문제는 아닌 것 같아요.

그래서 파이썬 많이 쓰셨으면 좋겠네요.

발표는 여기까지고요. 질문 있으면 질문 받겠습니다.