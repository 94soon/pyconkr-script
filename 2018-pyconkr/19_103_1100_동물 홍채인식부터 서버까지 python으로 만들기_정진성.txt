안녕하세요? 

일요일 아침부터 이렇게 저의 세션을 들어주러 오셔서 대단히감사합니다.

저는 동물 홍채인식부터 서버까지 발표를 맡은 정진성이라고 합니다.

반갑습니다.

그러면 발표 시작에 앞서 잠깐 저에 대해 소개드리겠습니다.

저는 현재 S전자 회사에서 소프트웨어 개발자로 일을 하고 있으며 파이썬은 접한지 2년 정도 되었습니다.

그리고 다다음 주면 저희 첫째 딸이 태어나고요.

저는 되게 동물들을 좋아합니다.

그래서 반려견도 키우고 있고 다른 동물도 좋아합니다.

이번 발표 내용은 회사하고는 전혀 상관없는 내용입니다.

개인 프로젝트로써 제가 회사 퇴근하고 주말에 계속 틈틈이 개발해서 만든 개인 프로젝트입니다.

그러면 오늘 발표 내용은 처음에 아이리스 리커그리션 발표 순서대로 진행하도록 하겠습니다.

그러면 이번 프리젠테이션 발표 목적은 파이썬으로 동물 홍채인식을 만든 경험을 여러분과 함께 공유하고자 합니다.

그러면 동물 홍채인식을 제가 왜 개발하게 되었고, 어떤 것인지에 대해서 간단하게 설명드리겠습니다.

제가 처음 동물 홍채인식을 만들게 된 계기는 몇 년 전에 집에서 환기를 시키려고 문을 열어놓은 적이 있었습니다.

그때 저희 집 강아지가 가출하였고 집에 있었기에 인식표를 하지 않았기 때문에 찾을 수 있는 방법이 없었습니다.

그래도 다행히 유기견 보호소에 연락해서 겨우 찾을 수가 있었습니다.

그렇지만 대부분 저처럼 반려견을 실수로 잃어버리거나 혹은 버려진 유기견들은 주인을 다시 만나는 일은 극히 드뭅니다.

그렇기 때문에 저는 IT로써 이러한 문제들을 해결해보고자 하여 반려동물 홍채인식를 개발하게 되었습니다.

반려동물의 홍채를 카메라로 찍어 이것을 신분증화해주는 것입니다.

그렇기 때문에 인식표나 다른 기타 신분을 입증할 수 있는 물건이 없더라도 주인을 찾을 수 있는 방법의 대안이 될 수 있을 것이라고 생각합니다.

그러면 홍채인식알고리즘을 설명드리기 전에 먼저 홍채의 특징에 대해서 알아보도록 하겠습니다.

사람의 눈은 아이리스 퍼필 스크렐라 세 부분으로구성이 되어 있습니다.

스크렐라는 보통 흔히 말하는 눈의 흰자라고 얘기할 수 있으며, 사람과 동물 모두 홍채가 존재합니다.

그리고 공막이 보이는 동물은 사람이 유일합니다.

한번쯤 개나 고양이 다른 동물을 보시면 흰자가 보이는 동물은 어떤 동물도 없을 것입니다.

그리고 홍채는 동공의 크기를 조절하는 근육의 문이면, 동공 주위의 근육이 수축과 이완을 통해 동공의 크기를 조절합니다.

빛의 세기에 따라 동공의 크기가 변하고 이에 따라 홍채의 면적도 변하게 됩니다.

가장 큰 특징은 변별성이라고 할 수 있는데 일란성 쌍둥이의 홍채가 다르고 좌우의 홍채도 다르다고 하는 것입니다.

홍채인식 알고리즘의 특징에 대해서 설명드리겠습니다.

홍채인식 알고리즘는 홍채 패턴을 인식하는 기술로써 홍채가 같을 확률은 수학적으로 10의 5승 분의 1입니다.

실제적으로 와닿지 않는 수치입니다.

10억분의 1 정도 가지고 있습니다.

줄어드는 이유는 데이터량이 많기 때문에 줄이기 위해서 저 정도 확률이 나오는 것으로 아를 고 있습니다.

그러면 오류 확률에 대해 보겠습니다.

홍채는 한쪽 눈이 10억 분의 1 정도의 오류 확률을 갖고 지문은 1000분의 1, 목소리는 0.1, 얼굴은 1.3% 오류 확률을 가지고 있습니다.

다른 생체인식과 비교해보아야 홍채인식이 변별력이 높습니다.

홍채인식만이 답이라고 저는 생각했습니다.

그러면 홍채인식 기술이란 누가 처음 발견했느냐 하면 런던의 존 버그너 교수가 세계 최초로 출현하였습니다.

아래와 같은순서로 되어 있습니다.

이미지를 획득하고 바이너리와 패턴 저장과 비교, 그리고 이것을 같은 사람인지 다른 사람인지 비교하는 디시젼 영역으로 구성됩니다.

이와 같은 순서대로 설명드리겠습니다.

제가 홍채인식을 하기 위해서 많은 논문을 봤는데 대부분의 많은 논문은 많은 수학적 공식으로 이루어져있습니다.

그래서 수학이 필수고 공식만 봐도 너무 어렵습니다.

대부분의 2차 적분, 미분, 행렬 등 다양한 수식이 존재하는데 다 이해하고 계산하고 코드를 구현것 조차가 너무 힘들었습니다.

그런데 제가 여러 가지 패키지를 찾던 도중에 OpenCV를 발견했었고 넘피라는 것도 있었습니다.

3.5.2, OpenCV 3.4 넘피 1.14로 개발하였습니다.

홍채인식을 개발할 때 특히 필요한 것이 카시야스 데이터베이스입니다.

홍채인식을 하게 되면 실제로 잘 구현되었는지 테스트하기 위해서는 홍채 이미지가 필요한데 중국의 카시야스라는 생체기술연구소가 있습니다.

거기에서 홍채 이미지, 지문, 여러 가지 생체정보에 대한 데이터베이스를 제공하고 있습니다.

저도 동물에 대한 홍채 데이터베이스가 없었기 때문에 우선 사람으로 먼저 구현하자고 하였고, 카시야스 데이터베이스를 이용하여 테스트를 하였습니다.

그러면 간단하게 OpenCV에 대해서 설명드리겠습니다.

OpenCV는 게리브리드스키에 의해 1996년 인텔에서 시작된 프로젝트며 다양한 알고리즘 지원과 C++ 자바 등의 다양한 언어로도 지원되고 있습니다.

거의 C++과 같은 성능을 내고 있습니다.

그리고 넘피는 수학연산을 위해 최적화된 라이브러리이며 행렬연산을 쉽게 할 수 있도록 도와줍니다.

아래 코드는 간단하게 OpenCV로 홍채 이미지를 읽어드리고 프린트문으로 출력해본 것입니다.

럼피 행렬에 다음과 같은 각 픽셀에 대한 크기값이 저장되어있는 것을 확인할 수 있습니다.

그러면 본격적으로 알고리즘에 대한 설명을 드리겠는데, 알고리즘을 진행하기 전에 처음에 노이지팩터리부터 진행해야 합니다.

다양한 노이즈들이 존재합니다.

다양한 노이즈는 이미지처리하는 데 있어서 방해요소가 됩니다.

그래서 노이즈 필터링을 통해 성능을 향상시킬 수 있습니다.

OpenCV에서는 다수의 필터를 제공하는데 그중에 홍채인식에 사용될 픽터는 솔드 앤 페이스트 노이즈.

미디엄 필터는 다음과 같은 파라미터를 가지고 있습니다.

K사이즈라는 3바이3행렬값을 집어넣어야 하고 홀수값을 가져야 합니다.

OpenCV왼쪽 그림이 솔드 앤 퍼페 이미지가 있는 이미지입니다.

이 이미지에서 미디어페퍼를 하게 되면 OpenCV 무늬와 마크만 남게 됩니다.

그러면 홍채에 실제로 적용하면 오리지널 이미지에서 K사이즈를 21로 주어 적용하게 되면 동공 주위에 보이는 흰점들이 거의 사라지게 됩니다.

그리고 뚜렷한 동공의 형태만 남게 되기 때문에 동공검출을 좀 더쉽게 할 수 있습니다.

그러면 로컬라이제이에 대해서 말씀드리겠습니다.홍채영역에서 동공의 영역을 뺀 부분이 순수한 홍채 영역이라고 할 수 있습니다.

아래 그림과 같이 실제로 이 동공만을 분리해서 홍채 영역만 추출해서 사용하게 됩니다.

동공은 경계가 굉장히 분명합니다.

그렇기 때문에 찾기 쉬운 편입니다.

노이즈필터링에서도 보셨듯이 노이즈필터링을 적용하게 되면 동공의 경계를 제외한 나머지노이즈는 많이 사라지는 것을 볼 수 있었습니다.

그리고 동공을 찾기 위해서는 OpenCV에서 제공하는 허프서클이라는 함수를 사용하게 됩니다.

허프서클은 다음과 같은 여러 파라미터를 갖고 있으며, 여기에서 주목해야 할 것은 민디스턴스, 그러니까 검출한 원의 최소거리입니다.

이 값이 작으면 많은 원이 검출되고 크게 되면 자기가 원하는 원이 검출되지 않을 수 있습니다.

그렇기 때문에 적절한 값을 주셔야 합니다.

엣지디텍션을 하기 위한 것인데 이 값 또한 적절한 값을 주셔야 합니다.

작은 값율 주게 되면 너무 많은 엣지가 검출되면 너무 큰 값을 주면 저희가 원하는 엣지가 나오지 않을 수 있습니다.

그리고 파람2도 적절한 값을 주셔야 하는데 이 값은 검출된 원이 맞는지를 판단하기 위한 카운팅 값입니다.

이 값 또한 많이 주시면 어느 정도 검출된 원이 맞는지 단하고 그리고 저희한테 실제 반환되는 원들의 숫자가 줄어들게 됩니다.

그리고 Min라이언스라는 것은 원의 최소반지름, Max라디언스는 원의 최대반지름을 얘기합니다.

동공을 찾는 코드를 첨부해놨습니다.

앞에서도 계속 누누이 강조해드렸는데 적절한 파라미터 밸류를 주는 것이 중요하고요.

찾는 것은 이미지를 분석하고 특징을 찾으셔야 합니다.

즉 받아들이는 이미지의 눈 사이즈도 다르고 다른 여러 가지 특성이 있기 때문에 이런 값들을 잘 분석하시고 실제로 파라미터를 넣어주셔야 합니다.

코드상에서는 저희가 미디엄필터를 이용할 때는 7을 주었고요.

원간의 최소거리는 100, 70, 반지름과 맥스반지름은 20에서 40을 주었습니다.

이렇게 해서 검출하면 동공만 검출되게 됩니다.

그러면 홍채는 어떻게 구현하느냐.

홍채는 동공보다 경계가 뚜렷하지 않습니다.

그래서 구하는 데 어려움이 많습니다.

그렇지만 적절한 파라미터 값을넣어주고 허프서클을 넣어줘서 찾을 수 있습니다.

아래 이미지는 카메라로 영상을 받아들여서 프레임별로 테스트를 하였고 거기에서 동공과 홍채를 찾았습니다.

카시야스 이미지 5200장 기준으로 하였을 때 99% 검출률을 가지고 있습니다.

그리고 이미지 파일네임에 있는 HDistance 소수점자리의 값은 헤밍 값이고 이것은 본인이라고 판단할 수 있는 근거가 됩니다.

그다음에 Normalization에 대해서 말씀드리겠습니다.

앞에서 허프서클을 통해 홍채영역의 중심좌표와 반지름을 구했고, 2000배열로 Normalization 하는 것을 얘기합니다.

즉 한마디로 말씀드리면 원으로 되어 있는 부분을 직사각형화해서 이차원 배열에 저장하는 것입니다.

맨왼쪽 상반 이미지가 원본입니다.

공식 이미지인데도 불구하고 330과 300의 순서가 바뀌어 있습니다.

최근 문서에는 바뀐 것을 며칠 전에 확인하였습니다.

그래서 OpenCV에서 제공하는 리니어폴라함수를 이용하면 왼쪽과 같은 이미지를 넣고 오른쪽에 보이는 화살표, 반지름 길이를 넣어줘서 변환하게 되면 좌측 하단에 있는 이미지와 같이 결과가 반환됩니다.

여기에서 왼쪽에서 보이는 값은, 왼쪽에서 약간 굴곡처럼 보이고 파란색은 중첩이 되어서 생기는 왜곡 현상입니다.

그런데 앞에서도 왜곡 OpenCV에서 제공하는 함수도 왜곡현상이 있었는데 이는 실질적으로 수학적으로도 고칠 수 없는 것 같습니다.

그런데 이것보다도 더 큰 문제가 있었습니다.

OpenCV에서 사용하는 리너폴라함수가 반환되는 결과값은 저희가 넣어준 반지름 크기만큼의 원이 직사각형화되는 것이 아니라 원본 이미지크기 그대로 반환되는 것입니다.

오른쪽과 같이 똑같은 크기로 반환되기 때문에 늘어진 형태로 되고 이는 엄청난 왜곡을 발생시키게 되었습니다.

그렇기 때문에 저는 어쩔 수 없이 OpenCV 함수를 이용하지 않고 다시 재구현하였습니다.

왼쪽과 같이 왜곡이 적은 함수를 만들 수 있었습니다.

그러면 이것을 실제 홍채인식에, 홍채이미지에 적용해봤습니다.

아래 디텍션 이미지는 홍채이미지의 노이즈필터링을 하여 블러링 효과를 준 것이고, 거기에서 동공과 홍채를 검출하였습니다.

이것을 이니어폴라로 적용하면 오른쪽같이 구현할 수 있습니다.

눈썹과 눈꺼풀을 제거해줘야 하고 동공은 제가 따로 잘라낸 이미지입니다.

이렇게 홍채 영역을 구하면 여기에서 특징을 추출해야 합니다.

특징은 픽셀의 크기값이 아닙니다.

픽셀의 크기값은 빛이나 다른 외부 영향의 요인으로 바뀔 수가 있기 때문에 이는 특징으로 사용할 수가 없습니다.

그렇기 때문에 홍채의 무늬, 즉 방향의 페이즈를 추출하는 것입니다.

추출 방법에는 2D 가봇필터, 레이블릿을 이용하는 것입니다.

앞에서 설명드린 더그너 박사가 이용한 것입니다.

OpenCV에서 제공하는 함수는 따로 없습니다.

그렇기 때문에 직접구현하셔야 하고 아래 이니어폴라된 이미지를 통해 변환하게 되면 오른쪽과 같이 방향 특징을 구할 수 있습니다.

대부분 실제 럼피에 저장되는 값이 복소수입니다.

즉 아날로그 값이라고 볼 수 있습니다.

그렇기 때문에 저장과 비교를 위해서는 바이너리로 변환해야 합니다.

혹시 퀀타이제이션이라고 아시는 분도 있을 것이고, 모르시는 분도 있을 텐데 레벨을 설치해서 어느 일정 범위 내에 들어오면, 예를 들면 뒤에서도 설명드리겠지만 1.5라는 값이 들어오고 레벨을 1에서 2사이라고 하면 이것은 앞에서 지정한 레벨 1이 되는 것이고, 2.1에서 3사이의 값으로 들어오면 레벨 2라고 하면 이 범위 안에 있는 값은 레벨2가 되는 것입니다.

그래서 더그만 박사는 아래 그림과 같이 360도를 4분면하여 2개의 비트를 이용하여 컨타이제이션을 진행하였습니다.

실제로 하는 것은 오른쪽 코드와 같이 쉽게 구현할 수 있습니다.

밸류값의 복소수값을 넣어주고 아래 간단하게 구현하면 오른쪽과 같은 결과를 얻을 수 있습니다.

그러면 실질적으로 여기까지 특징을 구하고 바이러니화까지 시켰으면 들어오는 이미지가 본인인지, 아니면 다른 사람인지 어떤 사람과 매칭이 되는지를 비교하기 위한 방법으로는 해밍디스턴스라는 것을 이용합니다.

같은 비스턴스를 갖는 일치하지 않은 것의 개수입니다.

각 비트끼리 간단하게 구현할 수 있습니다.

A와 B는 약 3개의 비트가 다릅니다.

즉 해밍디스턴스는 3이라고 볼 수 있습니다.

아래와 같이 간단하게 구현하실 수 있습니다.

그러면 앞에서 설명안 드렸던 부분이 이미지 캡처에 대한 부분이었습니다.

솔직히 약간 파이썬하고 관련이 없을 수 있지만, 홍채인식에 관심 있는 분들에게 좀 알려드리고자 부록으로 편성하였습니다.

그러면 홍채인식을 하기 위해서는 카메라를 선정해야 합니다.

실질적으로 하드웨어로 이미지를 받아들이고, 받아들인 이미지로 홍채인식 알고리즘를 처리해야 하는데 저 같은 경우는 실시간 영상으로 받아들일 수 있도록 구헌하였습니다.

현재 쓰고 있는 핸드폰 카메라나 일반 카메라는 빛반사가 생기기 때문에 홍채 촬영이 어렵습니다.

그래서 적외선 카메라가 필요합니다.

그리고 저의 경우에는 카메라 화소, 센서 크기, 시그널과 노이즈 조건에 따라 6개의 적외선 카메라, 20개의 렌즈를 조합해서 테스트를 하였고, 초근접거리 5cm부터 35cm 내에서 자유롭게 테스트를 해봤고, 그리고 제가 가장 적절하다는 거리와 최적의 카메라를 찾아서 구현하게 되었습니다.

그러면 이미지캡처는 솔직히 얘기해서 홍채인식 기술에서도 가장 핵심이라고 할 수 있고, 대부분 홍채인식 회사에서도 이 부분이 핵심기술이라고 할 수가 있습니다.

왼쪽의 이미지는 카시야스 데이터베이스에 있는 하나의 이미지이고 이 이미지 같은 경우에는 굉장히 깨끗하게 잘 찍힌 이미지입니다.

오른쪽 이미지는 제가 찍으면서 흔들리고 초점이 없고 그런 되게 안 좋은 이미지입니다.

그러면 좋은 이미지란 블러가 없고 초점이 잘 맞고 이미지안에 동공과 홍채가 찍혀 있는 이미지입니다.

왜 좋은이미지를 얻어야 하느냐 하면 좋은 이미지를 얻는 것은 오인식률을 낮출 수 있습니다.

나쁜이미지는 엉뚱한 원으로 계산하면 서버에 대한 부하를 줄 수 있고 자원낭비가 될 수 있습니다.

좋은 이미지를 얻는 것을 통해서 정확도를 올릴 수 있습니다.

그렇기 때문에 실제로 저도 많은 플랜 중에서 하나의 좋은 이미지를 캡처해서 서버에서 계산하게 됩니다.

좋은 이미지의 3요소 중의 저는 블러 디텍션만 말씀드리겠습니다.

블러 디텍션만 말씀드리는 것은 초점이나 이런 부분은 제가 특허로 낼 예정이라 공개가 좀 어렵기 때문에 블러 디텍션만 말씀드리겠습니다.

블러 디텍션이라는 이미지의 흐림이 있는지 없는지를 판단하는 방법입니다.

라플라 함수가 OpenCV에도 존재하는데 가로세로에 대한 기울기를 2차미분한 값이면 엣지를 검출하는 데 사용합니다.

라플라시아 밸류가 클수록 선의 경계가 뚜렷하고 블러가 적은 이미지라고 판단할 수 있습니다.

왼쪽에 있는 블러리 값은 197이고 이미지가 딱 보셔도 흐린 것이 보입니다.

그리고 오른쪽 이미지는 좀 더 선명한 이미지입니다.

이것은 블러 값이 라플라시아밸류가 268로 제가 설정한 200을 넘고 있습니다.

그런데 주의하셔야 할 점이 있습니다.

제가 그림판으로 이렇게 간단하게 선 을 하나 그었는데도 불구하고 값이 1800이라는 엄청 큰 수치가 나왔습니다.

즉 라플라시안밸류는 이렇게 직선이나 강한 선이 있으면 높은 값을 반환하기 때문에 라플라시안밸류를 이용한 디텍션만 이용하면 안 된다는 것입니다.

즉 다양한 알고리즘을 같이 적용하여 이것이 좋은 이미지인지 또 블러가 없는지를 판단하셔야 합니다.

그러면 이제 홍채인식을 처리해주는 에이전트 서버에 대해서 설명드리겠습니다.

지금 현재 프로토타입은 제가 이런 아키텍쳐를 갖고 구성하였습니다.

여기에서 클라이언트는 에이전트와 앱, 웹이 있고 이들은 다 통해서 연결되고 있습니다.

좀 더 부연설명드리면 옙 웹 에이전트는 클라이언트며 각각에 하는 역할도 다르고 접근하는 방법도 다르기 때문에 여기에서 통신하도록 하였습니다.

그리고 리커즈시션이라는 서버는 홍채인식 알고리즘이 돌아가기 때문에 CPU 작업이 많아 서버를 따로 분류하였습니다.

그리고 라이트리드 성능이 좋은, 그리고 유저 서버에서는 유저의 관리, 홍채정보 검색 등의 역할을 하고 있습니다.

저는 이 아키텍쳐를 크게 마이크로 아키텍쳐로 가기 위한 구성으로 삼고 현재 프로토타입을 만들고 있는 중입니다.

그러면 여기에서 사용된 패키지는 서버에서는 크게 장고, 몽고DB, 그리고 로고포 몽고라는 것과 폼넘버슬라이트라는 패키지를 사용했습니다.

맨 아래 있는 패키지는 뒤에서 설명드리겠습니다.

참고로 파이 3.1.2이 최선 버젼일 텐데 5.10.1 버전이 지원이 안 되고 있습니다.

그러면 에이전트는 USB 적외선 카메라로 이미지를 얻기 위한 프로그램이고 아래와 같이 베타 버전을 만들었습니다.

그리고 실제 버전에서는 로그인 뷰와 메인뷰로 구성하였고 메인뷰로는 카메라 화면과 정보 입력 및 출력창을 사용하였고 입크립션을 진행하였습니다.

그리고 같은 뷰에서 보여주도록 큐스레드와 OpenCV 통신을 할 수 있도록 하였습니다.

DB스키마는 이와 같은 방식으로 장고를 커스텀하여 사용하였고 폼넘버필드라는 것이 앞서 얘기드렸던 패키지를 이용하여 폼넘버를 벨리데이션하는 부분입니다.

그리고 에니멀모드라는 것이 있는데 동물에 대한 정보라도 전달하고 유저와 연결하였고, 바이어메트릭트 아이디라는 부분이 굉장히 중요한 부분입니다.

이 부분은 몽고DB에 실제 생체정보가 저장되고 원톤 필트로 구성을 하였습니다.

그러면 생체정보는 몽고DB에 저장되는데 몽고DB에 저장하게 된 이유는 Write/Read 속도가 SQL보다 빠르고 AB다 구분이 안 되기 때문에 모든 데이터를 다 불러와서 1:N으로 구분해야 합니다.

스키마가 자유롭기 때문에 동물의 정보가 명확하게 기획되지 않았기 때문에 몽고DB를 사용하게 되었습니다.

그래서 아래 바이어매트릭스에 보시면 실제로 들어가 있습니다.

그리고 앞에서 말씀드렸던 로고폼패키지를 사용하면 파일이 아닌 몽고DB에 저장할 수 있게 사용할 수 있습니다.

아래와 같이 몽고DB 라이브러리를 제가 만든 부분인데 저기에서 저 부분을 보시면 실제 몽고DB 아래와 같이 에러가 저장이 됩니다.

그런데 여기에서 한 가지 문제는 로고폼몽고라는 것이 시스템 서버가 시스템을 시작하거나 리부트되었을 때 연결되어 있지 않으면 커넥션을 뿜어내지 않습니다.

그렇기 때문에 제가 다시 오버라이딩해서 이 부분을 수정하였고 만약에 연결안 되면 파일을 쓸 수 있도록 코드를 수정하였고요.

이 전체 코드를 아래와 같이 삽입해놨습니다.

그러면 이제 마지막 부분인데요.

실제 앞에서 구현한 것들을 동물 홍채인식에 어떻게 적용했는지에 대해 말씀드리겠습니다.

제가 저의 집 강아지를 데리고 수천 장의 사진을 찍었습니다.

멀리서도 찍고 카메라별로 다양하게 테스트했습니다.

찍고 알아낸 것은 동물은 사람과 좀 다른 홍채와 동공을 갖고 있어서 어렵다는 것이고.

그래서 그러나 저는 새로운 알고리즘을 다시 개발하여 적용했습니다.

실제 저희 집 강아지를 찍었을 때 실제 동공과 홍채를 구분해줍니다.

아래 있는 그림이 저희 집 강아지인데 엄청난 사료와 간식을 바쳤습니다.

그러면 한번 실제 시연하는 영상을 보여드리겠습니다.

저희 집 강아지가 좀 잘 움직여서요.

이렇게 이미지를 초점이 맞으면 바로 찾게 되면 이렇게 이미지를 캡처해서 Normalization까지 다 해서 이렇게 나오게 됩니다.

저는 아직 많은 수의 개를 반려견들을 테스트하지 못했습니다.

아직 해외에서 연구사례도 크게 없습니다.

실제 제가 알고 있는 바로 제가 거의 홍채인식 동물 쪽에서 처음으로 한 것으로 알고 있고 그리고 반려견이 움직이지 않으면 5에서 10초 정도 인식하였고 DB는 계속해서 구축할 예정입니다.

그래서 마지막 결론은 반려견도 홍채인식이 가능하다는 것과 파이썬으로 할 수도 있었고, 그래서 결론은 더욱 더 열심히 파이썬을 하자는 것입니다.

동물 홍채인식에 관심 있으신 분은 아래 메일로 연락주시면 되겠습니다.

이상입니다.

감사합니다.