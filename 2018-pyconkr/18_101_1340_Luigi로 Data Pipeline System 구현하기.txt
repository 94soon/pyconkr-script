https://www.youtube.com/watch?v=UOunv9V14cA

안녕하세요? 네, 'LUIGI로 DATA PIPELINE SYSTEM구현하기' 라는 주제로 말씀드릴 송은우라고 합니다.

오늘 제가 여러분께 말씀드릴 내용은요. 

제가 현재 다니고 있는 트루쇼트라는 회사에서 데이터파이프라인 시스템을 구현할 때 

처음에는 파이썬스크립트와 크론탭으로 간단하게 시작했다가 여러 문제를 겪으면서 

그런 문제를 LUIGI라는 프레임워크를 사용하면서 어떻게 해결했는가 하는 이야기를 오늘 여러분께 드리려고 합니다.

저는 앞서 간략하게 언급드렸듯이 트루쇼트라는 핀테크 회사에서 CTO로 현재 일하고 있습니다. 

그래서 본 주제를 말씀드리기 위해서는 저희 트루쇼트가 어떤 서비스를 제공하는 회사이고 

왜 데이터파이프라인 시스템을 필요로 했는지에 대한 배경설명을 간략하게 드려야 할 것 같아요.

저희 트루쇼트는 주식정보분석서비스를 제공하는 회사입니다.

주식정보 중에서도 특히 공매도 정보를 제공하고 있는데요.

이 공매도에 대해서 잘 아시는 분들도 있으실 것 같고 또 생소한 분들도 계실 것 같아요.

공매도는 간단하게 설명드리면 이름 그대로 없는 주식을 매도하는 게 공매도입니다.

그런데 그렇다고 해서 없는 주식을 허위로 매도하는 건 아니고요. 

실제로는 다른 사람에게 주식을 빌려서 매도하는 게 공매도입니다.

그러면 왜 그렇게 하느냐 하면 공매도는 어떤 주식이 가격이 앞으로 내려갈 것이라고 예상될 때 사용하는 투자전략이에요.

그래서 예를 들어서 어떤 주식이 현재 가격이 5만원인데 앞으로 더 가격이 떨어질 것 같다고 생각을 한다면 

다른 사람에게 그 주식을 빌려서 현재 5만원을 곧바로 텁니다.

그리고 그 주식이 가격이 만원으로 떨어지면 되사요.

그래서 주식을 빌려준 사람에게 다시 갚습니다.

그러면 빌려서 5만원에 팔았는데 1만원에 다시 받았으니까 4만원의 차액을 얻게 되는 거죠.

이렇게 주식의 가격이 떨어질 것이라고 예상하고 사용하는 전략이 공매도인데요.

저희는 이런 공매도 전문 분석 데이터를 제공하고 있고요.

이러한 데이터들을 제공을 하기 위해서 파이프라인 시스템을 구축해야 했습니다.

ETL에서는 많은 분들이 알고 계실 텐데요. 

저희 트루쇼트도 다양한 데이터소스에서 주식정보, 그리고 공매도 정보들을 취합을 해서 그 취합한 정보들을 분석을 하고 가공을 합니다.

그리고 이렇게 분석하고 가공된 데이터들을 저희 데이터 웨어하우스에 저장을 해서 

저희 사이트, 그리고 플랫폼을 통해서 제공을 하게 되는 거죠.

그런데 스타트업에서 일해보셨거나 이미 일하고 계신 분들은 잘 아실 텐데 항상 속도가 중요하잖아요.

최대한 빨리 개발해서 최대한 빨리 서비스를 제공하는 것이 굉장히 중요하기 때문에 

저희도 개발속도가 굉장히 중요해서 처음에 ETL 파이프라인으로 구현할 때는 간단하게 그냥 시작했어요.

그런데 사실 처음에는 단순한 파이썬 스크립트, 그리고 크론탭만으로도 충분했습니다.

왜냐하면 ETL 구조가 그렇게 복잡하지가 않아요. 

단순하게 필요한 기본 데이터들을 먼저 취합을 하고요.

그리고 그 취합한 데이터들을 분석을 하고 가공을 하고 그리고 그렇게 분석하고 가공된 데이터들을 저장을 해서 저희 플랫폼에서 제공합니다.

그래서 별로 복잡하지 않아요. 

그래서 단순한 파이썬 스크립트로도 충분히 구현이 가능했습니다. 

그리고 이 ETL 스크립트를 제가 원하는 시간과 날짜에 주기적으로 실행될 수 있도록 크론탭으로 스케줄링만 해주면 됩니다.

그래서 사실은 어려운 게 하나도 없을 것 같아요.

그런데 저희 시스템의 규모가 커지고 저희가 받아오는 데이터의 양이 많아지고 

데이터의 종류가 다양해지면서 많은 문제들이 생기기 시작했습니다.

그중에 가장 큰 문제가 저희가 받아오는 데이터 외부 소스가 다양해지다 보니까 

더 이상 저희가 원하는 데이터를 동일한 시점에서 다 받아올 수가 없는 거예요.

각각 데이터 외부 소스가 다르고 데이터 종류가 다양해지니 데이터가 준비되는 시점이 다 달라지게 되거든요.

예를 들어서 공매도 거래에 대한 데이터는 오후 4시 반에 준비가 된다고 하면 

공매도 잔고량 데이터는 그다음날 9시 반에 준비되는 식입니다.

그러다 보니까 각각 데이터마다 그 데이터를 받아오는 스크립트들을 개별적으로 다 따로 만들고 

개별적으로 컨택해서 따로 스케줄링을 해야 합니다.

그렇게 데이터를 받아오는 스크립트들이 개별적으로 나눠지고 

스케줄링이 따로 되다 보니까 가공하는 것도 다 개별적으로 해야 하고 해요.

그러다 보니까 ETL 스크립트들이 수가 굉장히 많아지고 또 크론탭 구조가 굉장히 복잡해지기 시작했습니다.

그래서 조금 더 자세히 설명드리기 위해서 저희 플랫폼에서 실제로 제공하는 데이터를 예를 들어서 저희가 설명을 해드릴게요.

저희 사이트에서 제공하는 데이터 중에 TS스코어 랭킹이라는 게 있어요.

이 TS스코어는 간단하게 설명드리면 공매도 점수라고 생각하시면 돼요.

그래서 이 TS스코어가 높으면 해당 주식은 공매도가 활발하게 이루어지는 주식이고요.

TS스코어가 낮으면 활발하게 이루어지지 않는 주식이라고 생각하시면 됩니다.

그래서 저희는 이 데이터를 제공하고 또 순위를 매겨서 또 제공을 해요.

그래서 가장 공매도가 활발한 주식들의 순위를 제공하는데 

이 TS스코어 랭킹을 계산하기 위해서 먼저는 기본이 되는 데이터들을 다 받아야되고요.

그리고 이 데이터들이 다 받아지면 그다음에 분석을 해야 됩니다.

분석하고 계산하고 가공을 하고 그리고 그 가공된 데이터들을 저장을 하게 되는 그런 구조입니다.

그런데 앞서 말씀드렸다시피 이 기본 데이터들이 각자 준비되는 시점이 다르다 보니까 

각각 그 데이터들을 받아오는 스크립트를 개별적으로 짜고 또 개별적으로 스케줄링을 해야 돼요.

그래서 이 TS스코어랭킹의 작업을 하기 위해서는 먼저 크론탭에서 필요한 기본데이터들을 받는 스크립트들을 

각각의 시점에 맞춰서 시간순으로 스케줄링을 해야 됩니다.

그래서 이렇게 기본데이터 패치를 하는 스크립트들을 시간순으로 스케줄링을 하고요.

그리고 맨 마지막에 모든 필요한 기본 데이터들이 다 받아졌을 거라고 예상되는 시점에 

이 TS스코어랭킹을 계산하는 스크립트를 스케줄링을 해서 실행을 하게 됩니다.

그러면 이론적으로는 이 마지막 스크립트, TS스코어랭킹 스크립트가 실행되는 시점에는 필요한 기본 데이터들이 다 받아져있어야겠죠.

그 전에 스케줄링을 해서 실행을 시켰으니까.

그래서 지금 보시는 코드가 실제 TS스코어랭킹을 계산하고 가공하는 스크립트인데요.

이미 말씀드렸다시피 이 스크립트가 실행될 때쯤에는 이미 기본데이터들이 다 받아져있어야 되니까 

그냥 단순히 먼저 필요한 기본데이터들을 로드를 하고요. 이미 다 받아져있을 테니.

그리고 그 기본데이터들을 가공하고 분석을 하고요.

그리고 가공되고 계산된 데이터를 그냥 파일에 저장하고.

이게 굉장히 아직까지는 단순한 구조예요. 큰 문제가 없어보이고 별로 복잡할 것 같지않아요.

그런데 이렇게 단순한 로직으로 실행하면 큰 문제가 생깁니다.

어떤 문제가 생길지 감이 오시나요?

저희가 여기서 가정했던 것은 이 스크립트가 실행되는 시점에는 필요한 기본 데이터들이 이미 다 받아져서 

준비가 됐을 거라고 가정을 했는데 사실은 그게 굉장히 큰 가정이었던 겁니다.

사실은 데이터들이 준비가 안 되어 있을 가능성이 꽤 있어요.

그 이유는 이 데이터들이 외부소스에서 받아오기 때문에 저희가 예상치 못한 문제점들이 많이 생길 수 있습니다.

예를 들어 외부 데이터소스 시스템에서 에러가 났을 수도 있고요.

그리고 그냥 단순히 데이터가 준비되는 시점이 지연됐을 수도 있어요.

특히 금융데이터 같은 경우에는 여러 변수들이 있을 수 있기 때문에 

예를 들어 오후 4시 반에는 준비가 되어야 하는데 1시간 지연되어서 

5시 반에 준비가 되거나 심하면 다음 날에 준비되는 경우가 꽤 있습니다.

그런데 저희가 이 스크립트가 실행될 시점에는 이미 데이터가 다 준비되고 

우리가 우리 시스템으로 다 받았을 거라고 가정을 하고 시행을 했기 때문에 

만약에 데이터가 필요한 데이터 중에 하나라도 준비가 안 되어 있으면 이 스크립트는 오류가 나게 되는 거죠.

그래서 어쩔 수 없이 메인 로직을 실행시키기를 전에 

필요한 데이터들이 준비가 되어 있는지 하나하나 체크를 해줘야 돼요.

그래서 메인로직에 의존하는 디펜던시들이 준비가 되어 있는지 체크해줘야 합니다.

그런데 만약 이중에 하나라도 충족이 안 되어 있다면 어떻게 그 경우를 처리를 해야 될까요?

당연히 디펜던시가 아직 준비가 안 되어 있으면 다시 한 번 재실행을 시켜줘야겠죠.

제가 앞서 말씀드렸다시피 데이터가 단순히 지연됐을 가능성도 크기 때문에 

다시 한 번 데이터를 받아올 수 있는지, 디펜던시들을 재실행을 시켜줘야 돼요.

그래서 디펜던시를 체크하고 준비가 되지 않은 디펜던시가 있으면 

다시 한 번 재실행을 시켜주는 로직이 또 추가가 돼요.

그래서 이렇게 디펜던시 체크를 해주고 또 준비가 되지 않은 디펜던시가 있으면 

재실행을 시켜주고 나면 그다음에는 메인로직을 다시 한 번 실행을 시켜줘야겠죠.

그래서 메인로직을 함수로 만들고 그 함수를 다시 호출하는 그런 로직이 또 추가가 됩니다.

그런데 또 이것뿐만 아니에요. 또 다양한 파라미터들을 처리해주는 로직도 추가되어야 해요.

단일데이터만 계산하는 것이 아니라 과거데이터를 계산하는 경우도 굉장히 많거든요.

예를 들어서 1년 전부터 오늘까지 1년치의 TS스코어를 계산한다든가 하는 경우도 굉장히 많기 때문에 

그런 경우들을 처리를 해주기 위해서는 시작일, 그리고 종료일 등등의 파라미터들을 불러올 수 있도록 처리해주는 그런 로직이 또 추가가 되고요.

그런 파라미터들을 제대로 파싱할 수 있는 로직이 추가가 되고요.

그다음에 모든 코드가 다 그렇겠지만 코드는 언제든지 리셉션이 일어날 수 있고 

에러가 일어날 수 있기 때문에 그런 에러 핸들링을 해주는 로직도 추가되어야 합니다.

이렇게 한두 가지의 로직들이 계속 추가가 되다 보니까 실제 로직보다 보일러플레이트코드들이 훨씬 커지게 돼요. 

그런데 더 큰 문제는 이런 게 한두 개가 아니에요.

지금은 딱 하나의 데이터를 가공하는 스크립트만 말씀을 드렸는데 저희 플랫폼에서 제공하는 데이터들이 굉장히 많거든요.

그 데이터마다 이러한 복잡한 스크립트들을 굉장히 많이 짜야 돼요.

그러다 보니까 코드 양이 굉장히 많아지고 구조가 굉장히 복잡해지게 됩니다.

또 더 큰 문제는 이 디펜던시랑 워크플로우가 굉장히 복잡해져요.

왜냐하면 제가 말씀드렸다시피 다 기본데이터를 받아오는 시점이 제각각이다 보니까 

그 기본데이터들을 개별적으로 스케줄링해서 받아야 되고 

그러면 그 기본데이터들이 준비되는 대로 그 기본데이터들에 의존하는 1차 가공데이터들을 처리를 해줘야 되고 

그런데 저희가 데이터를 1차만 가공하는 게 아니라 2, 3차까지도 가공을 하고 있고, 

그러면 기본데이터가 준비가 되고 1차 데이터가 가공되고 1차 데이터들과 기본 데이터가 준비되는 대로 2차가 준비되고... 

그런데 또 각각 시점이 다르고 하다 보니까 이게 걷잡을 수 없이 금방 복잡해집니다.

그런데 이런 걸 매일 실행시켜야 돼요. 

주식시장이 열리는 날은 항상 실행시켜야 됩니다.

우리나라 주식시장은 월요일부터 금요일까지 매일 열리거든요.

그런데 도중에 에러라도 한번 나면 정말 머리가 아파지죠.

도대체 어디서 어떤 에러가 났는지 서버 로그 보면서 파악하고 더 큰 문제는 도대체 이걸 어디서 복구해야 하나.

어디서부터 어디까지 재실행을 시켜줘야 하나.

그리고 또 복구하는 도중에 또 다른 데서 에러가 나고 여러 에러가 쌓이고 그러면 정말 머리 아파집니다.

그래서 그나마 업무시간에 에러가 나면 다행인데요. 

새벽 3시에 자는데 갑자기 에러 나서 자다가 깨서 졸린 눈을 비비며 일어나서 서버 에러 보면서 이런 복구 작업 하고 있으면...

정말... 정말 멘붕이 오게 되는 거죠.

그래서 이렇게 너무 간단한 파이썬 스크립트와 크론탭으로만 처음에 구현을 했더니 

이런 문제들이 크게 생기면서 이제 시스템 규모가 너무 복잡해져서 더 이상 개발속도가 나지 않는 거예요.

오히려 보수, 유지 하는 데도 힘에 겨운 상황까지 가게 됐습니다.

그래서 저희가 프레임워크를 도입을 해서 체계적으로 제대로 다시 한 번 시스템을 재정비해야겠다 하는 시점에 도달하게 되었습니다.

저희가 프레임워크에서 필요로 했던 기능들은요. 

먼저는 명확한 디펜던시와 워크플로우 관리 기능을 제공해줘야 하고요. 왜냐하면 금방 복잡해지기 때문에.

그리고 동일한 코드들을 자꾸 구현 안 해도 되고요.

그다음에 데이터들이 부분적으로 받아져서 부분적으로 페일이 나는 일이 없어야 되고요.

그다음에 보일러플레이터코드가 적어야 되고.

그리고 태스크모니터링이 꼭 필요했습니다. 

서버로그를 보면서 어떤 작업들이 필요하고 실행되었고 이런 것들을 파악하기가 굉장히 어려워져요.

그리고 마지막으로 디펜던시 구조가 너무 복잡해지다 보니까 코드를 보면서 파악하기가 쉽지 않았어요. 

그래서 비주얼라이제이션이 필요했습니다. 

그래서 이런 기능을 가지고 있는 것을 찾다 보니 LUIGI를 도입하게 되었습니다.

LUIGI는 스포티파이에서 만든 것이고요.

처음에는 내부적으로 짜려고 만들었다가 2002년에 오픈소스로 출시를 하게 된 프레임워크입니다.

이 LUIGI는 기본 구조가 전부 다 클래스로 되어 있어요.

그래서 LUIGI에서는 모든 작업을 루이지라고 하는 태스크를 클래스로 구현함으로서 모든 작업이 이루어집니다.

이 LUIGI는 크게 네 개 부분으로 나누어져있는데요.

첫 번째 부분은 파라미터를 정의하는 부분이고요.

두 번째는 리콰이어 함수에서 디펜던시를 정의하게 됩니다.

그리고 세 번째는 런 함수를 구현해야 하는데 이건 실제 비즈니스 로직이 들어가는 부분이고요.

마지막으로 아웃풋 함수를 구현해야 하는데 

아웃풋 함수는 해당 태스크가 성공적으로 수행이 되고 나면 생겨야 될 결과물을 정의해주는 부분입니다.

그래서 LUIGI는 이렇게 태스크. 이 태스크 안에서 네 가지 부분을 정의해줌으로서 

모든 작업의 기본 구조가 이루어지게 됩니다.

그래서 아까 보셨던 TS스코어랭킹을 계산하는 코드를 LUIGI로 옮기면 이렇게 바뀌어요.

그래서 먼저는 파라미터를 정리를 해주게 되죠. 

이렇게 보시면 저는 그냥 파라미터, 데이트, 그리고 그 파라미터가 어떤 타입인지. 그리고 디포트가 뭔지만 정의를 해주면 됩니다.

그러면 이 파라미트를 받아서 파싱하고 하는 등등의 로직은 LUIGI가 다 해결을 해줘요.

저는 그냥 파라미터의 정의만 내려주면 돼요.

그래서 나머지는 LUIGI가 다 해결해주고요.

그리고 디펜던시도 제가 이 리콰이어스를 통해서 디펜던시가 무엇인지를 정의만 해주면 

체크를 하고 아직 실행되지 않은 것이 있으면 재실행을 시켜주고 하는 등등의 로직들은 LUIGI가 또 알아서 해결을 해줍니다.

그래서 저는 디펜던시도 그냥 정의만 해주면 돼요.

그다음에 실제로 런 함수에서는 필요한 비즈니스 로직을 구현해주면 되고요.

마지막으로 이 아웃풋 함수를 통해서 해당 태스크가 성공적으로 수행이 되면 나올 결과물을 정의만 해주면 됩니다.

그러니까 지금 저는 비즈니스 로직에 훨씬 더 신경을 쓸 수 있게 되는 거죠.

그래서 맨 처음에 파이썬 스크립트로만 사용했을 때 로직이 이렇게 길었다면, 코드가 이렇게 길었다면...

LUIGI를 사용해서는 이렇게 간단하게 훨씬 간략하게 되면서 또 시스템이 오히려 더 견고하게 되는 거죠.

왜냐하면 에러체킹이나 이런 것을 LUIGI가 구조적으로 다 해주기 때문에 저는 비즈니스 로직만 간단하게 따면 됩니다.

그러면 이 LUIGI의 부분부분에 대해서 좀 더 자세하게 말씀드리도록 할게요.

먼저 리콰이어 함수, 디펜던시를 정의하는 함수잖아요.

그래서 LUIGI가 해당 태스크를 실행하기 전에 먼저 이 함수에서 정의된 디펜던시들을 다 체크를 하고요.

그중에 혹시 실행이 안 된 디펜던시들이 있다면 알아서 재실행을 시켜줍니다.

그러면 LUIGI가 어떻게 이 디펜던시들이 성공적으로 수행이 되었는지 준비가 되었는지를 알고 또 어떻게 자동으로 재실행을 시켜줄까요?

LUIGI가 그렇게 할 수 있는 이유는 디펜던시들도 그냥 일반적인 LUIGI의 태스크예요.

즉 리콰이어스 함수 안에서 다른 태스크를 제가 디펜던시로 정의를 해주게 되는 구조입니다.

그래서 디펜던시도 그냥 태스크이기 때문에 만약에 아직 실행이 안 된 디펜던시가 있다면 

LUIGI가 알아서 재실행을 시켜줄 수 있는 거예요.

그런데 그러면 LUIGI가 어떻게 이 해당 디펜던시가 성공적으로 실행이 됐는지 안 됐는지를 알 수 있을까요?

그건 바로 이 아웃풋 함수를 통해서 알 수 있습니다.

아웃풋 함수가 제가 말씀드렸다시피 해당 태스크가 성공적으로 되었을 때 나올 결과물을 정의하는 함수잖아요.

그래서 여기서 보면 이 아웃풋 함수에서 해당 태스크가 성공적으로 실행이 되면 

여기에 지정되어 있는 경로로 이 파일이 생성되어야 한다고 한 거거든요.

LUIGI는 실제로 해당 경로에 해당 파일이 존재하고 있는가만 확인하면 됩니다.

그래서 존재하면 해당 태스크가 성공적으로 수행됐다고 하게 되는 거예요. 

그렇지 않으면 다시 한 번 실행시켜주는 겁니다.

그래서 실제로 보면 이 함수에서 보면 아웃풋 함수를 호출을 해요. 

왜냐하면 결과물로 파일이 생성되어야 한다고 해놨기 때문에 

이걸 곧바로 아웃풋 함수를 호출해서 나오는 타겟 클라스를 파일처럼 처리해서 거기에 곧바로 데이터를 저장하게 되는 구조입니다.

그러니까 당연히 이 태스크가 성공적으로 수행이 되면 해당 파일이 생성되고 그 안에 데이터들이 저장되어 있겠죠. 

그렇기 때문에 LUIGI가 체크와 재실행을 쉽게 해줄 수 있는 거죠.

그렇기 때문에 제가 더 이상 디펜던시, 그러니까 기본데이터들을 받아온 스크립트들을 

개별적으로 일일이 다 스케줄링을 해줄 필요가 없어요.

저는 메인로직을 실행시키는 것만 해지면 LUIGI가 아직 실행이 안 된 게 있으면 알아서 자동으로 실행시켜줍니다.

그래서 훨씬 더 간단해져요.

또 아웃풋함수에서 이제까지는 파일만 아웃풋 함수로 정리해줬는데 

파일 외에도 여러 다양한 형태의 아웃풋들을 정리해줄 수 있어요.

예를 들어서 데이터를 파일에 저장할 수도 있지만 데이터베이스에 곧바로 저장한다고 하는 경우는 

그에 해당하는 타겟클라스를 아웃풋함수에서 결과물로 정의해주면 됩니다.

그래서 파일 말고도 다양한 아웃풋들을 정의해줄 수 있고요.

LUIGI는 기본 태스크 말고도 다른 다양한 것을 제공해주고 있어요.

예를 들어서 HDFS 작업 같은 경우에도 서포트하는 것을 이미 제공해주고 있고요.

그래서 저는 그냥 쉽게 이 매퍼와 리듀스라는 함수만 구현을 하면 손쉽게 할 수 있습니다. 간편하게.

또 그 외에 래퍼태스크라는 태스크를 제공해주는데요.

이건 뭐냐 하면 여러 태스크들을 하나로 묶어주는 태스크예요.

그래서 여러 태스크들을 한번에 돌리고 싶다면 일일이 하려면 번거로운데 

이걸 사용하면 하나로 묶어서 이것만 실행시키면 

여기에 정의된 태스크들이 LUIGI가 하나하나 다 실행을 시켜줍니다.

그래서 이런 편리한 태스크들을 적용을 많이 하고 있고요.

또 LUIGI를 통해서 태스크를 실행시키는 것은 굉장히 쉽습니다. 

왜냐하면 일반적인 파이썬 스크립트를 실행시키듯이 하면 돼요.

그러다 보니까 그냥 크론타입에서 스케줄링을 해주셔도 되고요. 

아니면 그냥 이렇게 실행을 시켜주실 수도 있습니다.

그래서 LUIGI 태스크를 실행시키는 것도 간단해요.

그리고 또 LUIGI의 큰 장점 중의 하나가 확장도 굉장히 쉽습니다.

왜냐하면 LUIGI는 익스큐션 모델이 기본적으로 서버와 클라이언트 구조로 되어 있어요.

서버에는 루이지 센트럴 스케줄러가 있고 서버에는 워커가 있습니다. 

그래서 태스크가 실행이 될 때 스케줄러랑 워커랑 코디네이션을 해서 태스크들을 실행을 하게 되는데요.

스케줄리는 기본적으로 RPC 기반의 API라고 생각하면 되고요.

그래서 어떤 어떤 것들을 실행하라고 코디네이션을 해줍니다.

그런데 만약에 태스크 수가 적으면 그러면 그냥 서버 하나에서 동시에 돌리면서 한 서버에서 감당을 하시면 되는데 

예를 들어서 태스크 수가 한 100개 정도 된다고 하면 단순히 서버 수를 늘리시면 돼요.

그리고 거기서 태스크를 실행하시면 중앙에 있는 것과 워커들이 다 소통을 하면서 태스크들을 알아서 분배를 하게 됩니다.

그래서 코디네이션을 알아서 해주기 때문에 단순히 증강시키는 것만으로도 확장을 쉽게 하실 수 있어요.

또 LUIGI가 되게 좋은 게 모티피케이션도 쉽게 설정을 할 수 있습니다.

간단한 이메일 설정만 해주면 에러가 났을 때 이메일로 자동으로 보내줍니다.

그래서 에러가 났을 때 제가 직접 서버 로그를 봐야 될 경우가 별로 없고 

이메일에 이미 나와있기 때문에 어느 정도 파악이 돼요. 

그리고 자동으로 연락이 오기 때문에 굉장히 편합니다.

또 슬랙이랑 연결시킬 수도 있어요. 간단하게 설치하시면 노티피케이션을 슬랙으로 곧바로 보내실 수도 있습니다.

또 태스크 모니터링 대시보드도 제공을 해주고 있어요. 

그래서 아까 보셨던 루이지의 센트럴 스케줄러가 워커들과 코디네이션을 하는 스케줄러도 되지만 

동시에 관리자 대시보드도 제공을 해주고 있습니다.

그렇기 때문에 쉽게 현재 어떤 태스크들이 돌아가고 이미 실행이 되었고 등등을 쉽게 확인할 수 있어서 굉장히 편리하죠.

특히 태스크 수가 많고 자주 시행될 때는 굉장히 편리합니다.

그리고 또 태스크 히스토리 내역도 제공을 해줍니다. 

그래서 이제까지 실행되었던 태스크 히스토리들도 쉽게 볼 수 있어요.

그래서 이런 내역화 하는 것도 굉장히 쉽게 할 수 있습니다.

그리고 이 디펜던시 그래프로 자동으로 해줍니다.

코드만으로 파악하기가 쉽지 않은데 이렇게 그래프를 자동으로 생성해주기 때문에 

구조를 파악하는 것도 굉장히 쉽습니다.

물론 디펜던시가 너무 복잡하면 그래프를 그려줘도 사실 잘 알아보기는 쉽지 않은데요.

그래도 코드로 파악하는 것보다는 훨씬 낫죠.

제가 지금 몇 분 남았나요?
-지금 10분 남았습니다.
-10분 남았나요.

그래서 LUIGI 덕분에 그나마 밤에 잠을 잘 자고 있습니다.

그런데 그래도 LUIGI도 만능은 아니에요. 

LUIGI도 아쉬운 점이 몇 가지 있습니다.

먼저 제가 아쉬웠던 건 트리글 시스템이 없어요. 

그 말이 뭐냐 하면요. 

LUIGI 태스크를 직접 실행시켜야 돼요. 

그래서 주기적으로 실행시키고 싶으면 크론탭을 사용하거나 다른 것을 사용해야 돼요.

그런데 태스크들을 실행시키는 서버가 한두 개밖에 안 되면 사실 크론탭이 큰 문제가 되지 않는데 

서버 수가 10개, 20개 되면 각각 서버마다 스케줄이 다 되기 때문에 그걸 관리해주는 것도 굉장히 복잡해지거든요.

그러면 거기에 대한 다른 외부 솔루션을 사용해야 되고 하기 때문에 그 부분은 아쉽더라고요.

LUIGI가 이거를 다 해줬으면 편했겠다는 생각을 하고요.

또 분산실행도 제공해주고 있지 않아요. 

그래서 분산실행은 사용자가 직접 해야 합니다.

여기서 분산실행이라 함은 어떤 거냐 하면 여러 개를 동시에 실행시키는 것은 가능합니다.

그냥 동시에 걸리면 디펜던시 구조에 맞춰서 알아서 배분을 해서 실행시키는 것은 가능한데 

하나의, 동일한 태스크를 여러 워커에 나누어서 분산시키는 것은 제공해주고 있지 않아요.

그래서 그런 부분들은 사용자가 직접 구현을 해야 합니다.

그것도 아쉬웠고요.

그리고 LUIGI가 기본기능에 대해서는 굉장히 잘 되어 있어요. 

그래서 사실 기본적으로 태스크를 실행하는 데 LUIGI로 하면 금방할 수 있는데 

조금 고급버전을 하고자 하면 그렇게 잘 되어 있지는 않아요.

좀 더 문서화 되어 있고 한다면 플러스일 텐데 

그렇지 않아서 에러를 겪으셔야 되는 그런 조금 아쉬운 단점이 있습니다.

또 몇 가지 팁을 드리자면 디펜던시들은 가능하면 최대한 심플하게 하시는 게 좋아요.

물론 이 디펜던시는 어쩔 수 없는 경우가 많이 있습니다.

왜냐하면 데이터소스가 외부소스이다 보니까 그것에 맞춰서 시스템이 구현되다 보니까 

걷잡을 수 없이 복잡해지는 경우가 많거든요.

그래서 처음에 개발하실 때 디펜던시 구조에 대해서 가능한 알고 하시는 것이 좋습니다.

모르고 하시면 어느 순간 굉장히 복잡해져있거든요. 

그런데 그때 다시 단순화 시키려고 하면 굉장히 일이 커져있어요. 

어려운 경우가 많습니다.

그래서 가능하면 처음부터 디펜던시 구조에 대해서 고민을 많이 하셔서 

어떻게 하면 최대한 간단하게 할 수 있도록 고민을 하는 게 나중에 장기적으로 봤을 때 큰 도움이 되더라고요.

그리고 루이지는 태스크는 최소한의 단위로 하시는 게 굉장히 큰 도움이 됐어요.

그 이유는 재실행을 시켜야 하는 경우가 굉장히 많아요.

에러가 있어서 다시 실행을 시켜야 하는 경우도 있고 한데 

예를 들어서 5년, 10년치 데이터를 전부 다 재실행을 시켜야 된다.

모든 작업을 재실행을 시켜야 한다고 하면 시간이 너무 오래 걸려요.

그리고 또 그 도중에 에러가 나서 다시 재실행 시켜야 한다고 하면 정말 머리 아픕니다.

그래서 최소한의 단위로 잘라놓으면 이미 실행된 것은 재실행을 시키지 않아도 되거든요.

그래서 훨씬 간편해지고 시간이 훨씬 단축이 돼요.

그래서 태스크는 최소한의 단위로 하시는 게 도움이 됩니다.

그리고 노티피케이션도 꼭 필요한 것을 만드는 것으로 설정하시는 게 굉장히 좋습니다.

저도 맨 처음에 노티피케이션으로 설정을 할 때 시작할 때 다, 끝나면 다 노티피케이션을 했거든요.

그러니까 너무 많은 거예요. 

그래서 보지도 않고 꺼버려요. 

그래서 에러가 났을 때만 받을 수 있도록 설정하는 게 도움이 됩니다.

네, 제가 준비한 건 여기까지고요. 

제가 시간 내에 많이 설명을 드리다 보니까 좀 부족한 부분도 있었을 것 같은데 

혹시 질문 있으시면 질문해주시고 나중에 생각나시면 저한테 이메일로 연락주시면 됩니다. 감사합니다.