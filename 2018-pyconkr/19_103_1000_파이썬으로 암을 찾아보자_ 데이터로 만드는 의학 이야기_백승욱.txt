안녕하세요? 일요일 오전 10시에도 세션을 찾아주셔서 감사드리고요.

소개 받은 백승욱입니다.

이것은 미래 가치가 있다고 해서 창업하게 되었습니다.

저희 회사는 인공지능로 시작을 했고요.

그다음에 여러 가지 인공지능 애플리케이션 중에 역시 사람을 수 살리는 것만큼 중요한 것이 없겠구나 생각해서 다른 것은 다 제외하고 의학이적은분야에서 인공지능을 개발하고 있습니다.딥러닝으로 암을 정확하게 찾는 도움을 주는 제품입니다.

국내 1호 딥러닝 스타트업이고요.

1세대에 속합니다.

이미지웹챌린지라는 대회에서도 7위한 바 있고 2015년에 5위하면서 글로벌하게 이름을 알리기 시작했고요.

여러 가지 수상경력이나 이런 것을 봐서 아시겠지만 AI커뮤니티에서는 굉장히 많이 알려진 회사입니다.

파이썬 커뮤니티에서는 많이 알려져 있는 것 같지 않아서 회사 소개를 하려고 합니다.

그래서 이렇게 저희가 열심히 일을 해왔고요.

그래서 어느 정도 다 투자에 관심 있으신 분은, 스타트업을 하시는 분은 알만한 회사와 일을 하고 있고요.

의료영상에 인공지능을 도입하는 최선 변화를 전세계적으로 퍼트리는데 같이 일을 하고 있는 파트너들입니다.

실제로 저희로 루닛은 파이썬을 굉장히 사랑하고요.

한 번도 손에 놔본 적 없는데요.

특히 인공지능 하려면 파이썬을 안 쓸 수가 없지요.

라이브러리 파이톨치가 다 파이썬 기반으로 되어 있고, 저희가 서비스를 할 때도 백핸드를 선택할 때 가급적 파이썬 기반으로 나갑니다.

그래서 장고도 쓰고 있고요.

현재 저희가 만들고 있는 제품은 이런 것입니다.

웹브라우저 기반으로 돌아가는 서비스를 만들고 있습니다.

엑스레이 파일을 업로드하면 인공지능이 보고 이렇게 이 사람은 얼마나 악성 암의 확률이 높고, 그리고 어디가 암의 확률이 높다 이런 것을 알려주는 것이지요.

그런데 건방하게 이것이 무슨 질환이고 미주알 고주알 알려주지 않습니다.

은근하게 알려주는 제품을 만들고 있고요.

유방암 같은 경우도 이런 사진을 찍거든요.

유방암 엑스레이입니다.

보시는 것처럼 비슷한 방식으로 암이 있을 확률과 어디가 의심스러운지 이런 정보를 알려주는 기술을 만들고 있습니다.

그리고 더 들어가서 암으로 의심된다고 싶으면 조직을 떼어서 조직검사를 하거든요.

현미경 영상이 나오게 됩니다.

굉장히 큰 영상인데, 이것을 현미경으로 사람의 눈으로 판독하다 보니까 객관성이 떨어질 수도 있고, 또 저 안에 들어있는 모든 정보를 저희가 캐치하고 있느냐.

그렇다고 볼 수 거든요.

인공지능을 도입해서 객관적으로 여러 가지 저 영상상의 특징들을 한 다음에 이 환자가 어떠한 암을 가지고 있고 앞으로 어떻게 될 것인지는 객관적으로 예측하는 일을 하고 있습니다.

복잡하니까 쉬운 얘기 다시 돌아가서 엑스레이 얘기부터 해볼게요.

거의 다 찍어보셨을 것입니다.

건강검진하면 가슴팍에 대고 촬영하면 이런 영상이 나오죠.

뭔가 이상한 것이 보이시나요? 의사선생님은 안 계시겠지만 여기 뭔가 덩어리가 있어요.

이것은 저희 같은 사람도 조금만 배우면 쉽게 알 수 있는 이상소견입니다.

폐암이고요.

그런데 이런 케이스는 어떨까요? 의사선생님도 굉장히 어려워하는 케이스예요.

실제 암환자의 사진이고요.

암은 심장 뒤에 있었습니다.

그런데 엑스레이는 아시다시피 한 장짜리 영상이고 3D 데이터가 아니에요.

심장 뒤에 숨어있거나 뼈 뒤에 숨어있거나 그런 경우에는 놓칠 수 있어요.

그래서 이 경우에 저희가 15분의 영상이 전문의 분들하고 테스트를 했을 때 한 6분이 실제 놓쳤습니다.

암을.

그래서 실제로 엑스레이에서 폐암을 놓치는 확률이 얼마나 되느냐 하면 여러분이 폐암을 가지고 있다고 가정했을 때 73% 정도는 잡아내지만 나머지 27% 정도는 잡아내지 못합니다.

방금 같은 어려운 케이스는 더더욱 그렇고요.

그런데 그렇게 문제가 안 되는 이유는 암이 누가나 가지고 있는 질병은 아니기 때문이지요.

확률적으로 보면 암이 걸릴 확률은 높다고 볼 수 없지만 만일 내가 저 50명 중의 한 명이라면, 나의 얘기라면 저는 1년 2년에 한 번씩 엑스레이를 찍는데 내가 만일 암에 걸렸었다.

75%밖에 못 잡는다.

그러면 굉장히 큰 문제지요.

이런 문제를 반드시 해결해야 겠다는 생각을 했고요.

유방암 검사도 완벽하지 않습니다.

비슷한 수치인데요.

30% 정도의 유방암은 엑스레이 영상판독에서 발견이 안 됩니다.

그것이 현재 알려지지 않은 통계이고요.

이 케이스를 보시면 지금 겨드랑이 쪽에 암이 있었는데 실제로 병원에서 놓친 케이스예요.

이런 일들이 일어날 수 있습니다.

굉장히 무서운 일이죠.

그런데 이것이 누구의 잘못이냐?

의사들의 잘못일까요?

저희는 그렇게 생각하지 않아요.

굉장히 많은 의사선생님을 만났는데 정말 어떻게 더 환자를 도울 수 있을까 불철주야 노력하시는 분들입니다.

그런데 어쩔 수 없는 인간의 한계라는 것이 있는 것 같아요.

그래서 이분들은 도움이 필요하다.

그래서 의사가 실제로 진단에 믿고 쓸 수 있는 인공지능을 만들어서 말씀드린 문제를 해결하는 것이 저의 목표입니다.

그런데 인공지능이라는 것이 말로 그냥 인공지능 만들어서 의사를 돕는다고 해서 굉장히 쉬운데요.

그런데 적당히 만들어서는 안돼요.

의사분들이 굉장히 전문가입니다.

엑스레이는 한두 장 보신 분이 아니고 오랜 기간 동안 인턴 레지던트 펠로우 거치시면서 공부를 엄청 많이 하시고 연구도 많이 하시기 때문에 엄청난 전문가예요.

그런데도 놓치는 거거든요.

어중간한 인공지능으로는 그분들을 만족시킬 수 없어요.

압도적인 정확도여야 만족을 느낄 수 있습니다.

실제로 믿고 쓸 수 있는 것이고요.

실제로 가능한 숫자는 아니지만 99.99%는 있을 수가 없지요

하지만 인공지능 회사로써, 특히 사람의 생명을 다루는 인공지능 회사로써 지향해야 한다는 것이 당연한 얘기 같지만 실제로 많이 못하고 있는, 하지만 저희는 추구하고 있는 목표라고 볼 수 있겠습니다.

그다음에 던져볼 얘기는 이것이 과연 가능한 목표인가.

저는 가능하다고 생각합니다.

가능하다는 것이 99.99를 달성하는 것은가능하지 않겠지만 적어도 인간보다 어떤 특정한 테스크에 대해서도 더 높은 정확도를 보여줄 수 있는 인공지능을 만들 수 있을까.

저는 명확한 목표와, 그러니까 모든 것을 다하는 인공지능을 만드는 것이 아니라 명확한 목표, 폐암을 정확하게 잡겠어.

이런 목표와 그것에 상응하는 하이퀄리티 데이터가 있다면 해볼 만하다고 생각했습니다.

그리고 이것은 약간 딥러닝과 관련된 얘기인데요.

사람한테 배우는 인공지능이 아니라 객관적인 데이터로부터 의학적인 특징을 스스로 배우는 것이 딥러닝의 특징인데, 그런 딥러닝을 사용한다면 해볼만하다는 생각을 했어요.

이것이 무슨 얘기냐 하면요.

일반적으로 우리가 영상에서 뭔가 디텍트한다고 하면 이렇게 접근합니다.

이미지를 준비하고요.

그다음에 여기 빨간색으로 마스크라고 써놓은 것인데요.

저기에 암이 있다는.

저것을 누구한테 받나요? 보통 상식적으로 의사한테 가서 여기에 비정상 부분이 있으면 표시해주세요라고 얘기를 합니다.

지금은 여러 가지 방법들이 나와 있지만 저희가 이 일을 시작했을 때만 해도 이미지를 조각조각 내서 패치별로 이것이 비정상인지 아닌지 분류기를 만들어서 돌리는 식으로 접근했었습니다.

그런데 저 방식의 가장 큰 한계는 무엇이냐 하면 아까 인간을 넘어서는 인공지능을 만들어야지, 실제로 유저들이 믿고 쓴다고 말씀드렸잖아요.

그런데 데이터 자체가 인간으로부터 온 것이다.

모순이 있지요.

사람의 한계가 80%라면 AI는 넘어설 수 없다 제 생각이었습니다.

정확한 데이터는 병원에 있지요.

의사의 어떤판독이나 이런 것이 아니라 좀더 디테일하게 말씀드리면 엑스레이만 보고 의사가 마스크를 그리는 것이 아니라 좀 정확한 데이터라도 활용하라는 것이지요.

이런 데이터는 병원 가야 있습니다.

챌린저 참가했을 때 공개적으로 우리가 할 수 있는 그런 데이터는 엑스레이 달랑 하나 주거든요.

병원에 가서 환자 단위로접근할 수 있어요.

이 환자가 작년, 올해 왔을 때, 이런 리치한 데이터를 활용할 수 있는 것이지요.

그래서 저희는 이런 식으로 접근하고 있습니다.

병원에서 데이터를 얻어요.

암이 있는 환자, 암이 없는 환자.

그래서 맨 위에 맨 아래.

뭔가 있다고 나오면, 체스트엑스레이네거티스가 있다고 한다면 저희는 중간에 있는 데이터도 같이 쓸 수 있는 거예요.

사람이 보기에는 뭔가 놓쳤는데 CT검사에서 나온 이런 케이스도 있을 수 있습니다.

그런데 우리가 엑스레이를 준비해서 여기에서 의사의 마스크를 받아서 학습시키게 되면 중간에 해당되는 데이터는 정상이라고 들어갈 수 밖에 없어요.

왜냐하면 사람 눈에 잘 안 보이고 실수로 놓쳤을 수도 있고, 이런 식으로 굉장히 집착에 가까운 노력을 해서 데이터를 콜렉션하면 저런 데이터를 살릴 수 있습니다.

그래서 저희가 서울대병원을 포함해서 아산병원, 삼성병원 다 이름을 아실 법한 대형병원과 협력하고 있는 이유가 이런 하이퀄리티 데이터가 많이 필요하거든요.

그래서 큰 병원과 파트너십을 공교히 가져가고 있고요.

이렇게 데이터를 모으면 그다음에 딥러닝이 나옵니다.

딥러닝의 장점이자 단점이죠.

어떻게든 학습해요.

무슨 생각을 하는지 몰라서 그렇지, 어떻게 든 학습을 해냅니다.

특히 분류 성능이 어마어마하죠.

이미지 분류하는 것은 거의 풀렸다고 볼 수 있을 정도로 잘하는 분야 중의 하나입니다.

분류에필요한 데이터를 잘 모았다고 하면 학습을 해낼 수 있습니다.

훌륭한 분류를 한 다음에 어디를 보고 분류했는지 시각화해보자.

원래는 어디 있는지 알기 위해서 이미지를 조각조각낸 다음에 한다는 접근이었는데 지금은 저희가 먼저 하고 그다음에 그 결과를 어떤 로직으로 만들었는지 어떤 형태로든 시각화를 해보자는 철학을 가지고 시작했습니다.

2014년 말 정도의 생각이고요.

그래서 이것이 우리의 접근입니다.

여기에서 딥러닝 하신 분들은 다 쉽게 아실 수 있지만 좀 간단하게 설명드리면 이것이 가장 티피컬한 것이거든요.

쉽게 말씀드리면 픽셀 단위로 들어오는 정보를 폐암이 있다 없다 이런 식의 굉장히 추상화된 정보로 멀티레이어를 걸쳐서 하는 과정이라고 생각하시면 될 것같습니다.

이렇게 해서 폐암이 있는지 없는지를 분류하는 파일을 만든 다음에 맨 마지막 단에 있는 레이어를 저희가 의도적으로 폐암이 있다 없다 푼다면 2개의 레이어를 배치함으로써 폐암이 있으면 어떤 폐암에 우리가 어사인은 액티베이션에 뜨게 하고 그것이 아니면 노멀맵에 쓰게 해서 학습을 시켰어요.

일단 학습이 됩니다.

되면 이제 저희의 속셈은 무엇이냐 하면 새로운 영상을 넣었을 때 여기에 픽쳐맵에 뭔가 뜰 거예요.

뜬 것을 바로 영상상에 오버레이를 시켜보자.

그러면 이 영상에서 컴볼루션 필터가 이 부분에서 반응했기 때문에 이 영상은 폐암이 있다고 판단이 된 것이거든요.

이것을 오버레이해서 보면 얘가 클레식케이스를 폐암이 있을 확률이 80%다 이렇게 된 것에 리즈닝이 될 것이다.

실제로는 훨씬 복잡하게 하지만 큰 그림은 변하지 않았습니다.

그런데 이것이 과연 될까.

사실굉장히 두려웠어요.

2015년에 저희는 투자도 이미 받은 상태였고.

그런데 어떻게든 다르게 더 잘해야 됐거든요.

사실 리스크가 많은 어프로치였습니다.

저 당시만 해도 아무도 저렇게 안 했어요.

그래서 굉장히 고민을 많이 했는데 됐죠.

그래서 지금 이번에 암은 아니고 결핵이라는 질환으로 테스트를 해본 것인데, 저희가 인공지능한테 트레이닝을 할 때 이 부분이, 그러니까 결핵은 이렇게 생겼어.

받지 않고 아까 말씀드린 것처럼 분류기 학습을 시켰는데 이 부분에 결핵이 있다고 한 것이랑 정확하게 동일한 위치에 랩핑을 시킬 수 있다는 것을 보여줬습니다.

물론 당연히 잘된 것만 보여드린 것이기는 한데 어쨌든 가능성을 봤어요.

그래서 가설은 검증이 되었으니까 달려봐야겠죠.

그래서 이때부터 저희가 정확도를 극한으로 올리기 위해서 여러 가지 시도를 합니다.

아키텍쳐를 바꿔보고 러닝 알고리즘, 여러 가지 러닝웨잇 같은 것 테스트를 해보고요.

굉장히 다양한 것들, 컴비네이션도 종합해서 다 정량적으로 평가해서 선택했고요.

그리고 휴먼레이블링, 저희가 안 받는다고 는데 안 받았더니 좀 문제가 생긴 부분이 있었습니다.

너무 이 부분이 암이고 이 부분은 암이 아니야.

이런 식으로 명확하게 안 주다 보니까 데이터 안에 섞여 있었던 바이어리스라도 그대로 학습해버리는 문제가 있었어요.

그래서 저 문제를 해결하기 위해서 아주 일부분의 데이터는 아까처럼 이 부분이 암이에요.

이런 식으로 그 부분을 해결했습니다.

그다음에 앙상블, 서로 다른 방식으로 만들어진 모델을 합치면 일반적으로 성능이 좋아진다고 알려졌죠.

그래서 활용하고 있고, 그다음에 이것이 저희 회사에서 자랑스럽게 생각하는 것인데 피지션, 의사가 주도해서 합니다.

저희는 끊임없이 실험을 해요.

데이터를 넣어서 새로운 실험을 하고 결과를 봅니다.

결과를 우리 엔지니어가 평가하게 되면 잘 몰라요.

잘 잡은것인지 잘 모르는데 6명의 전문의가 풀타임으로 일을 하고 있어요.

굉장히 효율이 좋죠.

만들자마자 물어볼 수 있으니까.

전문가의 입맛에 맞는 모델을 찾기 위해서 이렇게까지 하고 있습니다.

그리고 그러기 위해서 이런 툴도 만들었고요.

장고, 리엑트, 이런 식으로.

합리적인 조합으로 툴을 개발하고 있고요.

극한까지 달려보니까 저희가 말씀드렸던 99%까지 못 미쳤지만 여기 파란색으로 보이는 것이 저희가 방금 말씀드렸던 모든 테크닉을 종합해서 달성한 98% 정도를 달성할 수 있었습니다.

모든 진단을 98%로 하는 것이 아니라 암을 찾는 것은 저 정도로 할 수 있다는 것이에요.

저 정도만 해도 굉장히 많은 것을 바꿀 수 있습니다.

그래서 이것이 저희가 하고 있는 일들이었고요.

좀 더 디테일하게 들어가볼 텐데요.

저희가 일을 해보니까 처음에는 좀 경쟁자가 많지 않았는데, 구글 같은 경우도 이 부분에 뛰어들고 있죠.

그래서 경쟁이 치열해지고 있습니다.

시간이 부족해요.

그래서 효율적인 학습이 중요해졌습니다.

그래서 한 학습을 돌리는데 시간을 우리가 줄일 수 있으면 그것이 그대로 경쟁력이 되고, 그러면 우리가 승리할 수 있는 이런 상황이 자연스럽게 만들어졌고요.

그래서 저희가 굉장히 좀 집착하고 있는 분야 중의 하나가 어떻게 하면 GPU가 1초도 쉬지 않게 부려먹을 수 있을까.

이런 고민을 하고 있고요.

단순합니다.

CPU 페이지랑 나눠서 생각하면 CPU에서 준비를 하겠지요.

준비할 때 여기 보시는 것처럼 굉장히 다양한 일을 합니다.

이미지로딩 당연히 하는 것이고, 여러 가지 들어가죠.

그다음에 이미지 리사이징도 여러 가지 해주고, CPU에서 처리하는데 굉장히 해비로드죠.

GPU로 넘어와서 배치가 올라갔다가 이런 과정을 거칩니다.

이것을 단순하게 짜잖아요.

그러면 저희 경험에 따르면 이렇습니다.

이것이 정지영상이 아니고요.

동영상인데요.

보시면 CPU 유틸이 거의 0이다가 갑자기 99% 떴다가 다시.

그래서 저기 오른쪽에 보면 데이터 파트에 지금 9초 가량 쓰고 있고 GPU가 1초 잠깐 썼다가 다시 9초 쓰고 있고 이러고 있습니다.

그러니까 이렇게 쓰고 있는 것인데요.

암 고치려다 암에 걸릴 것 같은.

이것은 우리가 바라는 것은 이런 것이지요.

이렇게 만들려면 당연히 제공해주는 것을 잘 써야 하고요.

멀티프로세싱 잘 활용해야 합니다.

저희 같은 경우는 의료영상 사이즈가 굉장히 크다는 문제가 있었어요.

고해상도를 쓸 일이 없는데 의료영상은 함부로 할 수가 없어요.

정보가 손실되고 정확도에 영향을 주기 때문에.

그래서 보시는 것처럼 엄청난 로딩 차이와 이미지로딩 차이를 보입니다.

그래서 CPU 시간을 어떻게 줄일 수 있을까.

더 최적화할 수 있는 것이 많다고 생각하는데 파이썬 정도에서 할 수 있는 것이 이 정도 있을 것 같습니다.

PIL 이 정도로 쓰는 것이 아니라 뭐죠? 그다음에 메모리카피 줄이고 이런 것을 다 활용합니다.

2가지로 말씀드리면 OpenCV는 컴퓨터비전 하셨던 분들는 굉장히 익숙할 거예요.

그런데 이것이 파이썬가 잘 되어 있어서 적극 활용하시면 좋습니다.

차이가 여기 보시는 것처럼 이미지 리딩할 때도 2.5배 정도 차이가 나고 리사이즈 어마어마한 차이가 납니다.

10배 이상 차이가 납니다.

그래서 OpenCV 적극 활용하시면 좋을 것 같고, 그러면 이미지 읽었으면 럼파이로 여러 가지 할 텐데, 이것도 쓰냐 안 쓰냐에 따라서 저 정도의 성능 차이를 보입니다.

그래서 이것이 저희가 개선을 한 버전의 동영상인데요.

속이 시원하시죠?

보시면 티데이터 시간이 거의 0으로 찍히는 것을 볼 수 있고요.

거의 쉬지 않고 0.1초도 쉬지 않고 일을 하고 있습니다.

GPU가 맛이 가지 않는 한 최적의 효율로 일을 할 수 있는 상황이 됩니다.

또 하나 경험을 공유하자면 회사가 커지니까 여러 프로젝트를 하게 되더라고요.

그러다 보니까 프로젝트의 개수도 많아 지고 한 프로젝트의 규모도 커지면서 모델의 복잡도도 늘어나고.

그러다 보니까 하나의 AI 모델을 혼자 만드는 것이 아니라 나눠서 분업하는 상황이 많아집니다.

그러다 보니까 여러 모델들을 효율적으로 개발통합하는 방법론이 중요해졌는데요.

예를 들어 현미경 영상을 나눌 때 줌 레벨에 따라서 조직의 거시적인 것을 봐야 하는 것도 있고, 아예 더 깊게 들어가서 세포 하나하나 들여다 봐야 할 수도 있습니다.

중간 단계를 봐야 할수도 있고요.

보통 이런 식으로 되겠지요.

각각을 다른 엔지니어가 만드는 일이 생깁니다.

그런데 우리가 최종 결과를 낼 때는 이 결과물을 다 합쳐서 결과를 내야 하는 상황이 생길 수 있어요.

그러면 텐스플로우에서는 이것을 할 때 무슨 일이 생기냐 하면 벨리어블 네임이 겹치는 상황이 생깁니다.

스코프를 잘 활용하시면 이런 일을 피할 수 있고요.

스코프를 잘 활용해서 하시는데, 문제는 그래프 상에서 충돌을 피할 수 있으나 우리가 엔지니어 A랑 B가 티슈나 스트럭처라는 스코프를 알고 만든 것이 아니라 합칠 때 만들어진 것이기 때문에 체크포인트 상에서는 지금 저 티슈나 스코프가 안 들어가 있습니다.

체크포인트 로딩을 할 때 랩핑이 안 돼요.

랩핑할 때 다시 전체 그래프에서 티슈에 해당하는 부분을 가져와서 걔네들에서 이 티슈라는 스코프를 제거한 다음에 해서 랩핑해줘야 이렇게 들어갑니다.

복잡해보이지만 굉장히 간단한 접근이고요.

실무적으로 효율이 좋은 어프로치이기 때문에 참고하시면 좋을 것 같고, 그러면 이렇게 결과를 잘 볼 수 있게 됩니다.

그래서 간단히 저희가 하는 일을 소개를 드렸고, 그리고 몇 가지 파이썬 관련된 팁들을 소개드렸는데요.

벌써 4년이 된 것 같습니다.

일을 시작한지가 2013년에 창업해서 2014년부터 본격적으로 해왔는데 드디어 판매하게 되었습니다.

이것이 의료기기다 보니까 허가를 받아야 팔 수 있더라고요.

그래서 저희가 그제 3일 전 기사입니다.

이것이.

그래서 저희가 처음으로 국내에서 엑스레이에서 폐암을 찾는 인공지능을 판매하게 되었습니다.

의료진단의 본질은 환자의 상태를 정확하게 분류하고 또 미래를 예측하는 것.

이것이 인공지능 머신러닝이 제일 잘할 수 있는 분야죠.

이렇게 할 일이 많고 엑스레이, 이런 것뿐만 아니라 심장질환 여러 가지 할 일이 많습니다.

그래서 저는 같이 의학혁신할 동료들을 열심히 찾고 있고요.

관심있으신 분은 저희가 항상 채용하고 있으니까 언제든지 여기 있는 정보로 연락을 주시면 되겠습니다.

감사합니다.