https://youtu.be/oiS0SaxEYLs

-발표하겠습니다. 정직한입니다. 

제가 정직할까요? 사실 거짓말을 많이 합니다. 

그런데 제가 정직하냐 안 정직하냐? 

이 많은 사람들이 샘플로 보는 거죠. 

그래서 성별이나 색깔이나 목록이나 키를 가지고 이 사람이 거짓말을 하냐 안 하는 사람이냐고 분별을 해 보고 싶습니다. 

그런데 실제로 머신러닝을 돌릴 때 딥러닝이 유행하잖아요. 

모델별로 띠오리가 있기 때문에 언제 잘 믿고 고민해야 하는 부분이 있습니다. 

그래서 트리모델 같은 경우에는 데이터 사이즈가 작을 때, 클 때도 됩니다. 

그런데 사이즈가 작고 비선형 모델일 때 주로 사용하게 됩니다. 

그래서 스플릿셔라고 나와 있는 그림을 보면 질문을 던집니다. 

이 사람이 키 몸무게가 얼마냐. 이것을 가지고 키와 몸무게를 가지고 피처의 맵을 그린 다음에 

그 구간에 할당된 구간에서 나오는 클래스가 실제 라벨하고 맞을 확률을 최적화하는 게 

트리모델인데 깊게 들어가면 엔트로피를 통해서 인포메이션을 가장 많이 얻을 수 있게끔 하게끔 옵티마이즈를 하는 방식이 트리모델인데요. 

문제점은 이게 그 기준을 네가 키가 160.. 제가 160.. 몸무게로 하죠. 

제가 몸무게가 70kg인데 네가 몸무게가 높으니까 거짓말할 확률이 높아. 

그런데 몸무게가 바뀌면 예측이 바뀌기 때문에 에버리지를 여러 모델을 가지고 예측을 가지고 그것을 섬을 한 것을 가지고 하는 게 앙상블입니다. 

이 앙상블이 액티르러닝에서. 이 앙상블을 썼을 경우에 부스팅이 큰 트랙입니다. 

이 백인가 부스팅은 백인 같은 경우에는 부스팅은 이제 예측을 덜 맞는 것은 웨이트를 덜 주고 

잘 맞는 건 예측을 더 높여서 예측을 하는 게 앙상블 모델입니다. 

이럴 경우에 이렇게 머신러닝이 유행하는데 하이퍼 파라시터 튜닝을 디폴트로 하는 경우가 있는데 

그럴 경우에는 잘 안 맞고 하이퍼 파라미터를 튜닝할 때 변수가 3개인데 공간이 몸과 키 같은 경우에는 

몸도 사실은 배리에이션이 크고 키도 배리에이션이 커서 최적의 파이퍼 파라미터를 튜닝하려면 시간이 오래 걸립니다. 

그래서 오토로 할 수 있는 게 파이썬 같은 경우에는 하이퍼 옵티티가 있어서 베이직한 옵티마이즈를 했습니다. 

여기에서 베이직 하다는 것은 어떤 사건에 대한 분포를 마음에 가지고 있고 사람들이 거짓말을 할 확률은 정규분포를 따라. 

그런데 이 분포를 아는 데 필요한 정보는 평균과 분산입니다. 

그리고 예를 들어서 어떤 분포가 있는데 네버티브가 안 나온다고 하면 정규분포를 넣으면 안 되죠. 

이런 나의 믿음을 가지고 실제 옵저베이션을 보고 실제 보는 것에 따라서 

나의 분포에 대한 가정을 바꿔나가는 게 베이지한 인데요. 

이 옵티마이즈를 통해서 하이퍼파라미터를 튜닝했을 경우에는 디폴트를 가지고 하는 거랑 다닙니다.

 왜 베이지안 옵티마이즈를 하면 좋냐면 오토로 가능하고 여러 가지 모델을 한꺼번에 다같이 돌려볼 수 있습니다.
 
  베이지안을 왜 하냐? 예를 들어서 센트리얼이라고 시뮬레이션 환경에서 돌리던 것을 
  
  강화학습을 해서 돌릴 경우에는 강화학습장에서 잠재공간상에서 돌릴 때 잠재공간에서 추정해야 하는 변수가 많을 경우에는 
  
  베이지안 중에서 추론을 할 수 있습니다. 사람들이 그냥 변분추론만 하는데 이것을 대충 분산해서 하면 더 빨리 높일 수 있습니다. 
  
  그래서 지금까지의 베이지안. 

슬라이드가 공유가 될 거라 큰 그림으로 해서 보면 실제 하나를 돌려본 것을 보면 랜덤으로 돌려봤더니 예측율이 0.56이 나옵니다.

 56%가 맞다는 거죠. 그런데 베이지안 옵티마이징을 하는데 큰 그림은 내가 옵티마이징 펑셜. 
 
 내가 미니마이즈를 하고 싶은 걸 규정하고 그것을 가지고 옵티마이즈를 하면 최적의 하이퍼 파라미터가 나오고 
 
 그것을 가지고 실제 값들을 하이퍼 파라미터를 나와서 랜덤 프로세스를 다시 돌리면 디폴트 값보다 7%가 오릅니다. 
 
 그래서 머신러닝을 돌릴 때는 하이퍼 파라미터를 고민해야 합니다. 감사합니다. 
