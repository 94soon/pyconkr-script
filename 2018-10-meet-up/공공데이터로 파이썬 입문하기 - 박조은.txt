오늘 주말인데도 이렇게 튜토리얼에 참여하러 와주셔서 감사를 드리고요.

아까 각 조에 도우미분들 손 들어주셨는데, 다시 한 번 손 들어볼까요?

지금 손 들어주신 분들이 도우민 분들이세요.

그래서 늦게 오시거나 실습하다가 안 되는 부분이 있을 때 이 도우미분들에게 도움을 요청해 주시면 도와주실 거예요.

미리 메일로 공유를 받으셨을 텐데.

경로를 안내를 못 받으신 분 혹시 계세요?

경로 안내를 못 받으셨으면 도우미 분께서 경로를 좀 안내해 주시면 좋을 것 같아요.

파이콘 kr 2018 튜토리얼이라고 폴더에 가면, 두 개의 폴더가 있어요.

그래서 오늘 두 개의 세션을 진행을 할 건데.

첫 번째 세션은 공공데이터로 파이썬 입문하기이고.

두 번째는 청와대 국민청원으로 자연어처리 입문이에요.

첫 번째 세션이기 때문에 이 공공데이터로 데이터분석 입문은 애드 투 마이드라이브로 해서 저는 제 드라이브이기 때문에 그 메뉴가 안 나오는데 내 드라이브로 추가를 해 주세요.

이 폴더를 통째로 내 드라이브로 추가를 해 주세요.

이게 추가가 잘 안 되시는 분들은 도우미 분들에게 도움을 요청을 해 주시면 돼요.

사본 만들기로 저장을 해 주세요.

내 드라이브로 사본을 만들어 가주세요.

오늘 공공데이터로 파이썬 데이터분석 입문하기는 노트북에 보면 네 개가 있어요.

순서대로 진행을 할 거예요.

전국신간아파트 분양동향가격부터 진행할 거고요.

다음으로 상가정보, 프랜차이즈 입점 분석, 전국도시공원 표준데이터 순으로 진행이 될 거예요.

50분 정도 진행을 하고 10분 정도 쉬는 시간을 갖고 50분, 10분 이렇게 쉬는 시간을 갖는 걸로 진행할 예정입니다.

뒤에 간식이 놓여있어요.

출출하신 분들은 간식을 드시면서 진행해 주시면 될 것 같아요.

오늘 여기에 오셔서 구글콜랩을 처음 사용하시는 분들이 많이 계실 것 같아요.

오늘 이 튜토리얼은 구글 Colaboratory를 중심으로 할 건데요.

왜 구글콜랩으로 진행하면요. 주피터 노트북을 사용하게 되면 저희가 오늘 실습시간이 3시간인데 설치하고 환경설정을 하느라고 세 시간을 다 보낼 수 있어요.

그래서 그런 시간을 절약하기 위해서 구글콜랩을 사용해서 실습을 진행할 예정입니다.

여기에 와이파이 정보가 떠 있어요.

와이파이 정보는 여기에도 있고.

앞하고 뒤에 종이패널에 또 와이파이 정보가 쓰여 있어요.

슬라이드가 지나가게 되면 저 종이 파일을 참고해 주셔도 되고.

이 슬라이드는 저희가 오늘 실습하는 폴더에도 같이 들어가 있어요.

그래서 슬라이드를 열어서 확인을 해 주셔도 됩니다.

실행이 되는지도 확인을 해 주세요.

노트북이 실행이 되는지.

사본을 설정했을 때 권한이 없어서 실행이 안 될 수도 있거든요.

그러면 내 드라이브로 다시 복사를 해서 권한이 있는 상태에서 실행을 하시면 실행이 될 거예요.

노트북이 실행이 안 되시는 분들은 도우미분들께 실행하는 방법을 물어봐주시면 돼요.

노트북 실행이 되는 거를 확인을 하고 세션을 시작하도록 하겠습니다.

노트북을 복사를 해 주시고요.

사본을 생성해 주시고 노트북을 실행하실 때는 여기 커넥트에 불이 들어와야 돼요.

노트북이 서버와 연결이 되어 있는 상태가 되어야지 커넥티드 상태가 되어야지 노트북을 실행할 수 있게 됩니다.

구글콜랩은 구글드라이브하고 똑같이 사용할 수 있어요.

구글드라이브에서 문서나 시트를 사용하는 것처럼 다른 사람과 내 문서를 공유하거나 협업해서 사용할 수 있고요.

오늘 제가 이렇게 노트북을 제공해드린 것처럼 여러분들도 노트북을 만들어서 URL을 공유하게 되면 다른 사람에게 제가 만든 노트북을 공유할 수 있습니다.

구글콜랩 노트북을 사본을 생성해서 본인 계정으로 복사를 해 주시고요.

오늘 사용할 도구는 파이썬3하고 Pandas, Plotnine 여기에 적혀져 있지는 않지만 Folio라고 사용할 거고요.

Anaconda 대신에 구글콜랩 노트북을 사용할 거예요.

튜토리얼에 사용될 노트북을 도우미분들에게 도움을 청해서 보고 복사를 해 주시고요.

애드 투 마이 드라이브로 복사를 해 주세요.

노트북의 실행권한이 없다면 내 드라이브로 세이브 어 카피 인 드라이브로 실행해서 해 주시면 내 드라이브에서 실행 권한이 생깁니다.

구글콜랩 노트북은 아까 제가 말씀드렸듯이 프레젠테이션 도구처럼 사용할 수 있어요.

그래서 메뉴에서 더보기를 누르면 콜래버레이터 메뉴가 보일 거예요.

메뉴가 보이지 않는 분들은 구글크롬에 앱스에서 웹스토어에 가셔서 Colaboratory를 검색하시면 Colaboratory를 설치할 수 있습니다.

아까 말씀드린 것처럼 첫 번째 세션에서는 전국신규민간아파트 분향동향, 상가업소정보, 프랜차이즈 입점 분석, 전국도시공원 데이터를 같이 볼 거예요.

사본 생성이 다 되셨나요?

아직 사본 생성 안 되신 분?

사본생성이 안 되신 분들은 도우미분들에게 사본 생성을 하는 거를 도움을 요청을 해 주세요.

여기에 보면 링크가 있는데요.

콜랩 리서치 구글닷컴이라는 링크가 있어요.

여기로 한번 들어가 보도록 할게요.

저는 최근에 제가 실행했던 노트북이 뜨는데요.

example에 가게 되면 오버뷰 콜랩 피쳐가 있어요.

콜랩이 어떤 건지 한번 잠시 살펴보고 가도록 할게요.

콜랩은 주피터 노트북을 온라인상에서 쓸 수 있도록 만들어진 툴이에요.

주피터 노트북을 사용해보신 분들이라면 오프라인에서 로컬에서 주피터 노트북을 사용했던 것과 비슷하게 이 콜랩 노트북을 사용하실 수 있고요.

여기는 문서와 도구를 주피터 노트북처럼 마크다운을 지원해요.

셀은 문서코드, 코드하고 텍스트가 있는데요. 코드와 텍스트를 실행해볼 수 있는 툴이에요.

코드를 누르면 코드를 생성할 수 있는 셀이 뜨고요.

텍스트를 클릭하면 텍스트를 쓸 수 있는 셀이 뜨게 됩니다.

이거는 구글에서 콜랩을 그냥 한번 훑어볼 수 있도록 만들어놓은 툴인데요.

여기에서 쉬프트 엔터를 치게 되면 각각의 셀을 실행해볼 수가 있어요.

지금 파이썬 작은 코드 조각이 하나 있는데요.

에이라는 변수에다가 10을 담았더니 아래 10이 찍히죠.

Anaconda에서 주피터 노트북을 사용했던 거하고 거의 비슷하게 사용을 해보실 수가 있어요.

여기에 보면 텍스트셀이라고 해서 가이드가 나오는데요.

엔터를 치게 되면 이렇게 마크다운 파일을 편집할 수 있는 화면이 뜨게 돼요.

다시 이 화면에서 쉬프트 엔터를 치게 되면 다시 이렇게 보이게 됩니다.

그래서 지금 코드셀하고 텍스트셀, 실행해보는 거를 간략하게 해보았고요.

다른 문서도 한번 보도록 할게요.

콜랩으로 다시 들어가서요.

example에 가서 보면, Chart in Colaboratory라고 있는데요.

이 Colaboratory에 가면 콜랩에서 사용한 예제를 모아놨어요.

Matplotlib으로 그래프를 시각화한 예제를 볼 수 있고요.

여기에서는 드라이브나 시트 연동해서 쓸 수 있는 것들이 모아져 있어요.

그리고 비쿼리나 폼을 사용할 수 있는 거라든지.

여기에서 사용하는 방법을 콜랩에 추가적인 사용방법을 더 공부해보고 싶으신 분들은 제가 링크해놓은 콜랩리서치의 콜랩닷컴에 들어가시면 이 콜랩의 사용문서가 뜹니다.

차트 인 콜래버레이터리 하나만 더 보고 넘어가도록 할게요.

차트 인 콜랩에 들어가서 보면, 이렇게 마크다운 문서로 생성된 문서가 왼쪽에 문서 구조에 따라서 뜨고요.

해당 내용을 클릭하면 그 내용에 해당되는 코르나 문서가 뜨게 됩니다.

Matplotlib으로 여러 가지 시각화된 도구들의 예제들을 볼 수 있고요.

이 예제를 보고 나중에 실습을 해보실 때 참고를 해서 사용을 해보실 수가 있어요.

콜래보레이터리에 대한 안내는 여기까지 드리는 걸로 하고요.

오늘은 Pandas라는 도구를 사용해서 분석을 주로 할 거예요.

보통 저희가 엑셀로 데이터를 많이 모아놓고 데이터분석을 하는데요. 

파이썬에서 비슷한 기능을 하는 게 Pandas예요.

키노트 연설을 하기도 했어요. 개발자가.

그래서 그 웨스매키니라는 개발자가 Pandas 10분 완성을 Pandas에 가이드문서에서 이 문서를 동영상으로 만들어놓은 게 있어요.

10분 동안 Pandas를 설명하는 동영상이 있는데요.

그 동영상이 10분 정도가 되지만 실제로 Pandas10을 실행해보려면 한 두 세 시간 정도가 걸려요.

데잇걸즈에서 이 문서를 번역을 해 주셨어요.

그래서 이 번역된 문서인 10 Pandas에 가셔서 Pandas를 학습해보실 수 있어요.

오늘 저희가 공공데이터 포털에서 데이터를 다운로드 받아서 데이터들을 열어봐서 볼 텐데요.

그런 데이터를 보고 요약해보고, 맷플로리의 일부 시각화 툴도 내장이 되어 있어요.

이 Matplotlib도 Pandas 안에서 사용해보실 수 있어요.

오늘 주로 사용할 툴은 Pandas, 데이터를 탐색하는 툴로 Pandas를 사용할 거예요.

Pandas에 대한 사용문서는 원본은 여기에 링크가 있고요.

한국어로 번역된 문서를 보시고 싶으시면 이 문서를 보시면 됩니다.

구글콜랩은 깃헙의 노트북을 콜랩으로 열어서 볼 수 있는 기능을 제공해요

제가 세 번째 실습을 할 때 이 실습을 해볼 예정이에요.

이거는 Folium에 대한 안내 문서인데요.

콜리움도 오늘 지리데이터를 사용할 거예요.

지리데이터를 사용할 때 조금 더 오늘 하는 실습 말고 다양한 표현을 하고 싶으신 분들은 이 도움말 문서를 사용해서 좀 더 다양한 시각화를 할 수 있을 것 같아요.

데이터를 공부하려면 일단 처음에 데이터가 필요한데요.

데이터를 얻기 가장 쉬운 곳이 공공데이터 포털일 것 같아요.

데이터를 연습해보기에 좋은 데이터들이 많이 들어있고요.

해외 데이터 같은 경우에는 많이 구할 수 있는 채널이 있는데, 국내 데이터 같은 경우에는 공공데이터포털이라든지 서울시데이터 사이트라든지 이런 곳들을 많이 활용할 수 있을 것 같아요.

오늘 제가 네 개의 노트북을 실습을 저와 함께하실 텐데요.

오늘 실습을 하신다고 해서 데이터분석을 자유롭게 하게 되기가 되게 어려워요.

그런데 오늘 실습의 목적은 같이 실습을 해보고, 여기에 있는 데이터셀을 하나를 다운로드 받아서 로컬에서 한번 불러와보고, 이 데이터를 오늘 했던 과정을 응용해서 실습을 해보시면 Pandas라든지 Matplotlib이라든지 Plotnine이라는 시각화툴을 사용할 텐데 그 시각화 툴을 사용하는 데 좀 더 익숙해지는데 도움이 될 것 같습니다. 오늘 데이터를 공공데이터포털에 있는 데이터를 아까 말씀드린 Pandas통해서 탐색하고요.

파이썬에 있는 시각화를 해 볼 건데.

이거는 앤스콤의 사인방이라는 그래프예요.

시각화를 하기에 앞서서 이 그래프를 소개를 해볼까 해서 소개를 하려고 해요여도

이 네 개의 그래프를 보면, 네 개의 그래프가 평균이라든지 표준편차, 코릴레이션, 여기에 보면 선형회기선이 있는데 그 회기선이 똑같아요.

통계적인 수치만 놓고 봤을 때 이 시각화를 하기 전에 그 수치만 놓고 봤을 때는 이 데이터는 같은 데이터라고 볼 수 있을 거예요.

막상 이렇게 시각화를 해보면, 스캐터 플롯으로 그렸을 때 이 데이터는 전혀 다른 데이터예요.

이 그래프가 보여주는 게 평균이나 표준편차 같은 회기선이 같다고 하더라도 실제로 시각화를 해보면 이 데이터들이 다른 모습을 하고 있다는 거를 설명을 하고 있는 그래프예요.

마지막 그래프 같은 경우에는 다 한 세 번째 칸에 데이터가 모여 있는데 맨 마지막에 있는 아웃라인 데이터 하나 때문에 회기선이 다른 그래프하고 마찬가지로 다르게 그려져 있는 거를 볼 수 있어요.

그래서 이 앤스콤의 사인방처럼 데이터를 다양하게 표현해놓은 재미있는 예제가 있어서 한번 소개해보고 싶어서 가져왔어요.

지금 여기 지아이에프로 그래프가 계속 바뀌고 있는 거를 볼 수가 있는데요.

데이터 사우루스라는 거예요.

공룡 모양으로 그려져 있는데요.

여기에 있는 그래프가 12개가 있는데요.

공룡까지 합치면 13개의 그래프가 있는 거죠.

이 그래프를 보면 엑스민값, 와이민값, 엑스 표준편차, 와이표준편차 그리고 마지막 값이 다 똑같아요.

통계적인 수치가 다 똑같은 거죠.

이런 그래프를 시각화해보지 않고 통계적인 수치만 놓고 봤을 때 이 데이터를 제대로 알기 어렵다는 거죠.

재미있는 예제라서 소개를 해보고 싶어서 데이터 사우로스를 소개해봤어요.

이것도 데이터 시각화를 할 때 되게 자주 등장하는 그래프예요.

이 지도가 뭔지 아시는 분?!

이 지도가 뭔지 아시는 분?!

있으실 것 같은데 (웃음)

이 지도 뭔지 아시는 분?

예! 한번 설명해 주시겠어요? (웃음)

-옛날에 우물과 병에 조사했던.

-정확하게 설명을 해 주셨는데.

이게 콜레라 지도라는 거예요.

그래서 영국에 의사가 콜레라가 영국에 발병이 많이 돼서 사람들이 많이 죽어 나갔죠.

그래서 의사가 집집마다 돌아다니면서 사망자 수를 시각화한 거예요.

지도에서 보면 특정, 브로드스트리트라는 곳에 사망자 수가 되게 많아요.

그래서 그 이유를 봤더니, 오른쪽 그래프에 보면 펌프라는 게 있어요.

물을 끌어올리는 펌프죠.

콜레라가 공기로 전염된다는 설이 있었는데, 사실 시각화를 해보니까 공기로 전염되는 게 아니라 저런 수도펌프를 통해서 콜레라가 전염이 되더라하는 원인을 발견했대요.

그래서 굉장히 시각화의 대표적인 사례로 소개가 되는 차트입니다.

재미있는 차트라서 소개해보고 싶어서 가져왔고요.

이거는 로즈다이어그램이라는 거예요. 장미처럼 생겼죠.

장미꽃잎처럼 생겼는데 이 다이어그램은 누가 만들었을까요?

앞에서 말씀해 주셨는데 (웃음)

나이팅게일이 만들어줬어요.

지금 답변 두 분이 해 주셨는데, 질문에 답변을 해 주신 분들께는 제가 책을 드리도록 할게요.

이따 끝나고 한 분 더 질문을 할 때 답변을 해 주시면 제가 책을 드리도록 하겠습니다.

책은 제가 드리는 건 아니고요. 파이콘 준비 위원회에서 드리는 겁니다.

이거는 나이팅게일이 전쟁 때 병원에서 환자들을 치료하면서 환자들의 사망원인 같은 거를 시각화한 그래프예요.

그래프를 보면 월이 쓰여 있어요.

August, September, October 이런 식으로 월이 쓰여 있고.

빨간색으로 된 부분이 있고, 검은 색으로 된 부분이 있고, 파란색으로 표시가 된 부분이 있어요.

이것도 앞에 그래프와 마찬가지로 사망자수를 시각화한 거거든요.

이 그래프 같은 경우에는 나이팅게일은 간호사로 알고 있잖아요.

그런데 전쟁에서 실제로 죽는 사람들이 부상으로 인해서 죽는 사람보다 감염에 의해서 죽는 사람이 더 많은 거예요.

사람들은 다 전쟁에서 다치는 부상으로 죽는다고 그 당시에는 생각을 했던 거죠.

그런데 나이팅게일이 실제로는 그게 아니라 세균이나 전염에 의해서 사람들이 많이 죽어나가는데 그거를 설득을 해서 병원의 환경을 개선해야 되는데, 그런 설득을 위한 자료로 이런 시각화를 한 거예요.

월별로 사망자 원인을 봤더니 빨간색으로 죽는 사람들보다 감염에 의해 죽는 사람이 훨씬 많죠.

여기에서도 보면 재미있는 게, 1~2월에는 원래 사망자수가 많았대요, 겨울에는.

그런데 사망자수가 원래 되게 많은데, 이렇게 면적으로 표시를 하게 되면 많고 적음이 그렇게 크게 보이지 않는 거예요.

그전의 그래프들은 면적이 아니라 길이로 표현을 했던 거예요.

그래서 길이로 표현하게 되면 차이가 더 커보이게 되는데 이렇게 표현하게 되면 차이가 좀 더 적어보이는 거죠.

그래서 위생 때문에 환경을 개선해야 된다는 걸로 사람들을 설득해서 병원의 위생을 개선하게 된 사례로 이 그래프를 가지고 왔습니다.

아직 쉬는 시간은 아니고요.

그러면 다시 신규민간아파트분양가격으로 돌아가서요.

오늘 파이썬으로 데이터 Pandas로 해보고 Plotnine이라는 툴로 시각화해볼 거예요.

오늘 첫 번째로 분석할 데이터는 링크로 가서 보시면, 전국신규민간아파트분양가격동향이라는 데이터예요.

저희는 여기 2018년 7월 데이터를 사용할 거고요.

두 개의 데이터를 사용할 거예요.

신규민간아파트분양가격에 가서 보면 7월이 있고, 6월이 있고, 각 월별로 데이터가 있어요. 데이터가 굉장히 많이 있어요.

그런데 여기 데이터를 다운로드 받아서 보면 각각의 월별로 한 달씩 데이터를 추가한 거예요.

그래서 데이터가 한 달씩 개월 수만큼 추가가 되어 있고, 더보기를 해서 보면.

이 때 데이터들이 또 쭉 많이 나와 있어요.

밑에 가면 에이치더블유피도 있어요.

그런데 오늘 분석에서 에이치더블유피로 된 자료는 사용하지 않을 거예요.

의외로 공공데이터포털은 에이치더블유피로 된 게 많아요.

재미있는 거는 에이치더블유피로 되어 있는 데이터로 실제로 활용하고 있는 곳이 여러 곳이 있더라고요.

그래서 에이치더블유피 파일을 열어보면 그 안에 표가 들어 있어요.

그 표에 있는 데이터를 다시 가져와서 csv 형태로 만들다든지 엑셀로 하든지 전처리해서 사용해도 되겠죠.

밑에 가보면 2013년 9월부터 2015년 9월까지 이런 데이터가 있는데요.

이 데이터를 열어보면 맨 위에 있는 데이터와 맨 아래에 있는 데이터를 열어보면, 그 안에 있는 데이터 형식도 다르고요. 모양도 다르고, 들어있는 데이터도 달라요.

분양가격에서 가장 최근 데이터를 다운로드를 받게 되면, 제가 이미 다운로드를 받아서 에스3에다가 올려놨어요.

여러분들은 에스3 경로를 Pandas에서 불러오셔서 쓰면 되고 제가 파일에 에스3 링크까지 다 해놨어요.

그래서 그냥 실행만 해놓으시면 될 텐데.

일단 이 데이터가 어떻게 생겼는지는 같이 보고 가면 좋을 것 같아요.

데이터를 보면 여기에 이렇게 미리보기를 할 수 있어요.

최근 데이터들은.

최근 데이터를 보면 지역명이 있고, 규모구분, 년도, 월, 분양가격이 있어요.

규모구분에 가면 전체, 그리고 규모에 따라서 데이터가 있고 분양가격이 제곱미터로 되어 있어요.

그런데 여기에는 2015년 10월부터 쭉 내려 보면. 쭉 내려 볼게요.

2017년 9월이 있고 여기에 보면 이렇게 비어있는 것도 있죠.

결측치도 있어요.

이렇게 데이터가 들어있는 거를 볼 수 있어요.

최근 데이터까지 들어가 있는 거를 볼 수 있고요.

과거 데이터는 미리보기가 없어요.

그래서 상태정보에 보면 미리보기가 없어요.

과거 데이터는 다운로드 받아서 노트북에서 볼 텐데요.

면적이 없어요.

면적 정보가 없고요.

그리고 또 없는 정보가, 또 다른 정보가 지역정보를 수도권 이렇게 요약해놓은 데이터가 있어요.

사실 그 요약된 데이터는 저희가 요약할 거기 때문에 없어도 되는데 그렇게 요약을 해놓고.

가격의 단위가 달라요.

최근 데이터는 제곱미터당 가격인데요. 그전의 데이터는 평당으로 되어 있어요.

한 2년 반, 2년 반씩 데이터가 두 개가 따로 들어 있거든요.

최근 5년간의 아파트분양가를 보고 싶잖아요.

그러면 이 두 데이터를 붙여야 될 거예요.

붙여서 봐야 되는데 다르게 생겼기 때문에 얘를 붙여서 보려면 전처리가 필요하겠죠.

그래서 그거를 어떻게 전처리를 할지 저희가 오늘 실습을 하면서 진행해보도록 할게요.

오늘 전국 신규 민간아파트 분양가격 동향을 첫 시간에서 진행을 할 거고요.

파이썬 도구로는 대표적으로 맷플로리가 있어요.

그런데 이거는 사용법이 복잡해서 씨번이라는 거를 사용해서 시각화를 많이 하세요.

그리고 캐글에 들어가서 다른 사람들이 분석해놓은 거를 보면 대부분은 씨그너로 분석해놓은 데이터들이 많아요.

그런데 오늘은 씨그너를 사용하지 않고 Plotnine을 사용할 거예요. 이거는 만들어진지가 얼마 되지 않았어요.

그래서 예제가 그렇게 풍부하지는 않아요.

하지만 Plotnine의 장점이 뭐냐면요.

혹시 여기에서 알을 사용해보신 분 있으세요? 알로 시각화를 해보신 분? 계신가요?

네.

그래서 알로 쓸 수 있는 문법을 똑같이 사용할 수 있어요.

비슷하게 사용할 수 있고.

알을 사용하셨던 분들이 파이썬에서 쉽게 시각화를 할 수 있도록.

아니면 파이썬를 사용하시던 분이 알로 넘어갔을 때 좀 더 쉽게 시각화를 할 수 있게.

왜냐하면 같은 문법을 사용하고 있기 때문에요.

Plotnine은 그램 오브 그래픽스라는 문법을 사용하고 있어요.

그래서 이렇게 쌓아올려서 시각화를 할 수 있는데.

이거는 이따가 그래프를 직접 그려보면서 이야기하도록 할게요.

첫 번째로 저희가 사용할 시각화 도구인 Plotnine을 설치하도록 할게요.

노트북을 실행하시려면 커넥티드도 되어 있으셔야 돼요.

그래서 일단 노트북이 커넥티드가 되어 있는지 잘 확인을 해보시고요.

노트북 실행이 잘 안 되시는 분들은 각 조에 도우미 분들이 계세요. 그래서 도움을 요청해 주시면 도우미 분들이 도와주실 거예요.

그래서 Plotnine을 설치했고요.

미씽노라는 것도 설치할 거예요.

미씽노를 개발하신 분이 아마도 포켓몬을 좋아하시는 분인 것 같아요.

미씽노라는 게 포켓몬에 나오더라고요.

그런데 이 미씽노는 여기에서는 어떤 걸로 쓰이냐면요.

결측치를 시각화해 주는 도구예요.

미씽노도 설치를 했고요.

콜랩의 장점은 Pandas라든지 논파이 맷플로리립이라든지 이런 기본적인 파이썬 데이터 분석 도구들이 설치가 되어 있어요, 미리.

그래서 이런 것들은 그냥 import를 하면 되고요.

import해서 애즈 pd. 별칭을 pd로 했어요.

Numpy는 np로 했어요.

파이썬에서 데이터를 탐색해볼 수 있는 도구고요.

이번 파이콘에서도 인생은 짧아요, 엑셀 대신 파이썬이라는 세션이 있었는데요.

엑셀처럼 사용할 수 있는 도구예요.

엑셀보다 더 많은 데이터를 자유롭게 탐색해볼 수가 있고요.

Numpy는 수치계산용 라이브러리예요.

그리고 re는 정규피씨를 사용하기 위해서 import했습니다.

그리고 콜랩을 사용하려면 한글폰트를 지원하지 않기 때문에 한글폰트를 설치해줘야 돼요.

한글폰트, 저는 나눔고딕을 사용하기 때문에 나눔고딕을 사용해줬고요.

나눔고딕을 설치를 하게 되면 이 경로에 나눔고딕이라는 파일이 설치가 돼요.

이 경로로 폰트프로퍼티를 사용해서 이 폰트를 불러오도록 했어요.

폰트를 설치해 주셔야지만 시각화를 하실 때 폰트가 한글폰트가 깨지지 않고 볼 수가 있어요.

만약에 이 폰트를 설치해 주시지 않게 되면 폰트가 다 깨져서 두부 모양으로 보이게 될 거예요.

네모 모양으로 폰트가 보이는데요.

실제로 그 폰트의 모양을 두부라고 부르더라고요, 정말 두부 모양이라서. 재미있었어요. 폰트를 두부라고 부른다는 게.

그리고 맷플로립의 기본 폰트를 나눔바른고딕으로 변경을 해 주도록 할게요.

만약에 저희가 주피터 노트북을 사용했다면 폰트 설치도 다 달랐을 거고 이 폰트 설정하는 데만 두 세 시간이 걸렸을 수도 있을 거예요.

폰트 설치도 좀 까다로워서.

그래서 콜랩을 설치하게 되면 다 같은 환경을 사용하기 때문에 설치에 대한 부담을 줄여줄 수 있다는 장점이 있어요.

첫 번째로 지금 불러온 이 데이터가 공공데이터포털에 있는 전국평균분양가격 데이터를 불러온 거예요.

뒤에 한글이라서 인코딩이 이렇게 돼서 보이는데요.

pre_sale하고 쉐이프.

Pandas에서 쉐이프를 찍게 되면요.

피디 점 리드 언더바 씨에스와이로 불러올 수 있고요.

이거를 pre_sale에 있는 데에 담아줬어요.

그리고 데이터 프레임이 쉐입을 찍어봤더니 2800의 행을 볼 수 있고요.

그리고 결측치를 시각화해보도록 할게요.

시각화해봤더니 지역명이라든지 규모구분 연도 월에는 결측치가 없어요.

그런데 분양가격에 이렇게 결측치들이 있는 거를 확인해볼 수가 있어요.

그래서 저희는 pre_sale라는 데이트프레임에 아까 파일의 내용을 다 담아줬어요.

그래서 여기에 섬을 하게 되면 분양가격에 131개의 데이터가 결측치가 있는 거를 볼 수 있어요.

2805행의 데이터 중에서 131개의 행이 결측치가 있는 거예요.

위에서 10개만 불러와보도록 할게요.

pre_sale에 점 헤드를 찍게 되면 위에서 있는 데이터를 미리보기를 해볼 수 있어요.

저희가 터미널에서 파일을 열어볼 때 헤드로 열어보잖아요. 그거랑 똑같이 Pandas에 이 헤드로 찍어볼 수 있고요.

헤드를 공백으로 해서 찍게 되면 기본 값이 5예요.

그래서 다섯 개의 데이터를 불러왔어요.

2015년 10월 데이터부터 있는 거를 볼 수 있고요.

뒤에서 5개를 점 테일로 불러오도록 해볼게요.

그러면 2018년 6월까지의 데이터가 있는 거를 볼 수가 있어요.

그리고 이 pre_sale의 인포라고 해서 인포를 찍어주게 되면 Pandas에서 다 인포로 데이터 프레임의 정보를 찍어보면요.

컬럼은 지역명, 규모구분, 연도, 월 분양가격이 있고 데이터 파일은 인트 오브젝트로 되어 있는 거를 볼 수 있어요.

여기에서 재미있는 게 있는데요.

지역명은 오브젝트 타일이 맞을 것 같아요.

그리고 규모구분은 얘도 오브젝트 타입인데요.

전용면적 60제곱미터 이하니까 얘도 오브젝트 타입이 적당할 것 같고요.

연도는 인트로 되어 있어요.

그리고 월도 인트로 되어 있어요.

그런데 분양가격이 오브젝트예요.

여기에 보면 분양가격이 숫자인데 오브젝트로 되어 있잖아요. 얘의 타입을 숫자로 변경할 필요가 있을 것 같아요.

분양가격을 일단 pre_sale 프라이스라는 데에 다시 담아주고요.

그리고 연도와 월은 저희가 보기에 숫자 데이터예요.

그런데 수치형 데이터이기는 하지만 저희가 얘를 시각화해줄 때는 카테고리 데이터로 쓸 거예요.

1월부터 12월까지 수치데이터로 쓰는 게 아니라 카테고리 데이터로 쓸 거거든요.

그래서 연도와 월을 인트 데이터가 아니라 그냥 스트림으로 변경해 주도록 할게요.

그리고 분양가격은 저희가 숫자로 사용할 거예요.

그래서 Pandas에 투 뉴메릭을 사용해서 숫자로 바꿔줄 거예요.

뒤에 나오는 데이터 같은 경우에는 최근 데이터는 제곱미터당 분양가격인데, 다음에 불러올 데이터는 평 분양가격이 될 거예요.

평당 분양가격이 좀 더 익숙하기 때문에 3.3을 곱해서 분양가격을 평당 분양가격으로 만들어주도록 할게요.

다시 인포를 찍어보면, 여기 평당 분양가격이 숫자타입 플롯 타입으로 바뀐 거를 보실 수 있어요.

평당 분양가격이라고 콜랩을 새로 만들어줬어요.

원래는 분양가격이라는 거까지만 있었는데 제곱미터의. 그런데 이 오브젝트 타입을 수치형 데이터로 바꿔서 제곱미터가 없는 분양가격이라는 새로운 컬럽을 만들어줬어요.

Pandas에서는 이렇게 새로 컬럽 명을 지정해 주고 시리즈 데이터를 넣어주게 되면 그 값이 변경이 돼요.

그래서 지금 평당 분양가격을 3.3을 곱해서 평당 분양가격을 만들어줬어요.

분양가격의 결측치가 많았는데 이렇게 수치형으로 만든 다음에 다시 해보니까 아까 131개이던 결측치가 223개로 늘었어요.

왜 그럴까요?

이거 말씀해 주실 분 계신가요?

이것도 책 한 권 드릴게요. (웃음)

아까 결측치가 131개였어요.

그런데 얘의 데이터 타입을 그냥 수치형으로 바꿔줬다고 해서 갑자기 결측치가 많이 늘어났어요. 왜 그럴까요?

네!

-뛰어쓰기가.

-아, 네 거의 맞추셨어요.

공백 데이터가 들어가 있었어요.

그런데 이 공백데이터가 그전에는 공백데이터를 데이터로 인식했는데 수치형 데이터로 바꿔주면서 그런 공백데이터들은 결측치로 바뀌게 된 거죠.

결값으로 바뀌어서 공백데이터들이 바뀐 거를 확인할 수가 있어요.

생각보다 아까 2805개 정도의 행을 가지고 있었는데 결측치가 생각보다 많이 있어요. 10% 가까이 결측치가 있는 걸 볼 수가 있어요.

그리고 여기 pre_sale에 디스크라이브를 해보면 디스크라이브를 해보게 되면 기본 값은 수치데이터에 대한 요약을 보여줘요.

여기에 옵션을 주게 되면 오브젝트 타입의 데이터 요약도 볼 수 있고요. 전체 데이터 요약도 볼 수 있어요. 그런데 전체 데이터의 요약은 카테고리 형태일 경우에 의미가 있지만 텍스트일 경우에는 의미가 없어요.

그래서 디스크라이브로 디폴트값이 수치형인 거를 볼 수 있는데 여기에 보면 기본적인 통계 값을 볼 수 있어요. 카운트 값, 민값, 최대 값, 최소 값, 그리고 4분의 1 값을 볼 수 있어요.

이렇게 요약된 값을 봤는데 제가 아까 데이터 사우루스를 소개드렸잖아요.

거기서 이런 수치형 데이터만을 보고 이 데이터를 판단하기 어렵

어렵다.

그래서 저희가 시각화를 해 볼 거예요.

일단 2017년 데이터만 보도록 할게요.

그런데 이 수치데이터 요약 내용을 안 보고 넘어갔네요.

여기를 보면 평당 분양가격이 평균 단위가 1000원인데요.

평당 분양가격이 1000만 원 정도가 좀 넘는 것 같아요.

전국의 평균분양가가 1000만 원 정도가 넘는 것 같고요.

서울의 평당 분양가는 생각보다 많이 비싸고, 지역 간의 편차도 크죠.

서울 같은 경우에는 구 단위로 나뉘어져 있는 게 좀 더 현실적인 것 같은데요.

여기 공공데이터포털에는 구 단위로까지는 나뉘어져 있지 않아요.

전국의 평균분양가는 1000만 원 정도 된다.

그리고 최대는 2006백만 원. 이것보다 더 될 것 같은데.

그래서 2017년 데이터만 보면요.

7개의 컬럼이.

2017년 데이터가 없네요.

연도. 아!

그래서 2017년의 데이터가 없네요.

일단 다음으로 넘어갈게요.

규모구분에서 베일류 카운트를 하게 되면 저희가 커리에서 그룹바잉을 해서.

-2017에 다운폴을 하면 나오는..

-아까 저희가 데이터를 스크림으로 바꿔서.. 감사합니다.

아까 데이터타입을 스트림으로 변경해줘서 지금 스트링으로 바꿔줬더니 값이 나왔어요.

데이터타입이 생각보다 데이터분석을 할 때 굉장히 중요해요.

시각화를 할 때도 그 데이터타입이 인트냐 아니면 수치형이냐 아니면 오브젝트형이냐에 따라서 표현이 다르게 돼요.

그래서 내가 원하는 표현으로 그래프를 시각화하기 위해서 타입을 일부러 바꿔주기도 해요.

그런데 아까 제가 2017을 스트링으로 바꿔줬던 거는 연속형이기는 하지만 카테고리에 더 가깝게 표현하고 싶어서 스트링 데이터로 변형해줬어요.

규모구분을 봤더니 데이터가 베일류 카운트를 하게 되면 그룹바잉을 해서 카운트를 해준 거하고 같은 결과를 얻을 수 있어요.

각각의 데이터들을 그룹바이에서 카운트를 해줬더니 전용면적 60이하, 뭐 이렇게 돼서 521개씩 데이터가 들어있는 거를 볼 수 있어요.

분양가격을 좀 쉽게 보기 위해서 중간에 이렇게 콤마를 하나 넣어줬어요.

그리고 디스크라이브를 해 주고 얘를 다시 티를 하게 되면 엑스축하고 와이축을 트랜스포즈를 해 주는 거예요.

둘을 바꿔서 한 번 더 다시 티를 해 주게 되면, 이 밑에서 셀을 하나 만들어서 다시 티를 해줄게요.

아.. 네.

이거를 다른 데 담은 다음에 티를 해줬어야 했는데 제가 그냥 티를 했네요.

그래서 이 pre_sale을 티를 안 한 거와 한 거의 차이를 보여드릴게요.

티를 빼고 볼게요.

그러면 이렇게 보여져요.

그런데 얘를 좀 더 보기 편하게 하기 위해서 둘을 바꿔주면 엑스축과 와이축을 이렇게 바꿔서 볼 수 있어요.

그래서 연도별로 분양가격과 평당 분양가격의 수치 값들을 비교해보려고 디스크라이브, 그룹바이를 한 다음에 디스크라이브를 해봤어요.

그리고 그 다음으로 규모별 평균 분양가격을 보도록 할게요.

당연히 면적이 큰 게 분양가격이 높겠죠.

그래서 규모별로 연도별로 봤을 때, 그냥 연도만 놓고 봤을 때 2015년에서 2018년으로 가면서 분양가격이 점점 높아지는 거를 확인해볼 수 있어요.

각각 모든 평수가 분양가격이 다 올라갔어요.

그리고 규모구분이 전체로 되어 있는 아이들이 있어요.

평당 말고 전체로 되어 있는 애들만 따로 보고 싶어서 새로운 데이터프레임에 담아줬어요.

지금 이렇게 왼쪽에 새로 변수를 생성해서 넣어주게 되면, 새로운 데이터프레임에 담기게 돼요.

새로운 데이터프레임에 담긴 애를 다시 또 만들어서 여기에 넣어줬어요.

아까 제가 세션을 시작할 때 Pandas는 엑셀하고 굉장히 비슷하다고 말씀을 드렸어요.

파이썬에 있는 엑셀과 비슷한 도구라고.

그래서 엑셀에 있는 피봇 테이블도 요약해볼 수 있어요.

그래서 이 피봇 테이블 만든 거를 새로운 데이터프레임에 넣어줬어요.

그리고 얘를 지역별로 연도별로 보는데요.

만들어준 이유는요.

해마다 분양가격이 계속 상승을 했는데, 어느 지역이 가장 많이 오르고, 어느 지역이 가장 적게 올랐는지를 보고 싶어서 이렇게 새로 데이터프레임을 만들어서 찍어준 거예요.

여기에 보면, 2015년부터 2018년까지 분양가는 계속 상승을 했어요.

그리고 여기에서 여기.

맥스델타 프라이스, 그리고 엔파이의 민 평균값을 구해서 천을 곱해줬어요.

그래서 변동액이 가장 큰 지역, 그리고 가장 적은 곳, 그리고 평균의 변동액을 구하도록 했어요.

15년부터 18년까지 분양가는 계속 상승했고 상승액이 가장 큰 지역은 어디죠? 제주.

제주도가 분양가가 가장 많이 상승을 했어요.

그리고 상승액이 가장 작은 지역은 울산이에요.

그런데 상승액이 가장 작은 지역이 사실 울산인지 제대로 이 데이터에서 알기 어려워요. 왜 그럴까요?

그거는 이따 시각화를 해보게 되면 답이 나오는데요.

왜 울산이 가장 여기서는 작게 변동했다고 나오잖아요. 변동이 거의 없거든요? 왜 그럴까요? 혹시 알 것 같은 분?!

왜 울산이 여기에서 가장 변동액이 적을까요?

책은 다 끝났어요.

이제 (웃음)

그래도 혹시 왜 가장 적냐면요.

울산은 결측치가 많이 있어요.

그래서 특정 평형대만 값이 있기 때문에 변동액이 0인 거예요.

변동액이 없는 구간이 있기 때문에 울산이 가장 변동액이 적은 거로 보여지는데요.

울산 다음으로 변동액이 적은 곳은 강원이에요.

강원도가 울산 다음으로 적게 오른 걸로 이 자료에서는 확인이 돼요.

그래서 이제 시각화를 해보려고 해요.

Pandas로 데이터를 요약해봤으니까, 연도별로 변동 그래프를 그려보도록 할게요.

쉬프트 엔터를 누르게 되면 엑셀이 실행이 되고 아니면 이 앞에 플레이 버튼을 눌러도 셀이 실행이 돼요.

그래서 이렇게 그래프를 그리는데.

알하고 문법은 약간 차이가 있는 점이 있어요.

얘는 끝에 양쪽 끝을 괄호로 감싸줘야 돼요, 그런 부분이 알하고 차이가 있는데 알하고 거의 비슷한 문법으로 사용해서 파이썬에서 데이터를 시각화해볼 수 있어요.

리젼 이얼 올이라고 새로 만들어준 데이터 프레임에서 엑스축은 지역명으로 지정하고요. 와이축은 평당 분양가격, 그리고 필은 연도로 했어요.

그 연도별로 그래프를 시각화해봤어요.

씨곤에서 보면 엑스축, 와이축.

여기에서는 필로 사용하고 있는 데이터를.

그래서 그렇게 연도별로 각각의 다른 값을 찍도록 했고요.

에스테틱에다가는 엑스축에 어떤 값을 지정하고, 지오메틱에는 반차트로 그리겠다.

그렇게 해서 포지션을 닷지로 한 거는 밑에서부터 그리겠다.

엑스축 0이 있는 이 밑 있잖아요.

밑에서부터 위로 그려올리겠다는 의미예요.

그렇게 해서 포지션 닷지로 해서 타이틀은 신규민간아파트분양가격으로 하겠다.

15년부터 18년까지.

폰트프로퍼티에 폰트를 지정해줬는데, 이 폰트는 우리가 노트북을 처음 실행할 때 위에서 나눔고딕을 설치하고 폰트프로퍼티를 변수에 넣어줬어요.

그래서 폰트로 설정해준 얘를 폰트프로퍼티에 넣어줬어요.

그래서 피겨사이즈, 이 그래프의 사이즈는 8, 4로 지정했고요.

그래프를 그리게 되면, 전국적으로 그래도 분양가가 가장 높은 지역은 서울이죠.

서울이 가장 분양가가 높고요.

그다음에 보면 2015년부터 2018년까지 꾸준히 분양가가 상승한 거를 알 수 있어요.

아파트 분양가가 계속 꾸준히 상승했고요.

울산이 결측치가 많다고 했는데, 울산을 보면요.

이렇게.

그런데 이 그래프 상에서는 인천이 변동 폭이 더 작아 보이는데 울산이 결측치가 많아서.

일단 그래프로 표현했을 때는 그렇고요.

변동액이 가장 큰 지역이 디스크라이브를 해서 봤을 때 그리고 디스크라이브를 해서 차이 값을 여기에서 구해서 맥스 값을 구했을 때 제주도가 가장 많이 올랐잖아요.

그래서 제주도를 보면요.

여기인데요.

제주도가 2015년에서 2016년에 네모 한 칸이 되게 크잖아요.

이 네모 한 칸만큼 올라간 게 보여지세요?

제주도가 2015년에서 16년에 굉장히 많이 올랐어요.

전국적으로 가장 분양가가 많이 오른 지역이고요.

그다음에 지역별 평당 분양가격 합계액을 보도록 할게요.

지역별로 보면 이렇게 쭉 나열이 되어 있으니까 눈에 잘 안 들어오잖아요.

규모별로도 한번 보도록 할게요.

규모별로 보면, 어떤 지역은 큰 평형대가 분양가가 높은 지역이 있고 어떤 지역은 작은 평형대가 분양가가 높은 지역이 있어요.

서울을 보면 85제곱미터 초과에서 102제곱미터까지가 가장 분양가가 높아요.

같은 평형대별로 지역별로 보면 인기 있는 평형대가 면적비율이 다 달라요.

제주도 같은 경우에는 연두색이 가장 높잖아요.

전용면적 60제곱미터 이하.

제주도는 작은 평형대가 분양가가 좀 높은 편이에요.

그리고 인천은 좀 큰 평수가 분양가가 높아요.

그래서 평형대별로 인기가, 선호하는 평형대가 다른 것 같아요.

그다음으로 여기에 보면 팩스랩이라고 해서 지역명으로 팩스랩을 지정해줬어요.

이렇게 지정을 해 주면 지역별로 그래프를 그리게 돼요.

그래서 지역별로 그리게 되면, 서울에서 엑스, 와이축은 연도와 평당 분양가격으로 했고요. 규모구분을 필에 넣어줬어요.

규모구분별로 엑스축은 연도, 와이축은 평당 분양가격.

그래서 지역별로 그래프를 따로 구해볼 수가 있어요.

보면, 이 그래프를 보다 보면요.

이가 빠진 애들이 있어요.

전국데이터를 보다보면 세종시 같은 경우에는 15년부터 있는데요.

15년 9월부터 있거든요.

15년도에 보면 앞부분이 많이 이가 빠져 있어요.

그렇죠?

이런 데이터들이 보통 결측치예요.

그래서 울산이 변동 폭이 가장 작았었잖아요.

울산을 한번 찾아보도록 할게요.

울산을 보면, 최근 2018년 데이터, 2017년 데이터에 이가 굉장히 많이 빠져 있어요.

그래서 울산 같은 경우에는 특정 평형대의 값이 많이 빠져있기 때문에 결측치가 많이 있다는 거를 알 수 있어요.

대전도 결측치가 좀 있고요.

광주. 아, 아까 세종시가 아니라 광주였네요.

광주에 이렇게 결측치가 있어요.

지역별로 어디의 결측치가 있는지를 알 수 있어요.

다음으로, 박스플롯을 그려보도록 할게요.

디스크라이브로 해서 4분의 1수를 그려봤잖아요.

그 4분의 1수를 박스플롯으로 그린 거예요.

지역별로 봤을 때 아까 울산이 가장 변동액이 적었잖아요.

울산을 한번 보도록 할게요.

울산은 이렇게 그냥 선으로 그어져있는 부분이 있는데, 아마도 이 부분이 결측치일 것 같아요.

그리고 가장 변동 폭이 컸던 지역이 어디였죠? 제주였죠.

제주를 보면, 연두색이 아마 60제곱미터 이하인데 이 부분이 변동액이 굉장히 커요.

그래서 제주도를 봤을 때 변동액이 좀 큰 편이고.

대구 같은 경우에는 102 제곱미터 초과가 변동액이 커요.

이런 것들을 박스플롯으로 어디가 언제.

여기에 보면 연도예요.

순서대로 연도별로 언제.. 아 평당 분양가격이네.

지역명별로, 규모구분별로 어디가 변동액이 큰지를 봤습니다.

그리고 서울만 따로 보도록 할게요.

여기 pre_sale이라는 데이터프레임에서 지역명이 서울인 애만 따로 데이터프레임을 뽑아와서 pre_sale_서울이라고 해서 데이터를 따로 만들어줬어요.

그래서 서울만 따로 찍어봤어요.

언제 가장 집값이 많이 오른 것 같나요, 서울은?

분양가격이. 집값은 아니고 분양가격이요.

15년, 16년, 17년 다 변동액이 커 보여요.

18년은 변동액이 작아 보이는데 이것도 함정이 있어요.

무슨 함정이 있을까요?

네?

올해 전체 데이터가 있지가 않아요.

그래서 이 데이터만으로는 올 한해의 변동액이 얼마나 컸는지는, 아까 7월 데이터까지가 있었던 걸로 기억하는데요.

전체 데이터를 놓고 비교를 했을 때는 이거하고는 좀 더 다른 값이 될 것 같아요.

변동액이 가장 컸던 제주를 한번 보도록 할게요.

제주는 60제곱미터 이하가 가장 인기가 많았어요.

15년에는 변동액이 별로 없어보여요.

아까 위에 그래프를 보게 되면 아마도 결측치가 있을 수도 있을 것 같아요.

제주도에 결측치가 있는지 위에 그래프를 보면 15년도에 역시나 결측치가 있네요.

그리고 18년도에도 결측치가 있어요. 파란색, 85제곱미터 초과 102제곱미터 이하의.

그래서 제주도도 이렇게 찍어봤을 때요.

이렇게 선으로 표시가 되는 부분들은 결측치로 표기가 되었다는 거를 확인해볼 수가 있어요.

그리고 변동액이 가장 작았던 울산을 보면요.

18년 데이터 같은 경우에는 다 선으로 되어 있죠.

2018년 데이터의 결측치가 많이 있는 거를 볼 수 있어요.

그래서 지금 2015년 9월부터 2018년 상반기까지의 데이터를 봤는데요.

2013년 12월부터 2015년 9월까지의 데이터를 불러오도록 할게요.

데이터를 불러올 때 리드 언더바 씨에스를 해 주고 인코딩을 이유씨케이알로 지정해줬어요.

최근 국민청원에서 김설미를 김설미라고 부르지 못하는 그런 기사 보신 분 계신가요?

공공데이터포털에 있는 데이터 중에도 이유씨케이알로 된 데이터들이 상당히 많이 있더라고요.

스킵으로는 1 헤더는 명 이렇게 해서 이 데이터 같은 경우에는 컬럽값이 첫 번째 로우에 들어 있잖아요.

보통 첫 번째 로우에 컬럽값이 들어 있으면 얘를 리드 언더바 csv로 불러왔을 때 자동으로 컬럽으로 인식해요.

그런데 얘 같은 경우에는 그냥 언네임드로 되어 있거든요.

우리가 필요한 컬럼은 여기에 있는 것 같은데, 여기에도 보면 넌값이 있는 게 있어요.

2013년 14년하고 뒤에는 쭉 비어있어요.

여기에 연도가 있고 그 다음에 맨 끝에는 3.3제곱미터 이렇게 단위. 천 원씩이고.

그리고 전월비, 전년 동비. 이렇게 되어 있어요.

이 데이터를 2013년 12월 데이터부터 있는데 어떻게 보면 2014년부터 있는 거죠.

그래서 최근 데이터까지 붙여줘야 되잖아요.

그런데 아까 처음에 가져왔던 공공데이터포털에서 상세보기를 보도록 할게요.

여기에는 이렇게 아까 가져왔던 데이터는 이렇게 생겼어요.

그런데 지금 가져온 데이터는 이렇게 생겼어요.

그래서 얘를 어떻게 합쳐주는 게 좋을까요?

컬럼명을 통일되게 맞춰주는 게 좋겠죠.

그리고 얘가 가지고 있는 데이터는 지역, 규모, 연도, 월 분양가격이죠.

합칠 데이터가 있는지 찾아봐야 될 것 같아요.

여기에는 연, 월이 있기는 한데 위에 이렇게 있고 여기는 비어져 있고요. 이 빈 결측치도 채워줘야겠죠.

그리고 지역도 보면 시군구가 따로 나뉘어져 있어요. 그리고 한쪽이 채워져 있으면 한쪽은 비워져 있으니까 얘도 합쳐줘야겠죠.

일단 지역명도 전처리를 해줘야 되고 연월도 전처리를 해 줄 필요가 있을 것 같아요.

그래서 얘를 전처리를 해주도록 할게요.

일단 이어하고 번스를 0번째, 첫 번째.

여기에 보면 영번째, 첫 번째의 로우를 얘는 연도로 가져오고 얘는 월로 해서 일단 이어하고 먼스라는 변수를 가져왔어요.

그래서 이어를 그냥 찍어보면, 이렇게 엔에이엔으로 결측치로 되어 있는데 이 값을 채워주면 될 것 같아요.

2014년에서 4번부터 14번까지는 2014년으로 채워주면 되겠죠.

그리고 16번부터 25번까지는 2015년으로 채워주면 될 것 같아요.

이어하고 먼스를 돌게 했어요.

그러면서 수동으로 채워주기를 했어요.

폼을 돌면서.

아까 제가 말했던 번호대로 돌면서 2014년, 15년을 채우고 나머지도 이렇게 채우고.

그렇게 해서 아까 비어있던 값들, 엔에이엔 값들을 이렇게 채워줬어요.

그리고 이 컬럼을 얘는 이어에다 다 넣어줬거든요, 값을.

그래서 이 컬럼을 이어로 지정해줬어요.

아까 있었던 0번째와 첫 번째를 드럼을 시키고요.

컬럼의 이름을 다시 지정해줬어요, 이어로.

그리고 영 번째와 첫 번째를 하니까 컬럼명이 컬럼명다워졌어요.

지역 컬럼을 새로 만들어서 시도와 시군구도 합쳐주도록 할게요.

여기에 보면 둘 중에 하나만 들어가 있잖아요. 얘도 합쳐줄 거예요.

그래서 이렇게 합쳐주고요.

지역이라는 컬럼을 새로 만들었어요.

이 두 개의 값을 붙여서 넣어줬어요.

여기에 보면 비어있는 값이 있고 6대광역시부산으로 되어 있는 것도 있고 지방강원으로 되어 있는 것도 있어요.

이런 값들도 전처리를 해 줄 필요가 있을 것 같아요.

그래서 그 컬럼값만 따로 카피를 해서 멜트컬럼스라고 지정해줬어요.

얘네는 멜트 시킬 때 컬럼으로 할 애들이에요.

지역을 아이디로 쓰고 베일류에다가 이 값을 넣어주겠다.

지역의 이 연도를 아까 컬럼에 되어 있던 애들을 다 로우로 미뤄졌어요. 녹여줬어요.

그래서 알에서는 이런 과정을 타일데이터 만들기라고 부르더라고요.

알에 있는 타일데이터 만들기를 멜트를 사용해서 컬럼에 있는 값들을 다 로우로 넣어줬어요.

컬럼명도 지역, 기관, 분양가로 해서 다시 컬럼명을 지정해줬고요.

그리고 여기에서 연이라고 되어 있던 값들을 연으로 되어 있던 값에서 스크림을 해서 연으로 넣어주고요.

그리고 월 앞에 있는 연과 월 사이에 있는 이 데이터는 월이라는 컬럼을 만들어서 연도와 월이라는 새로운 컬럼을 만들어서 넣어줬어요.

이렇게 해서 만들었더니 지역, 기관, 분양가, 연도월 이렇게 만들어졌어요.

그랬더니 공공데이터포털에 있는 연도월은 일단 맞춰졌죠.

그리고 여기는 지역명으로 되어 있어요.

그래서 지역명만 맞춰주면 될 것 같아요.

아, 분양가도 있네요.

아까는 위에서 평당 분양가격이라고 만들어줬었는데.

일단 지역부터 정리를 해보도록 할게요.

베일류 카운터를 해서 보면, 이렇게 지역들이 쭉 나오는데 6대광역시부산, 지방강원이라는 애가 있어요.

6대광역시부산은 부산으로, 지방강원은 강원으로.

이 실습을 시작하기 전에 import 알이로 하기 위해서 알이로 import를 해줬어요.

그래서 여기서 6대광역시부산은 부산으로 지방강원은 강원으로 해서 Pandas에 있는 어플라이를 사용해서 이 어플라이 안에 함수를 적어줄 수 있어요.

그래서 이런 값들을 데이터전처리를 해줬어요.

그 값이 조금 더 그전에 있던 데이터와 비슷해졌어요.

이거를 보면 아까와 같은 다르게 아까는 사분의 수가 보였는데 여기서는 안 보이고 이렇게 보여요.

이렇게 나오는 이유가 뭘까요?

앞에서 되게 작게 말씀해 주셨는데, 데이터타입이 달라서 그래요.

얘의 데이터타입을 한번 보도록 할게요.

다 오브젝트로 되어 있어요.

그래서 데이터타입 때문에 이렇게 되어 있는 거고요.

분양가는 분양 수치형 데이터이기 때문에 분양가격으로 해서 인트로 바꿔주도록 할게요.

그리고 2013년부터 15년까지의 합쳐준 데이터를 아, 2014년부터 15년까지의 데이터를 그려보고요.

그리고 이렇게 멜트시킨 데이터를 시각화를 해보았어요.

멜트를 시키지 않으면 기존의 데이터로는 우리가 꼭 붙이지 않는다고 하더라도 시각화를 하려면 이렇게 멜트하는 과정이 필요해요.

그래서 멜트를 시키고 시각화를 해 본 다음에.

2013년부터 18년까지.

4월로 되어 있는데. 그전 데이터가 되어 있어서 잘못 되어 있는데.

2018년 데이터까지 보도록 할게요.

헤드 말고 테일을 찍어볼게요.

2015년..

2018년 6월까지 있어요. 4월이 아니니까 여기도 고치도록 할게요.

고칠 때는 엔터를 누르면 고쳐지고요.

여기서 편집을 누르면 반영이 돼요.

2018년 6월까지의 데이터를 합칠 준비가 되었어요.

그래서 이렇게 데이터.

2015년부터 18년까지의 데이터를 보고요.

컬럼을 보면 이렇게 컬럼이 13년부터 15년까지의 컬럼이 이렇게 되어 있고요.

컬럼명이 같은지를, 컬럼명을 같이 맞춰주도록 할게요. 지역명, 연도, 월, 분양가격으로요.

그래서 컬럼명을 찍어보면 컬럼이 추가로 생겨있는 게, 바뀌어져 있는 거를 볼 수 있고요.

2015년부터 2018년까지 지역명, 연도, 월 평당 분양가격을 디스크라이브를 해보도록 할게요.

아까는 디스크라이브를 했을 때 보여지는 게 달랐어요.

오브젝트 타입일 때 프리퀀시 값이라든지 그런 게 보였었는데 지금은 다시 카운트값, 민값, 4분의 수랑, 최댓값, 최솟값을 볼 수 있어요.

그래서 이렇게 준비된 두 개의 데이터를 13년부터 15년, 15년부터 18년까지 두 개를 붙이도록 할게요.

Pandas에 보면 머지하고 컨캣이 있어요.

머지와 컨캣의 차이점을 이야기해줄 수 있는 분?

아, 손 드신 게 아니었나요? (웃음)

머지는 이쪽에 다른 컬럼들이 있을 때 컬럼끼리 합칠 때 머지를 주로 사용하고요.

인덱스별로 위아래에 있는 데이터를 불일 때는, 행을 붙일 때는, 컨캣을 사용하게 돼요.

컨캣은 다른 실습할 때도 다시 등장을 하게 될 거예요.

그래서 데이터프레임을 합쳐줬고요.

합친 데이터프레임을 봤더니 헤드를 찍었을 때 2013년 12월부터 있고요. 2018년 6월까지 있는 거를 확인할 수 있어요.

13년부터 18년까지 데이터가 두 개로 분리가 되어 있었고, 데이터 형태도 완전히 달랐어요.

그런데 이 데이터를 전처리를 해서 같은 형태로 만들어서 하나의 데이터프레임으로 만들어주었고요.

지역명을 유니크값을 찍어보면 지역명이 좀 달라요.

그래서 다른 지역명을 뽑아보면요.

전국, 그리고 공백, 수도권 이렇게 지역명이 있어요.

이런 지역명도 전처리를 해 주면 더 좋겠죠.

그래서 지역명이 전국하고 수도권인 애들만 따로 뽑아봤어요.

이런 값들이 있고요.

그래서 전국하고 수도권인 데이터는 드랍을 시키도록 할게요.

왜냐하면 그전 데이터에만 있기 때문에 얘는 삭제를 하고 다시 시각화를 해보도록 거래예요.

(해보도록 할게요.)

아까는 15년 후반기 데이터부터 18년까지의 데이터가 앞에 있던 데이터하고 합쳐져서 2013년 12월 데이터부터 18년 6월까지의 데이터가 그래프로 시각화된 거를 볼 수가 있는데요.

이걸로 봤을 때 전국적으로 꾸준히 분양가가 상승한 걸로 볼 수 있어요.

지역별로 편차가 있기 때문에 지역별로 보는 게 더 좋겠죠.

그래서 엑스축에 지역명을 두고 평당 분양가격을 연도별로 봤어요.

그랬더니 13년부터 18년까지 전국적으로 계속 상승하고 있는 거를 볼 수가 있습니다.

14년부터 18년까지 박스플롯을 그려보면요.

역시 계속 상승을 하고 있어요.

가운데 선 평균값들이 계속 증가하는 거를 볼 수 있고요.

그리고 가장 상승폭이 컸던 제주를 보면요.

16년도에 상승폭이 좀 컸던 걸로 보여지고요.

역시나 마찬가지로 위에서 지역별로 맷을 지정해서 했는데, 여기서 그 그래프를 박스플롯으로 다시 한 번 그려보도록 할게요.

지역별로 그려보면요.

아까 울산 같은 경우에는 거의 선으로 보여지는데요.

이런 지역들은 보통 결측치가 좀 있는 지역들은 이렇게 보여지는 거를 볼 수 있어요.

첫 번째 노트북은 여기까지예요.

최근 5년간의 아파트분양가를 공공데이터 포털에 올라와있는 데이터를 통해서 분양가가 어떻게 얼마나 상승을 했는지를 봤는데요.

사실 이 데이터만 두고 봤을 때는 계속 분양가가 오른다고만 볼 수는 없어요.

분양가가 안 올랐던 해도 있고, 거의 상승액이 미미했던 해도 있었고, 최근 10년간의 집값을 두고 봤을 때 계속 오르지만 하지 않았거든요. 최근에는 계속 오르기는 했지만.

그래서 최근 10년, 20년의 데이터를 두고 봤으면 좀 더 좋았을 텐데 공공데이터포털에 올라와있는 최근 엑셀이라든지 csv 형태로 되어 있는 데이터들은 13년부터 볼 수가 있어서 13년부터 18년까지.

2013년 같은 경우에는 12월의 데이터부터 있어요.

그래서 월별로 변화추이를 보면 좀 더 다른 추이를 볼 수 있을 것 같은데요.

그런 분석도 추가적으로 해보시면 좋을 것 같아요.

시간이 1시부터 시작을 해서 제가 50분하고 10분을 쉬려고 했는데 한 시간 반을 진행을 했어요.

그래서 준비한 노트북이 네 개인데 이 네 개를 다 할 수 있을지 모르겠어요.

그래서 일단 10분간 40분까지 쉬는 시간을 갖고요. 40분부터 그 다음 두 번째 노트북을 진행하도록 하겠습니다.

감사합니다.

(박수)

45분이 다 돼서 다시 시작을 해보도록 할게요.

두 번째 노트북을 열어주시면 되고요.

이번 두 번째 하고 세 번째는 같은 데이터를 사용해서 할 거예요.

두 번째 하고 세 번째는 어떤 거를 해볼 거냐면요.

그냥 상가업소정보 데이터가 있어요.

공공데이터포털에 역시나 이 링크를 따라 가다보면, 소상공인시장진흥공단 상가업소정보가 있는데요.

여기에 어떤 데이터가 있는지 일단 한번 살펴보고.

여기에 데이터를 보면 위경도 값이 나와요.

위경도 값으로 해볼 수 있는 것들을 지리데이터를 조금 다뤄보도록 해요.

아까 보면 지난 세션에서 존스노우의 콜레라 지도를 같이 봤었는데요.

지도에 뭔가 시각적으로 표기를 해놨었잖아요.

저희도 지도에 점을 찍어서 어떤 상가정보, 업소정보가 있는지를 2번하고 3번 실습은 이어진 실습이라고 보시면 돼요.

같이 진행할 거고요.

두 번째 노트북인 상가업소정보를 시작하기에 앞서서 콜랩의 단점이 이 라이브러리를 노트북 안에 설치를 해줘야 된다는 거예요.

그거는 좀 단점인 것 같아요.

만약에 주피터 노트북으로 로컬에서 사용하신다고 하면 설치를 해놔서 import해서 사용하시기만 하면 되는데.

콜랩은 노트북을 실행할 때마다 설치를 이렇게 해줘야 된다는 게 좀 단점인 것 같아요.

Pandas와 Plotnine을 import해보도록 할게요.

위에서 Plotnine을 설치해줬고요.

역시나 한글폰트도 새로 설치를 해줘야 돼요.

번거롭긴 한데 설치해줬고요.

여기에 Plotnine의 import를 또 해줬는데, 중복으로 해주게 됐네요.

폰트설치를 해 주고요.

기본글꼴을 저는 나눔바른고딕으로 변경해 주도록 할게요.

콜랩 노트북도 계속 바뀌고 있어요.

그래서 없던 기능이 쓸 때마다 새로운 기능이 하나씩 하나씩 보이는데요.

제가 여름에 파이콘에서 튜토리얼 진행할 때만 해도 맷플로리에서 설정하는 거는 안 해줘도 폰트가 로드가 됐었는데 노트북이 바뀌어서 기본글꼴을 또 변경을 해줘야지만 설정이 되더라고요.

그래서 나눔고딕으로 기본글꼴을 변경을 해 주었고요.

2번 데이터 같은 경우에도 공공데이터포털에서 여러분들이 다운로드 csv 파일을 다운로드 받아서 할 수 있는데.

로컬에서 주피터 노트북에서 돌려보실 때는 파일을 다운로드 받아서 사용하시고 여기서는 제가 에스3에다가 미리 csv 파일을 올려놨어요.

그래서 데이터를 불러왔어요.

공공데이터포털에 이 데이터들이 올려있을 때 어떤 인코딩으로 되어 있는지 미리 알려주면 좋을 것 같은데 따로 표기가 되어 있지 않아요. 그런데 대부분 씨피 949로 되어 있는 편이에요.

그래서 인코딩을 만약에 불러올 때 안 불러와진다고 하면 디폴트값이 이러니까 변경해서 불러오시면 돼요.

그래서 이번에도 2018년 6월 데이터인데요.

그전에 썼던 데이터, 2017년 9월 데이터를 변경을 해놨어야 했는데 안 했는데 실수고요.

2017년 9월 1번 데이터로 해서요.

여기 데이터를 다운로드 받게 되면 짚파일로 되어 있는데요. 그 짚파일 안에 네 개의 csv 파일이 들어 있어요.

그 csv 파일 중에 첫 번째 csv 파일을 불러와서 쉐이프를 찍어보게 되면요.

몇 건의 데이터가 되는지 한번 세어볼게요. 47만 6천 183건의 데이터가 있어요.

그래서 이 데이터를 아까와 마찬가지로.

일단 데이터를 불러오면 헤드하고 테일로 그 데이터를 미리보기를 해봐요.

전부 다 찍어보면 너무 오래 걸리고요.

로드가 되다가 멈춰버리는 수가 있기 때문에요.

일단 헤드와 테일만 찍어봐요.

저희 크로닝한 데이터를 터미널에서 열어볼 때도 한번에 열면 터미널이 멈추거나 가끔 아이들 상태에 빠지는데요.

앞에서 세 개만 불러와서 보도록 할게요.

여기에 보면 상호명, 지점명, 이런 정보들이 눈에 띄고요.

어떤 데이터를 쓸 수 있을지를 위에서 다섯 개만 보고 한번 훑어볼게요.

우편번호 정보도 있고요.

동정보, 주소정보, 상권업종분류코드가 있고, 중분류, 후분류 이런 것들이 있어요.

이 데이터로 뭘 할 수 있을지 한번 생각을 해볼게요.

테일로 뒤에서 세 개만 찍도록 했어요.

아까 말씀드렸듯이 여기에 숫자를 지정해 주지 않으면 기본값은 5예요.

기본값으로 5개를 불러오면 아까 위에 데이터는 헤드로 불러왔을 때 부산, 서울, 서울 이렇게 있었는데.

이번에 테일로 불러오니까 서울시 강동구, 은평구 부산광역시 이런 데이터로 되어 있어요.

분류를 보면, 숙박, 생활서비스, 소매 이런 게 있고요.

앞에 보면 상호명도 있어요.

그래서 어떤 상호가 있는지도 보았고요.

결측치를 한번 보도록 할게요.

결측치를 보면요.

썸을 하게 되면 결측치를 볼 수 있는데요.

생각보다 결측치가 많이 있어요.

지점명이라든지, 표준산업분류코드라든지, 분류명, 지번부번지, 건물부번지, 동정보, 후정보 이런 게 있어요.

데이터를 보다보면 생각보다 결측치를 많이 마주하게 되는데요.

결측치 같은 경우에는 일부러 누락이 되어서 수집이 안 됐을 수도 있고 아니면 필요 없는 데이터일 수도 있고, 혹은 결측치를 보완해줘서 좀 더 나는 결과가 될 수 있기는 한데.

저희는 여기서 결측치를 채운다든지 하는 작업은 하지 않을 거고요. 여기에 있는 정보를 가지고 결측치가 많은 정보는 사용하지 않을 거예요.

그래서 상호명도 하나는 결측치가 있네요.

지점명 같은 것도 사실은 그렇게 큰 필요는 없을 것 같아요.

그래서 위도와 경도 정보가 있기 때문에 위경도를 엑스축에 경도를 주고, 와이축에 위도를 줘서 아까처럼 ggplot으로 해서 그래프를 스캐터플로 찍어볼 거예요.

그런데 여기에 전부 다 아까 40만 건이 넘었는데요.

이 40만 건을 한번에 다 찍으면 정말 오래 걸려요.

그래서 천 건만 위에서 천 건만 슬라이스를 해서.

슬라이스를 하게 되면 천 건만 가져오게 되거든요.

천 건만 슬라이스를 해서 찍도록 했어요.

찍어보니까, 어떤 걸 찍은 것 같으세요?

예. 맞아요.

서울, 부산이에요.

이 데이터는 서울하고 부산 데이터만 있어요.

아까 제가 말씀드렸는데 공공데이터포털에서 데이터를 다운로드 받으면 csv 파일이 네 개가 들어 가 있어요.

그래서 다른 세 개의 파일에는 다른 지역의 파일들이 들어 가 있어요.

그래서 이 데이터는 서울과 부산만 있는 데이터예요.

서울과 서울이 아닌 데이터로 한번 나눠보려고 해요.

스타트위스 해서 서울로 시작하는 단어.

그런데 여기에 물결표시를 주게 되면요.

서울 아닌 거에 대한 것만 뽑게 돼요. 서울인 거와 서울이 아닌 거 두 개에 대한 새로운 데이터프레임을 넣어줬어요.

그랬더니 아까 48만 이렇게 있었는데, 33만 건, 14만 건 이렇게 나뉘는 거를 볼 수가 있어요.

그리고 이 데이터를 서울 데이터프레임을 따로 만들어줬는데요.

데이터프레임을 위경도로 찍어줬어요.

해서 알파값은 얘의 투명도고요.

사이즈는 0.2도 해서 스캐터플롯을 찍어보도록 할게요.

그래서 서울만 찍었더니 스캐터플롯에 위경도로 찍었어요.

그랬더니 서울지도 같은가요?

서울 같죠.

서울 데이터만 있어요.

여기에 도로명주소를 가지고 시도와 구군을 따로 컬럼을 만들어보려고 해요. 

시도와 구군을 여기서 스플릿을 공백으로 했어요.

도로명 주소에서 보면 서울시 무슨 구 이렇게 있잖아요.

거기에서 도로명주소를 가지고 0과 1로 나눠서 첫 번째는 거를 시도에 그 다음 거를 구군에다가.

0번 인덱스는 시도로 1번 인덱스는 구군에.

맨 끝에 시도와 구군에 컬럼이 새로 생긴 거를 볼 수 있어요.

이거를 찍어볼 때 쉐이프를 써서 컬럼이 생성된 거를 확인하기도 해요.

위에서 보면 컬럼을 만들기 전에 쉐이프 선이 9개였는데 41개가 되었어요.

39개에서 2개의 컬럼이 늘어서 41개로 늘어났어요.

그리고 그 다음으로 여기에서 시도 구군을 만들어줬잖아요.

구군을 만들어줬으니까 필로 써줘도 되는데 컬러라고 써줘도 돼요.

이전 시간에 엑스 와이 다음에 에스테틱에다가 필이라고 채워졌었는데 이거를 컬루로 써줘도 되거든요.

컬러로 구군을 채워줬어요.

그러면 어떤 모습으로 찍힐지 한번 보도록 할게요.

데이터가 서울이 33만 건이라서 좀 오래 걸려요.

그래서 33만 건을 찍었더니 구별로 이렇게 나뉘어서 데이터가 표시가 되는 거를 볼 수 있어요.

저희가 아까 스플릿을 해서 시도와 구군을 나눠주고 구군의 컬럼을 시각화해서 여기에 넣어줬어요. 그래서 구별로 다른 색상으로 표시를 해서 데이터를 찍어주었어요.

여기에 보면 상권업종대분류명이라는 컬럼이 있어요.

그 컬럼에 어떤 대분류로 서울시에 있는 소상공인들을 나눴을까, 상가업소를 나눴을까를 봤어요.

나눠서 봤더니, 음식, 소매, 생활서비스, 학문교육, 의료 이런 순으로 있어요.

가장 많은 업종은, 저희는 밥을 먹지 않으면 살 수 없기 때문에, 음식점이 가장 많아요.

또 경도와 위도로 상권업종대분류명이 어떻게 서울에 분포가 되어 있는지, 업종별로 특정구는 특정업종이 많이 분포가 되어 있을 수 있잖아요.

그래서 업종별로 한번 어떻게 분포가 되어 있는지 찍어보도록 할게요.

역시 서울 데이터가 좀 많아서 그래프를 찍는 데 시간이 좀 오래 걸려요.

데이터가 너무 많아서.. 지금 이 점들이 겹쳐서 찍혔어요.

그래서 좀 가려졌는데요.

여기에서 가장 많이 보이는 색상이 약간 자주색? 핑크색하고 파란색이 좀 많이 보이죠.

그다음에 연두색.

이렇게 보이는데요.

아마도 아까 음식이 가장 많았는데요.

음식이 보라색이었고요.

이거는 좀 겹쳐지는 게 많아서요.

이 순서대로 보면 될 것 같아요.

음식, 소매, 생활서비스로 볼 수가 있고요.

데이터가 많아서 나누어서 보는 게 좀 좋을 것 같아요.

교육과 학문과 관련된 것만 따로 보려고 해요.

상권업종 대분류명에서 학문 교육인 애들만 따로 데이터프레임에 엘오씨로 하게 되면 이 데이터만 따로 뽑아져요.

이거에 해당되는 애들만요.

그래서 데이터프레임을 shop 서울 언더바 애드로 해서 새로 만들었어요.

그래서 여기에 상권업종분류별로 다시 찍도록 할게요.

학문교육.

왠지 학원이 특정지역에 많이 몰려있을 것 같잖아요?

그다음에는 부동산을 찍도록 했는데요.

부동산은 미리 그려져 있는 그래프를 보도록 할게요.

부동산에서 보라색으로, 대체적으로 부동산도 서울시에 전체적으로 고르게 분포돼있는 거를 볼 수가 있어요.

주거도 의식주 중에 빠질 수 없는 부분이기 때문에요.

그래서 부동산에서도 강남 쪽에 특히나 보라색이 좀 많이 찍혀져 있는 거를 볼 수 있어요.

보라색 데이터가 뭔 봤더니 평가개발관리 같은 부동산업종은 강남 쪽에 몰려있는 거를 볼 수 있고요.

부동산 관련 서비스는 빨간색인데 애는 다른 색이 겹쳐서 잘 보이지는 않아요.

그리고 파란색, 하늘색으로 되어 있는 부분은 분양이에요.

분양도 부동산하고 마찬가지로 고르게 분포가 되어 있는 것 같아요.

그래서 위에 그래프를 찍는 데 좀 시간이 걸렸어요. 데이터가 많아서 오래 걸리고 있는데요.

그 다음 데이터를, 미리 찍혀진 그래프를 보도록 할게요.

얘는 어디일까요?

서울 외의 지역만 모아놓은 데이터예요.

부산이죠.

혹시 여기에 부산에서 오신 분 계신가요?

원래 집이 부산이셨던 분?!

부산하고 비슷하게 생겼나요?

얘도 부산에서 구별로 찍도록 했어요.

그랬더니 제가 사이즈를 좀 줄여서 찍었는데.

얘가 좀 바쁘네요.

노트북이 지금 커넥팅이라고 뜨는 거는 바쁘다는 거예요.

초록색으로 커넥티드라고 되어 있을 때 정상적으로 실행이 되는데, 지금 노트북이 다시 연결 중이에요.

그래서 일단 여기까지 부산까지 구별로 위경도만을 가지고 스캐터플롯으로 찍어봤어요.

어떤 업종이 어떤 지역에 있는지 봤고요.

그다음으로 세 번째 프랜차이즈 입점 분석을 보도록 할게요.

그런데 지금 약간 와이파이가 잘 안 되는 것 같아요.

기호 활성화가 되어서 표시가 되고 있어요.

세 번째 노트북을 열도록 하겠습니다.

잠시만요.

인터넷 연결을 다시 좀 해보도록 할게요.

인터넷 연결 저 말고 또 안 되는 분 계세요?

그리고 세 번째 노트북은 약간 콜리움이 콜랩하고 잘 안 맞는 것 같아요.

그래서 콜리움 코드가 맨 밑에 그려져있는 코드를 추가해도 그 코드가 계속 잘리더라고요.

콜랩에 어떤 기능이 있냐면요.

여기에 제가 링크를 해놨는데, 그 링크를 생성할게요.

이 기능도 콜랩에 최근에 생긴 기능이에요.

실습할 노트북들을 깃헙 계정에 다 올려놨어요.

여기에 보면 상권비교라고 해서 노트북 파일을 올려놨는데요.

여기에서도 이 노트북 깃헙에서도 볼 수 있는데요.

깃허브에 있는 파일을 콜랩으로 바로 불러올 수가 있어요.

뒤에 주소를 제가 어떻게 적어 줬냐면요.

앞에는 콜랩 닷 컴까지 적어주고, 깃허브까지 적어주고요.

그다음에 깃허브에 제 노트의 경로를 붙여넣기를 해줬어요.

깃허브의 경로를 붙여넣기를 하고 실행을 하면 제 이 깃허브의 노트북을 바로 불러와요.

그래서 콜랩에서 바로 실행해볼 수 있는데요.

여기서는 바로 실행이 안 될 거예요.

왜 안 되냐면 데이터파일의 경로가 여기에 없기 때문이죠.

그래서 엘에스 해서 여기에 보면 이런 파일이 없다. 이 디렉토리가 없다고 떠요.

파일이 없기 때문에 아마 여기서는 안 될 거예요.

그리고 여기에 보면 Plotnine이나 플롯을 설치를 해줘야 돼요.

얘는 로컬에서는 이미 설치가 되어 있었기 때문에 오류가 나지 않았는데요.

이렇게 이 경로로 불러와서 분석을 하고 싶으실 때는 이 Plotnine하고 콜리움을 노트북에서 새로 추가를 해줘야 돼요.

추가해서 설치를 해 주게 되면 깃허브에 있는 노트북을 바로 콜랩으로 불러오셔서 사용하실 수 있어요.

지금 설치를 해 주고 있고요.

세 번째 노트북 파일을 열어서 원래는 실습하는 건데.

아까 인터넷이 끊기고 이 노트북이 끝에 제가 콜리움으로 지도를 그리는 부분이 있는데 추가를 해도 계속 없어지더라고요.

그래서 그 부분 때문에 연결하는 거를 한번 해봤어요.

설치를 지금 하고 있고요.

Plotnine하고 콜리움을 설치하고 있어요.

특정버전을 설치할 때는 버전을 명시해 주면 해당버전의 라이브러리를 설치해요.

저는 0.5.0를 사용하고요.

최신버전을 사용해도 이 실습을 하는 데는 문제가 없어요.

콜리움의 버전을 지정해서 설치를 했고요.

import를 해오면요. 정상적으로 import가 되죠.

만약에 주피터 노트북을 로컬에 설치해서 사용하시게 되면 매번 이렇게 라이브러리를 설치할 필요가 없을 텐데요.

콜랩의 단점은 약간 이런 연결이 불안정하다는 거와 라이브러리를 그때그때 설치해줘야 된다는 게 번거롭기는 해요.

다시 제가 원래 올려놓았던 3번 프랜차이즈 입점분석으로 가서 볼게요.

한글폰트까지 설치를 해줘야 돼요.

매번 한글폰트를 설치를 하고 한글폰트를 설치한 게 귀찮은 과정일 수도 있는데요.

저희는 오늘 다 같은 환경에서 실습하기 위해서 이렇게 실습을 하고 있고요.

그래서 아까 제가 깃허브에서 바로 열었던 노트북 파일을 실행해보시면 여기에 있는 파일을 복사해서 이 노트북에 붙여넣기를 해 주면 아마 이 데이터를 불러올 수가 있을 거예요.

한번 해보도록 할게요.

얘를 복사해서 여기에 csv 파일 경로를 붙여넣기를 하고 실행을 하게 되면요.

여기서는 실행이 되는데요.

노트북을 두 개를 띄우고 있잖아요.

그러면 제가 사용할 수 있는 메모리가 한정적이더라고요.

그래서 아마 이 메모리를 나눠 쓰고 있어서 좀 오래 걸릴 수도 있는 것 같은데요.

여기서 일단 이렇게 아까와 같은 파일이에요.

상가업소정보를 똑같이 가져왔고요.

그리고 이번에는 상권업소 분류명에서 커피라는 이름이 들어가는 데만 가져오려고 해요.

서울에 카페가 정말 많잖아요.

그래서 커피가 들어간 거를 가져오도록 하고요.

그랬더니 커피가 들어간 상호명이 13472개가 있어요.

그리고 커피의 시도명을 보도록 할게요.

아, 여기서 시도명을.. 시도명이 있는데요.

시도명이 널값이 시도명이 없어요.

그래서 유니크값에 찍어줬더니 서울하고 부산만 있어요.

아까 제가 전처리를 해서 시도명하고 시군구명을 따로 만들어줬었는데요.

사실은 이 데이터 안에 다 들어 있어요.

그래서 데이터 안에 들어있는 거를 써도 돼요.

상권업소 중분류명을 찍어봤더니 커피가 들어가는 분류명에 중분류명은 다 커피점 카페고요.

이 데이터만 또 1000개를 찍어봤더니 서울하고 부산이 이렇게 위치가 되어 있고요.

서울만 다시 카피를 해서 데이터프레임을 만들어줬어요.

아까처럼 서울만 따로 만들어줬고요.

상권업종 대분류명, 아까 했던 실습하고 동일한 실습이에요.

디스크라이브에서 엔피 오브젝트로. 오브젝트 타입만 요약해서 보는 거예요.

디스크라이브 했을 때 얘가 오브젝트이냐, 아니면 넘버냐에 따라서 얘는 오브젝트이기 때문에 카운트값, 유니크값, 탑, 프리퀀시 이렇게 가져오게 되는데요.

여기에서 카운트값은 몇 개의 데이터가 있는지, 유니크한 데이터가 몇 개인지, 그리고 아마 저 탑은 프리퀀시, 자주 등장하는 단어에서 가져 온 건데요.

씨유라는 게 아마 가장 많이 등장하는 상업명일 거예요.

지점도 본점이라는 게 294개로 가장 자주 등장하는 단어고요.

대분류명도 음식이라는 게 가장 많이 등장하고요.

한식이 제일 많이 등장해요.

이 디스크라이브를 해서 봤을 때, 이 데이터에 음식이 들어가는 대분류명과 중분류명에 한식이 들어가는 거, 소분류명에는 한식과 한정식과 백반 이런 업소가 서울에 있는 업소에 가장 많다는 거를 볼 수 있어요.

위도와 경도만 따로 뽑아보면요.

여기에 인클루드 정보는 사실 따로 써줄 필요는 없는데요. 위도와 경도를 지정해줬기 때문에요.

이렇게 엔피 넘버로 지정할 수 있다는 거를 알려드리기 위해서 이렇게 지정해봤어요.

그리고 Pandas에서 쓰다보면 도움말이 궁금할 때가 있어요.

도움말이 궁금할 때 여기에서 디스크라이브하고 물음표를 하게 되면 도움말이 바로 떠요.

디스크라이브를 어떻게 쓰는 건지 여기서 설명을 보고 쓸 수 있어요.

저는 지금 여기서 인클루드 엔피 넘버 그리고 오브젝트로 해줬잖아요.

인클루드 올이라고 하게 되면 모든 정보를 다 표현할 수 있게 되는 거예요.

그래서 도움말이 옵션에 대한 정보를 보고 싶을 때는 이렇게 물음표를 해 주게 되면 그 정보를 확인할 수 있다는 거를 말씀드리고 싶었어요.

위도와 경도를 이렇게 해서 가져와서 봤더니요.

민값을 보면요.

아마 이게 데이터에 가장 많이 등장하는 것 중에 중간값이 되겠죠. 37.54, 126점이 중간값이에요.

그리고 상권업종 대분류명을 시각화를 해서 보면요.

어떤 분류가 가장 많은지 봤더니 음식점이 가장 많아요.

역시나 음식점.

아까 위에서 프리퀀시로 찍었을 때도 한식, 한정식 이런 게를 많았잖아요.

음식점이 가장 많고 그다음에 소매, 학문교육, 생활서비스.

저희가 이거를 베일류 카운터로 찍었을 때도 이거하고 같은 값을 볼 수가 있었는데요.

그 값을 시각화해놓은 거예요.

대분류명 음식.

음식이 들어가는 것만 가지고 왔더니 10만 건 정도가 되네요.

그리고 중분류명을 찍었더니 한식.

음식점 중에서 어떤 음식이 들어가는 거를 푸드라는 데이터프레임을 따로 만들었어요.

그 데이터프레임에서 어떤 중분류명이 있나봤더니 음식점 중에서도 특히나 한식점이 많은 거를 볼 수 있어요.

그리고 패스트푸드가 들어가는 거.

컬럼이 어떤 게 있는지 찍어보았고요.

여기에서 상호명을 가져와서 유니크한 거를 찍어봤더니요.

이런 상호들이 보여요.

배스킨라빈스가 보이길래 던킨과의 입지분석을 해봐야겠다는 생각이 들었어요.

상호명에 배스킨하고 던킨이 들어가는 애만 찾았어요.

그랬더니 438개가 나왔어요.

서울에서 배스킨하고 던킨이 들어가는 것만 찾은 거고요.

상호명을 베일류 카운트를 해서 찍어보면요.

배스킨라빈스 31으로 되어 있는 게 102개가 있는데 나머지 하나씩 되어 있는 애들을 보면 지점명이 같이 들어가 있어요.

상호명이.

그러면 애네들을 다 같이 쓰려면 뭔가 전처리를 해 주면 같이 쓸 수 있겠죠?

그래서 이 데이터를 전처리를 해 줄 거예요.

저는 브랜드명이라는 컬럼을 새로 만들어줬어요.

거기에 만약에 배스킨이라는 단어가 들어간다고 하면 얘는 배스킨라빈스라고 써주고요.

상호명에 던킨이 들어가면 던킨도넛츠라고 써줬어요.

그래서 얘를 실행해서 보면요.

브랜드명이라는 컬럼이 새로 생기고 배스킨인지 던킨인지 뽑아서 표시를 하도록 했어요.

이 브랜드명에 베일류 카운트를 해봤더니 던킨보다 배스킨이 좀 더 많죠.

이 비율을 이렇게 나누기로 해서 계산을 했어요.

그랬더니 서울에는 던킨도너츠보다 배스킨라빈스 매장이 1.96배 많아요.

이 데이터만을 봤을 때요.

그래서 df_31을 해서 찍어보면 위도 경도만 플롯이고 나머지는 오브젝트 타입인 거를 볼 수 있어요.

그래서 데이터 타입을 확인했고요.

위경도를 다시 스캐터플롯을 그렸어요.

점 포인트로 해서 엑스축이 경도, 와이축을 위도로 해 주고 컬러를 브랜드명으로 다르게 찍도록 했어요.

봤더니 비슷한 위치에 있는 것 같기는 한데 이 점 사이즈가 좀 커요. 그래서 이것만으로는 알기는 어려운데. 일단 배스킨과 던킨의 분포가 고르게 되어 있는데 배스킨이 좀 더 많이 있는 거를 볼 수가 있어요.

얘를 콜리움이라는 시각화툴로 찍어보려고 해요.

마커로 표시를 해 줄 텐데요.

이 아이콘은 폰터어썸에 들어가는 걸로 표시할 수 있어요.

저는 인포로 다 찍었는데요.

여기서 이 콜리움맵을 불러와서 로케이션에서 위도와 경도는 민값, 평균갑을 찍어주도록 했어요.

평균값으로 콜리움 지도를 찍어올 때 어디를 중심으로 잡을 건지 그 값을 평균으로 구해서.

일단 콜리움맵을 초기화해 주고요.

이 줌스타트는 얼마나 확대해서 보여줄지예요.

애를 1로 바꿔보도록 할게요.

좀 시간이 오래 걸리는데요.

1로 바꾸면 이렇게 세계 지도가 뜨죠.

배스킨하고 던킨이 우리나라 근처에 엄청 많이 몰려있는 거를 볼 수 있어요.

확대해서 봐야하기 때문에 확대해서 보도록 할게요.

배스킨하고 던킨이 서울시에 분포가 되어 있는 거를 볼 수 있고요.

던킨 같은 경우에는 핑크로, 배스킨은 블루로 찍도록 했어요.

그리고 이 아이콘을 클릭했을 때 그 주소도 같이 찍을 수 있도록 표시를어요.

표시를 했어요.

그래서 어느 위치에 상점들이 위치해있는지를 찍어봤고요.

그리고 다시 이번에는 지도의 타일을 여러 가지로 바꿀 수가 있어요.

스타일을 좀 바꿀 수가 있는데요.

이렇게 스타일을 좀 바꿔서 출력을 했어요.

이 지도에 대한 도움말을 보실 때는 여기에 보면 제가 링크를 해놨는데요.

여러 가지 스타일로 지정해서 지도를 그릴 수가 있어요.

여기에 있는 예제를 가져다가 그리면요.

이런 식으로 예제를 가져다가 그려보실 수가 있어요.

여기에서 또 얘는..

이런 식으로도 찍어줄 수가 있어요.

히트맵 같은 것도 찍어줄 수가 있고.

여기에 있는 예제를 참고하셔서 그래프를 변경해서 찍어오실 수 있어요.

여기서는 그냥 마커로 어느 위치에 있는지 찍도록 했어요.

뚜레쥬르하고 파리바게트의 매장위치도 분석해보고 싶었어요.

저희 동네에 대표적인 빵집이 뚜레쥬르와 파리바게트고 어디에서나 볼 수 있는 빵집인 것 같아서 분석을 했고요.

파리바게트의 경우에는 끝이 트로 끝나는 애도 있고 뜨로 끝나는 애들도 있어요.

그래서 그런 애들.

그리고 파리크라상도 같은 매장으로 봤어요.

상호명을 불러올 때 파리로 시작을 하고 바게트나 크라상인 애로 가져오도록 했어요.

그래서 바게까지만 가져오도록 했어요.

뜨로 끝나는 애도 있고 트로 끝나는 애도 있기 때문에도

뚜레주르도 주르가 있고 쥬르가 있어요.

그래서 애도 가운데에 이렇게 선택을 해서 가져오도록 하고요.

파리바게트, 뚜레쥬르 이렇게 데이터프레임 상호명에 가지고 와서요.

브랜드명에 넣어주도록 했어요.

아까는 이 브랜드명을 df 괄호 안에 브랜드명을 써줬는데 이런 식으로 새로 컬럼을 지정해줄 수도 있어요.

그래서 브랜드명 컬럼을 생성했고요.

브랜드명을 찍어보면 파리바게뜨와 뚜레쥬르가 이렇게 차이가 나는 거를 볼 수 있고요.

제공된 데이터를 봤을 때 서울에는 파리바게뜨가 뚜레쥬르보다 매장이 1.9배 많아요.

뒤에 더 셀이 있는데 이상하게 셀을 추가해도 없어지더라고요.

그래서 그 다음 데이터부터는 깃허브에 있는 데이터로 보도록 할게요.

콜리움의 오류인지.

이 특정셀만 들어가면 오류가 나서요.

얘를 제가 깃허브에 올렸는데 콜리움은 미리보기가 안 돼서 주피터 노트북에서 보도록 할게요.

파리바게트하고 뚜레쥬르도 아까, 던킨도너츠랑 배스킨라빈스 찍었던 거하고 마찬가지로 색깔을 구분해서 찍을 거고요.

그래서 아까는 마커로 표시를 하도록 했는데요.

이번에는 써클마커로 표시하도록 했어요.

제가 밑에 서클에 써클마커로 썼거든요.

써클마커를 쓰면 계속 노트북에 오류가 뜨더라고요.

그래서 써클마커를 주피터 노트북에서만 보도록 할게요.

써클마커로 던킨과 배스킨도 이렇게 표시를 했고요.

이 써클마커는 신기하게 콜랩에서는 표현이 안 돼서요. 제가 부득이하게 주피터 노트북에서 보여드릴게요.

깃허브에서 파일을 다운로드 받으셔서 실행해보실 수가 있고요.

파리바게트의 정보를 보면 1.9배 가량 파리바게트가 많은 거를 확인할 수 있는데요.

실제로 파리바게트 홈페이지에 제가 들어가봤어요.

서울시에 있는 매장 정보를 보니까요.

798개가 있더라고요.

공공데이터셋에는 434개가 있는데 실제 데이터하고는 차이가 있는 거를 알 수 있어요.

뚜레쥬르도 244개인데 194개가 있었어요.

매장이 생기고 없어지고 하다보니까 데이터를 수집하는 시점에 따라서 데이터가 조금 다르게 들어가있는 거를 볼 수 있고요.

여기도 이렇게 뚜레쥬르와 파리바게트를 마커로 찍어주기도 했고요.

아 처음부터 다시 실행을 해야 되는데.

세 번째 노트북이 계속 연결이 안 되고 문제가 좀 많이 있었어요.

그런데 이 코드를 추가하니까 서클마커와 관련된 코드를 추가하면 오류가 나더라고요.

그 문제를 아직 못 찾았는데, 혹시 원인을 찾게 되면 저한테 제보해 주시면 감사하겠습니다.

던킨하고 배스킨의 입점을 분석해보았고요.

한 셋이 실행이 되고 있는데..

상호명에 파스쿠치나 잠바주스도 계열이더라고요.

그래서 그 상호들은 다 제외하도록 했어요.

이렇게 물결을 하게 되면 그 부분은 빼는 거거든요.

그거는 빼도록 하고.

찍었어요.

그래서 서클마커로 찍으면 이런 모습이 돼요.

파리바게트와 뚜레쥬르가 곳곳에 매장이 있는 거를 볼 수 있어요.

가끔 저는 친구들한테 이 쿠폰을 선물할 때 친구 집근처에 어떤 빵집이 있나 보고 선물하거든요.

입점을 분석해보았고요.

지금 세 시 삼십분인데요.

한 10분간 쉬는 시간을 갖고 3시 40분까지 쉬는 시간을 갖고 이어서 진행을 하도록 하겠습니다.

원래 4시까지인데요. 4시 10분까지 하도록 할게요.

마이크 이거 안 해도 되나요?

네 번째 전국도시공원 표준데이터를 보도록 할게요.

위에 공공데이터포털의 링크들을 걸어놨는데요.

도시공원 표준데이터에 가보면요.

전국도시공원 표준데이터가 있어요.

어떤 공원이 어떤 지역에 위치해있는지를 상권정보하고 비슷하게 위치정보를 사용해서 스캐터차트로 찍어보고 실제로 지도에 찍어보는 실습을 하도록 할게요.

역시나 마찬가지로 Plotnine하고 콜리움을 설치해줘야 돼요.

그리고 여기에서 저희가 처음에 사용했던 미씽고를 설치해서 결측치가 얼마가 되는지를 시각화해보도록 할게요.

필요한 모듈들을 import해왔어요.

지도표현을 위해서 콜리움을 import해왔습니다.

그리고 그래프에서 한글표현을 위해서 폰트설치를 해줬고요.

기본글꼴을 나눔바른고딕으로 변경해주었어요.

데이터를 리드 언더바 csv로 해서 csv 파일을 불러왔고 이 인코딩은 이유씨 케이알로 되어 있네요.

이유씨 케이알로 인코딩을 변경해 주었습니다.

그리고 헤드로 위에 다섯 개 데이터만 찍어봤어요.

그랬더니 맨 위에 있는 데이터는 강원도부터 있는 게 보여지네요.

강원도부터 보여지고요.

우편번호와 위경도 정보, 소재지 주소 같은 것들이 있어요.

여기에서 보면요.

불필요한 컬럼들이 생각보다 많이 있어요.

이렇게 엔에이엔으로 결측치가 많이 보이는데요.

이런 컬럼들은 사용하지 않을 거예요.

일단 결측치가 얼마나 되는지 보도록 할게요.

공원보유시설이라고 되어 있는 이 부분은 결측치가 훨씬 많이 있어요.

그래서 이번 분석에서는 이 데이터들은 다 빼고 가도록 할게요.

파크라는 데이터프레임에 데이터를 담아주었는데요. 컬럼들을 써서 이 컬럼들은 다 드랍을 시키도록 할게요.

씨에프를 찍어보면요.

처음에 가져왔던 거에 비해서 위에서 쉐이프를 안 썼는데 컬럼이 10개로 줄었어요.

위경도 정보를 지난 실습에서 했던 것처럼 마찬가지로 찍었더니 우리나라 지도 같나요?

여기에 보면 끝에 점이 찍힌 거를 볼 수 있어요.

이 두 개의 점은 이상한 곳에 찍혀 있어요.

이 점이 어디인지 한번 궁금해서 볼 필요가 있을 것 같은데요.

공원면적을 전처리를 해주도록 할게요.

공원면적별로 어떤 데는 큰 공원이 있고 어떤 곳은 작은 공원이 있는지 시각화를 해서 보면 큰 공원을 찾는 데 도움이 될 것 같아서요.

공원면적을 플롯으로 처리해 주도록 할게요.

공원면적 사이에 스트림에 쉼표가 있어요. 이 쉼표를 공백으로 바궈주고요.

얘를 플롯으로 해서 수치데이터로 바꿔

바꿔줬얶

아, 이미 바꾼 애를 다시 바꿔서 오류가 났는데요.

다시 불러오도록 할게요.

이럴 때는 다시 불러와야 돼요.

그래서 데이터를 다시 csv 데이터를 로드하고요.

컬럼해 주고 씨에프 찍고 다시 실행해줄게요.

다시 실행을 해 주었고요.

공원면적 비율을 보면 Plotnine에 사이즈를 찍을 때 이 사이즈를 그대로 찍으면 지도가 아마 다 덮힐 계요.

그래서 지도에 표시할 수 있는 사이즈로 줄여주기 위해서 일단 스캐어노트를 씌어주고 거기에 0.01을 다시 곱해줬어요.

이 숫자는 의미있는 뭇자는 아니에요.

루트를 씌운 이유는 편차가 너무 크기 때문에 그 편차를 줄여서 작은 크기로 만들어주려고 공원면적비율을.

얘도 너무 작은 동그라미와 너무 큰 동그라미가 쓰면 제대로 구분이 돼서 보이지 않기 때문에 편차를 줄이기 위해서 스캐어노트를 씌어줬어요.

그래서 0.01을 곱해줘서 그래프에 표시하기 적당한 면적 사이즈로 변경해줬어요.

그리고 소재지도로명주소와 지번주소의 널값을 봤어요.

도로명주소와 지번주소를 봤더니 도로명주소가 지번주소보다 많이 입력이 되어 있는 거를 볼 수 있어요.

그래서 도로명주소의 널값을 지번주소로 채워줄 거예요.

도로명주소는 없는데 지번주소가 있는 경우가 있잖아요.

그런 경우에 지번주소로 채워주고, 널값을 보면 널인 로우가 없는 걸로 보여지죠.

그래서 이렇게 결측치를 주소 같은 경우에는 도로명 주소와 지번주소를 서로 채워줄 수 있을 것 같아서 이렇게 채워줬고요.

도로명주소에서 공백으로 스플릿을 했어요.

맨 앞에 거를 따 오면 이렇게 시도가 될 거예요.

맨 앞에 거를 시도를 새로 컬럼을 만들어서 넣어줬어요.

시도에서 앞에 강원도 이렇게 들어가 있고요.

그 다음 데이터를 구군에다가 넣어줬어요.

그러면 시도, 구군 컬럼이 새로 생긴 거를 볼 수 있어요.

위도와 경도를 또 다시 디스크라이브 해서 보면요.

이렇게 평균값이 36.49, 127.55인 거를 볼 수 있어요.

이 평균값은 저희가 지도를 찍을 때 어디를 중심으로 할지, 그리고 데이터프레임에서 다시 구해올 거예요.

위도와 경도가 범위를 벗어나는 게 있을 것 같아서요.

아웃라인 데이터를 제외하고.

널값인 것들이 있어요.

널값인 것들은 제외하고요.

아웃라이어데이터들이 있는데 그것들이 어떻게 되어 있는지 찍어봤어요.

위도와 경도가 이상하게 들어가 있는 애들.

봤더니 아까 두 개가 이상하게 찍힌 애들을 봤더니.

위경도가 좀 이상한 값이 들어가 있어요.

위도와 25, 그리고 경도가 137

그런데 주소를 봤을 때 부산하고 충북인데 아까 찍힌 거는 태평양 어딘가였죠.

이런 데이터를 주소를 가지고 위경도를 받아올 수 있어요.

구글에서도 제공하고요.

네이버나 다음 에이피아이를 사용해서 받아올 수 있어요.

여기에서는 그거까지는 다루지는 않고요.

시도의 베일류 카운트를 해보도록 할게요.

경기도 데이터가 가장 많아요.

이 데이터만을 보고 경기도에 공원이 제일 많다고 판단하기는 좀 어려울 거예요.

왜냐하면 여기는 어린이 공원이라든지 묘지 공원이라든지 다양한 공원들이 있기 때문에요.

그래서 시도별 공원데이터를 찍어보도록 할게요.

역시나 엑스축에 경도와 와이축에 위도.

그리고 컬럼을 시도로 해서 스캐터플롯으로 찍었는데요.

여기서 파크낫눌이라고 해서 널값은 제외한 걸로 찍었어요.

시도별로 찍었는데요.

약간 우리나라 지도 같기는 한데.

우리나라 지도보다 약간 찌그러져 보이는 것 같아요.

이렇게 찌그러져 보이는 데이터는 메카트로도법을 사용하게 되면요.

우리나라 지도를 일반적으로 이미지에서 볼 때처럼 찍을 수가 있는데 여기서는 그냥 스캐터플롯을 가지고 출력을 하도록 했어요.

공원구분별로 분포를 보도록 할게요.

여기를 보면요.

여기에서 사이즈를 공원면적비율로 찍도록 했어요.

그런데 작은 것들은 좀 큰 거에 가려져서 잘 안 보여요.

여기에 프론트플롯에 알파값을 0.25로 찍어서 다시 해볼게요.

이런 식으로 공원들이 큰 공원과 작은 공원들이 분포가 되어 있는 거를 볼 수가 있는데요.

전체 데이터만 놓고 봤을 때는 그렇게 의미있는 데이터 같지는 않아요.

그래서 이것도 지역별로 따로 보면 좀 더 의미가 있을 것 같기는 해요.

어린이공원이 너무 많아서요.

다른 공원이 어린이 공원에 덮혀서 안 보이거든요.

어린이 공원은 빼고 찍도록 했어요.

어린이 공원은 빼고 찍었더니 그래도 다른 공원에 가려져서 잘 안 보이는데요.

제주도는 가운데에 한라산이 있기 때문에 해안선을 주변으로 공원들이 많이 분포가 되어 있는 거를 볼 수 있어요.

그래서 파크 엘오씨 낫널을 헤드값으로 찍어보면요.

여기에 공원면적이 숫자가 되어 있고 면적비율은 이렇게 들어가 있는 거를 볼 수 있어요.

시도별 공원비율을 보면요.

경기도가 가장 많고요.

이거는 베일류 카운트를 했을 때도 위에서 처음 봤을 때라도 경기도가 가장 많기는 했는데요.

전체 비율을 봤을 때 27% 정도가 경기도에 공원이 분포가 되어 있는 거를 볼 수 있어요.

데이터 베일류에서 이렇게 하나하나 줄에 시도, 합계비율, 한 개의 컬럼에 로우의 데이터들을 시리즈데이터라고 하는데요.

이 시리즈데이터를 합계와 비율의 시리즈데이터를 합쳐서 하나의 데이터프레임에서 볼 수 있도록 만들어놨어요.

이렇게 보게 하기 위해서 아까 제가 아파트분양값을 하면서 컨캣으로 위아래의 데이터를 합쳤는데 이렇게 머지를 사용해서 합계와 비율데이터를 합쳤어요.

합계와 비율 데이터를 이렇게 출력을 해서 봤고요.

얘도 그냥 이 차트로 그리면 경기도가 월등히 많은 거를 볼 수 있어요.

공원구분도 어린이 공원이 가장 많아요.

맨 마지막에 하나 있는 거를 보면 도시농업공원구역이라는 것도 있어요.

제일 많은 거는 어린이공원, 근린공원, 소공원, 문화공원이라는 공원들이 있고요.

공원구분별로 합계를 보면요.

어린이공원이 제일 많죠.

그다음에 근린공원이 있는 거를 볼 수 있고요.

경기도에 가장 많은 공원이 있어서요.

시도가 경기도인 것만 모아서 지지라는 새로운 데이터프레임을 만들어줬어요. 그래서 지지에 데이터프레임을 찍어줬디논란3675개의 데이터베일류 카운트가 나왔어요.

또 베일류카운트를 해서 봤더니 어린이공원이 제일 많고 근린공원, 체육공원, 소공원 이렇게 있는 거를 확인할 수 있어요.

여기서 공원면적비율을 위해서 스캐터롯트를 씌우고 0.02를 곱해서 네 개의 면적 비율로 나눠줘요.

공원면적비율로 공원을 출력해봤어요.

서울을 제외하고 경기도가 서울을 둘러싸고 공원들이 분포가 되어 있는 거를 볼 수 있어요.

그중에도 특히나 이 원이 커 보이는 공원들이 있어요.

그 공원들은 어떤 공원인지 콜리움에서 찍어보도록 할게요.

수원에 있는 공원만 보고 싶어요.

그래서 수원에 있는 공원만 따로 데이터프레임을 만들어서 실행해주면요.

여기에 유난히 큰 공원이 있어요.

이쯤에 공원이 있는데요.

여기가 어디일지 위경도만으로는 사실 파악하기가 어렵잖아요.

그래서 콜리움에 찍어보도록 했어요.

콜리움에 찍어보면요.

이렇게 마커로 찍었는데요.

마커만으로도 사실 어떤 공원이 큰 공원인지를 좀 파악하기는 어려워요.

그래서 공원의 크기를 콜리움 지도에 반영을 해 주고 싶어요.

여기서 공원면적비율인 레디우스에다가 지정을 해줬어요. 그래서 위도와 경도에 초기화시켜줬고요.

수원할 거라서 수원데이터의 평균값을 지도의 중심좌표값을 잡아주고요.

여기에 보면 유난히 크게 원이 그려지는 공원이 있어요.

이 공원은 어디일까요?

책을 하나를 상품으로 드릴 수 있을 것 같습니다.

어디일까요?

이 유난히 큰 이 공원.

손을 들고 말씀해 주셔야지 제가 책을 드릴 수가 있어요.

네!

무슨 호수공원이죠?

네, 맞아요.

광교호수공원이에요.

거기에 이렇게 호수가 큰 게 두 개가 있어요.

여기 전부 다 산책하는 곳 보면 광교호수공원이라고 있고요.

여기를 클릭해봤으면 아실 수 있으셨을 텐데.

클릭해보면 여기에 제가 무슨 공원인지 크게 뜨도록 해놨어요.

광고호수공원, 제가 가끔씩 가는 공원이에요.

한 바퀴 도는 데 한 시간 정도 걸립니다.

광교호수공원이었고요.

경기도 일부 공원만 보도록 할게요.

어린이공원 같은 게 너무 많이 찍히면 다른 공원이 잘 안 보이니까 역사공원을 보고 싶어서 찍으면 이렇게 분포가 되어 있는 거를 볼 수 있어요.

시간이 많이 없어서 빨리 진행하도록 할게요.

경기도에 일부공원만 표시를 하면 전체적으로 공원이 있는 거를 볼 수 있고요.

서울시에도 공원데이터가 어떻게 돼 있나 찍어봤어요.

서울시에는 좀 이렇게 많이 이상하게 데이터가 흩어져있는 것 같아요.

서울 지도 밖에도 찍혀있는 것 같고요.

서울시 데이터는 자세히 볼 필요가 있을 것 같아요.

서울에 있는 공원을 봤을 때 역시나 어린이공원이 제일 많고 서울에도 묘지공원이 35개나 있어요.

그리고 서울 특별시에 어린이 공원만을 보고 싶어요.

그래서 서울에 플레이그라운드라고 해서 구별로 찍어보면요.

이렇게 어린이공원을 찍어보면 특정지역에 어린이공원이 굉장히 부족해보여요.

왜 그럴까요?

한번 볼까요?

전체 서울에는 25개의 구가 있어요.

이 데이터는 그냥 검색을 해서 위키데이터에서 서울에 있는 정보를 긁어왔어요. 그래서 몇 개가 있는지 세어봤더니 35개의 구가 있더라고요.

25개의 구가.

그런데 봤는데 무악동이라는 게 구에 들어가 있어요. 얘는 군인데.

이렇게 데이터가 좀 잘못 들어가 있는 게 있고요.

그런 데이터는 전처리를 해 줄 필요가 있어요.

그리고 강남서초 송파에 어떤 공원이 있는지 표시를 해봤어요.

그런데 강남서초 송파를 찍었는데 이렇게 위에 가있는 공원들이 있어요.

그래서 얘가 어디일까 했는데 여기는 안 보여서 지도를 축소해봤어요.

강남송파를 찍었는데 여기에 가 있어요.

서초구 신호동인데 고양시에 가 있죠. 안골도 내북동인데 고양시에 가 있고.

위경도 데이터가 잘못 되어 있는 데이터가 생각보다 많이 있어요.

이런 아이들은 에이티아이를 사용해서 위경도 정보를 보정을 해줄 필요가 있을 거예요.

공원구분, 서울에도 역시나 주로 어린이공원이 많이 있고요.

아까 출력해 봤던을 것처럼.

그리고 경기도도 어린이공원이 가장 많이 있어요.

공원면적을 봤을 때도 강남구에 공원구분과 면적을 봤고요.

시간이 많지 않아서요.

일단 제주도를 보고 끝내는 걸로 할게요.

제주 특별자치도만 따로 데이터프레임에 담아줬어요.

여기 사이즈에 공원면적비율로 이렇게 그래프를 스캐터차트를 찍도록 했어요.

제주도의 해안선을 따라서 이렇게 크고 작은 공원들이 모여있는 걸로 보여지고요.

이 공원들이 어떻게 위치가 되어 있는지 찍어보면요.

이렇게 해안선을 따라서 있고요.

한라산 올라가는 길과 내려가는 이쪽에 있는 걸로 볼 수 있어요.

이전 실습에서는 이 써클마커를 쓰면 오류가 났었는데 이 노트북에서는 또 오류가 안 나네요.

이상하게..

그래서 여기에서 써클마커로 또 큰 공원을 표시해봤어요.

대충 이렇게 큰 공원을 봤더니 남조봉공원이라는 게 꽤 커요.

저는 이 공원을 처음 들어봤거든요. 제주도 여행을 몇 번 갔어도?

그래서 이 공원을 어떤 공원인가 봤더니 검색해보니까 생각보다 큰 공원이기는 하더라고요.

이렇게 공공데이터포털에 생각보다 분석을 해볼 수 있는 데이터들이 꽤 많이 있어요.

Pandas를 입문을 하신다든지 아니면 파이썬으로 데이터분석을 입문하실 때 공공데이터포털에 있는 데이터를 직접 다운로드 받으셔서 로컬에 있는 주피터 노트북이나, 아니면 이렇게 제가 다음 세션으로 진행하는 국민청원 데이터에 보면 이 파일을 업로드해서 불러올 수 있는 코드를 같이 노트북에 올려놓았어요.

그래서 그 코드를 참고해서 csv 파일을 직접 콜랩에 업로드를 하고 그 파일을 csv 파일을 불러와서 이 Pandas로 데이터를 요약해보고 시각화하는 실습을 해보시면 Pandas 데이터분석하는 데 좀 더 도움이 될 것 같습니다. 그래서 오늘 준비한 공공데이터로 파이썬 데이터분석하기는 여기까지 진행하고요.

참여해 주신 많은 분들께 감사드리고요.

도우미로 참석해 주신 분들께도 감사를 드립니다.

이어서 4시 30분부터는 청와대 국민청원 데이터로 파이썬 자연어처리 분석하기를 진행하도록 하겠습니다.

감사합니다.



